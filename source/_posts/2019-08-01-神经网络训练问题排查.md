---
layout: post/
title: 神经网络训练问题排查
date: 2019-08-01 17:01:14
tags: Deep learning
categories: Deep learning
---
# 数据标准化
数据的分布情况如何？数据是否经过适当的缩放？总体上的规则是：

* 如果数据是连续值：范围应当在-1到1、0到1，或者呈平均值为0、标准差为1的正态分布。实际的范围不用如此精确，但确保输入数据大致处于上述区间内会有助于训练。缩小过大的输入，放大过小的输入。
* 如果数据是离散的类别（以及对于分类问题的输出而言），则通常使用one-hot表示。也就是说，如果有三种类别，那么这三种不同类别的数据将分别以[1,0,0]、[0,1,0]、[0,0,1]的方式表示。

请注意：训练数据和测试数据的标准化方法必须完全相同，这非常重要。
# 权重初始化
您需要确保权重不会过大，也不会过小。Xavier权重初始化方法通常是比较好的选择。对于使用修正线性（relu）或带泄露的修正线性（leaky relu）激活函数的网络而言，RELU权重初始化方法比较合适。
# Epoch数量和迭代次数
一个epoch周期的定义是完整地遍历数据集一次。DL4J将迭代次数定义为每个微批次中的参数更新次数。

在训练中，一般应让训练持续多个epoch，而将迭代次数设为一次（.iterations(1)选项）；一般仅在对非常小的数据集进行完整批次的训练时才会采用大于1的迭代次数。

如果epoch数量太少，网络就没有足够的时间学会合适的参数；epoch数量太多则有可能导致网络对训练数据过拟合。选择epoch数量的方式之一是早停法。早停法还可以避免神经网络发生过拟合（即可以帮助网络更好地适应未曾见过的数据）。

# 学习速率
学习速率是最重要的超参数之一。如果学习速率过高或过低，网络可能学习效果非常差、学习速度非常慢，甚至完全没有进展。学习速率的取值范围一般在0.1到1e-6之间，最理想的速率通常取决于具体的数据（以及网络架构）。一种简单的建议是，一开始可以尝试三种不同的学习速率：1e-1、1e-3、1e-6，先大致了解一下应该设为怎样的值，然后再进一步微调。理想状态下，可以同时以不同的学习速率运行模型，以便节省时间。

选择合适的学习速率的常用方法是借助DL4J的可视化界面来将训练进程可视化。您需要关注损失随时间变化的情况以及更新值与参数的绝对值之比（通常可以先考虑1:1000左右的比例）。

# 策略与学习速率计划
您可以选择为神经网络设定学习速率策略，让学习速率随着时间推移逐渐“放缓”，帮助网络收敛至更接近局部极小值的位置，进而取得更好的学习效果。一种常用的策略是学习速率计划（learning rate schedule）。
# 损失函数
神经网络不同层中的损失函数的作用包括预训练、学习改善权重，以及在分类问题中得出结果（位于输出层上）。（在上述例子中，分类发生在重写段中。）

网络目的决定了所用的损失函数类型。预训练可选择重构熵函数。分类可选择多类叉熵函数。
