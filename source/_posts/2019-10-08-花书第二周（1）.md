---
layout: post/
title: 花书第二周--机器学习基本概念
date: 2019-10-08 13:53:29
tags: deep learning
categories:
  花书
---

# 机器学习算法
1. 什么是学习？
对于某类任务T和性能度量P，一个计算机程序被认为可以从经验E中学习是指，通过经验E改进后，它在任务P上由性能度量P衡量的性能有所提升。
2. 什么是机器学习算法？
能够从数据中学习的算法

## 1.1 任务T
#### 机器学习的任务是什么？
机器学习系统应该如何处理样本，即对严办进行一个复杂的非线性变化从而得到正确的结果

我们通常会将样本表示成一个向量 $x \in \mathbb{R}^n$, 其中向量的每一个元素是一个特征

#### 常见的任务有哪些？
* 分类： $f: \mathbb{R}^n \to \{1,...,k\}$ （输出离散，输出为概率分布）
* 回归： $f: \mathbb{R}^n \to \mathbb{R}$ （输出连续）
* 转录：OCR, ASR
* 机器翻译： seq2seq
* 结构化输出：输出值之间内部密切相关，如语法树
* 异常检测
* 合成与检测
* 缺失值填充
* 去噪
* 密度估计

本节重点讲了分类回归问题的区别

度量：

分类：precision, recall, auc, roc, f1

回归: mse
## 1.2 经验
无监督学习：

含有很多特征的数据集，但是没有label

监督学习：

（线性回归，LDA,SVM)数据集有label or tag
# 容量，过拟合和欠拟合
训练集：
测试集：衡量模型的好坏

* underfitting: 参数太少，模型简单

* appropriate capacity: 泛化能力最好

* overfitting: 模型复杂，训练集误差小，测试集误差大

模型泛化：模型容量

泛化误差：测试误差

## model原则：
* 剃刀原则： 若有多个假设与观察一致，选择最简单的
* 没有免费午餐定理：不存在能够在所有可能的分类问题中性能均为最优的算法
* 解决方案：尽可能深入了解分布，寻找先验知识
* 正则化：降低泛化误差而非训练误差，L1,L2（为什么？）

$J(w)=MSE_{train}+\lambda w^{\top}w$

## 超参数和验证集
超参数：
用于挑选超参数的数据子集成为验证集，通常8：2

验证集：
交叉验证，留出法，k折交叉验证

实际工作经验：训练集，交叉验证集，测试集

训练集：训练数据

交叉验证集：判断学习率是否要调整，何时结束训练，每一个epoch都测试

一般来讲，训练数据每过一个epoch, 都要在交叉验证集上看一下

性能：损失函数

测试集：判断模型的性能好坏，最后用
