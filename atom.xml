<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Dinry</title>
  
  <subtitle>notebook</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://dinry.github.io/"/>
  <updated>2019-12-06T12:58:04.320Z</updated>
  <id>http://dinry.github.io/</id>
  
  <author>
    <name>dinry</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>AE+DAE+CDAE+Trust CDAE</title>
    <link href="http://dinry.github.io/CDAE/"/>
    <id>http://dinry.github.io/CDAE/</id>
    <published>2019-12-05T11:27:29.000Z</published>
    <updated>2019-12-06T12:58:04.320Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="ae-auto-encoders">AE (auto-encoders)</span></h1><p>The schematic structure of an autoencoder is as follows:<img src="/CDAE/1.JPG" alt>The encoder part of the network is used for encoding and sometimes even for data compression purposes although it is not very effective as compared to other general compression techniques like JPEG.Encoding is achieved by the encoder part of the network which has decreasing number of hidden units in each layer. Thus this part is forced to pick up only the most significant and representative features of the data.</p><p>The second half of the network performs the Decoding function. This part has the increasing number of hidden units in each layer and thus tries to reconstruct the original input from the encoded data.</p><p>AEs are an unsupervised learning technique.</p><p>Training of an Auto-encoder for data compression: For a data compression procedure, the most important aspect of the compression is the reliability of the reconstruction of the compressed data. This requirement dictates the structure of the Auto-encoder as a bottleneck.</p><p>Step 1: Encoding the input dataThe Auto-encoder first tries to encode the data using the initialized weights and biases.<img src="/CDAE/2.JPG" alt></p><p>Step 2: Decoding the input dataThe Auto-encoder tries to reconstruct the original input from the encoded data to test the reliability of the encoding.<img src="/CDAE/3.JPG" alt></p><p>Step 3: Backpropagating the errorAfter the reconstruction, the loss function is computed to determine the reliability of the encoding. The error generated is backpropagated.<img src="/CDAE/4.JPG" alt>The above-described training process is reiterated several times until an acceptable level of reconstruction is reached.</p><p>After the training process, only the encoder part of the Auto-encoder is retained to encode a similar type of data used in the training process.</p><p>The different ways to constrain the network are:</p><ul><li>Keep small Hidden Layers: If the size of each hidden layer is kept as small as possible, then the network will be forced to pick up only the representative features of the data thus encoding the data.</li><li>Regularization: In this method, a loss term is added to the cost function which encourages the network to train in ways other than copying the input.</li><li>Denoising: Another way of constraining the network is to add noise to the input and teaching the network how to remove the noise from the data.</li><li>Tuning the Activation Functions: This method involves changing the activation functions of various nodes so that a majority of the nodes are dormant thus effectively reducing the size of the hidden layers.</li></ul><p>The different variations of Auto-encoders are:-</p><ul><li>Denoising Auto-encoder: This type of auto-encoder works on a partially corrupted input and trains to recover the original undistorted image. As mentioned above, this method is an effective way to constrain the network from simply copying the input.</li><li>Sparse Auto-encoder: This type of auto-encoder typically contains more hidden units than the input but only a few are allowed to be active at once. This property is called the sparsity of the network. The sparsity of the network can be controlled by either manually zeroing the required hidden units, tuning the activation functions or by adding a loss term to the cost function.</li><li>Variational Auto-encoder: This type of auto-encoder makes strong assumptions about the distribution of latent variables and uses the Stochastic Gradient Variational Bayes estimator in the training process. It assumes that the data is generated by a Directed Graphical Model and tries to learn an approximation to $q_{\phi}(z|x)$ to the conditional property $q_{\theta}(z|x)$ where $\phi$ and $\theta$ are the parameters of the encoder and the decoder respectively.</li></ul><h1><span id="dae">DAE</span></h1><p>Denoising AutoEncoder（DAE）comes from “Vincent Extracting and composing robust features with denoising autoencoders, 2008”. Its essence is to add noise to the original sample, and the expectation is to use DAE to restore the noise sample to the pure sample.</p><p>DAE is a modification to the autoencoder framework to explicitly integrate robustness to partially destroyed inputs.</p><ul><li>corrupt the initial input x to get a partially destroyed version $\hat{x}$ by means of a Stochastic mapping $\hat{x} - q_D(\hat{x} \mid x)$.</li><li>In experiments, we considered the following corrupting process, parameterized by the desired proportion $v$ of “destruction”: for each input x, a fixed number $vd$ of components are chosen at random, and their value is forced to 0, while the others are left untouched. All information about the chosen components is thus removed from that particuler input pattern, and the autoencoder will be trained to “fill-in” these artificially introduced “blanks”.<img src="/CDAE/5.JPG" alt></li></ul><h1><span id="cdae">CDAE</span></h1><p>CDAE is a model-based CF method for topN recommendation.</p><p>CDAE assumes that whatever user-item interactions are observed are a corrupted version of the user’s full preference set. The model learns latent representations of corrupted user-item preferences that can best reconstruct the full input.</p><p>Contribution:</p><ul><li>propose a new model CDAE, which formulates the topN recommendation problem using the Auto-Encoder framework and learns from corrupted inputs. Compared to related methods, CDAE is novel in both model definition and objective function.</li><li>Demonstrate that CDAE is a generalization of several state-of-the-art methods but with a more flexible structure.</li><li>conduct thorough experiments studying the impact of the choices of different components in CDAE, and show that CDAE outperforms state-of-the-art methods on three real world data sets.</li></ul><p><img src="/CDAE/6.JPG" alt></p><p>Figure 1 shows a sample structure of CDAE. CDAE consists of 3 layers, including the input layer, the hidden layer and the output layer.</p><ol><li>In the input layer, there are in total I + 1 nodes, where each of the first I nodes corresponds to an item, and the last node is a user specific node (the red node in the figure), which means the node and its associated weights are unique for each user $u \in U$ in the data. We refer to the first I nodes as item input nodes, and the last node as user input node. Given the historical feedback.</li><li>There are K nodes in the hidden layer and these nodes are fully connected to the nodes of the input layer. Here K is a predefined constant which is usually much smaller than the size of the input vectors. The hidden layer also has an additional node to model the bias effects (the pink node in the figure).</li><li>In the output layer, there are I nodes representing reconstructions of the input vector yu. The nodes in the output layer are fully connected with nodes in the hidden layer.</li></ol><p>Formally, the inputs of CDAE are the corrupted feedback vector $\hat{y}_u$ which is generated from $p(\hat{y}_u \mid y_u)$ as stated in Equation 9.Intuitively, the non-zero values in $y_u$ are randomly dropped out independently with probability q. The resulting vector $\hat{y}_u$ is still a sparse vector, where the indexes of the non-zero values are a subset of those of the original vector.</p><ul><li>CDAE first maps the input to a latent representations $z_u$:$z_u=h(W^\top\hat{y}_u+V_u+b)$,</li><li>At the output layer, the latent representation is then mapped back to the original input space to reconstruct the input vector. The output value $\hat{y}<em>{ui}$ for node i is computed as follows:$\hat{y}</em>{ui}=f(W^{'\top}_{i}z_u+b^{'}_i)$,</li><li>minimizing the average loss.</li></ul><h1><span id="trust-aware-cdae">Trust-aware CDAE</span></h1><p>This paper utilize CDAE to tackle data sparsity and cold start to learn compact and effective representations from both rating and trust data for top-N recommendation.</p><p>This motivate us to propose the TDAE model, which utilizes Denoising Auto-Encoder model to learn exactly user preferences from both of rating and trust data.</p><h4><span id="motivations">Motivations:</span></h4><ul><li>First, most of them model the trust relationships with shallow model and ignore the high-order interactions among each users’ friends; it is possible for a user to take all the opinions of his friends into account and then come out his own thinking rather than linearly combine all of them.</li><li>Second, the trust relationships are also facing the sparse problem as well as ratings. This may limits the improvement of trust-aware algorithms and make it difficult to utilize deep model to learn high-order information from trust data.</li></ul><h4><span id="contribution">Contribution</span></h4><ul><li>In this paper, we propose a novel deep learning model to learn user preferences from rating and trust data. Toward the big challenge of data sparse for this problem, the TDAE model is built by fusing two denoising autoencoders with a weighted layer, which is used to balance the importance of rating and trust data. This model can also easily be extended for other recommendation tasks with additional information.</li><li>To keep away from overfitting, we further propose a correlative regularization to constraint the learning process. Since we model user preferences in two perspectives, we argue that they can be used to predict each other to a certain degree. This motivate us to propose the Correlative regularization to build relations between the layers in same level. This regularization can efficient improve the effectiveness and robust of TDAE model.</li><li>We conduct comprehensive experiments with two datasets to compare our approach with state-of-the-art algorithms on Top-N recommendation task. There are several works show clearly that Top-N recommendation is more close to real application scenarios than rating prediction. So we adopt ranking-sensitive metrics to evaluate the TDAE model, i.e., MAP and NDCG. The results demonstrate that our model significant outperform other comparisons, and is further improved by incorporating correlative regularization.</li></ul><h4><span id="related-work">Related work</span></h4><ul><li>Trust-aware Recommendation: SocialMF, SoReg, TrustMF, TrustSVD, However, all these methods utilize trust data in shallow level and ignore the factor that trust relationships are very complex.</li><li>Deep Learning for Recommendation: rating-based methods and auxiliary data based methods.</li><li>Topn recommendation:</li></ul><p><img src="/CDAE/7.JPG" alt></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;&lt;span id=&quot;ae-auto-encoders&quot;&gt;AE (auto-encoders)&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;The schematic structure of an autoencoder is as follows:
&lt;img src=&quot;/CDAE/1
      
    
    </summary>
    
      <category term="recommender systems" scheme="http://dinry.github.io/categories/recommender-systems/"/>
    
    
  </entry>
  
  <entry>
    <title>Gumbel-sofmax采样技巧</title>
    <link href="http://dinry.github.io/Gumbel-sofmax/"/>
    <id>http://dinry.github.io/Gumbel-sofmax/</id>
    <published>2019-12-01T02:45:40.000Z</published>
    <updated>2019-12-01T05:24:22.538Z</updated>
    
    <content type="html"><![CDATA[<p>以强化学习为例，假设网络输出的三维向量代表三个动作（前进、停留、后退）在下一步的收益，value=[-10,10,15]，那么下一步我们就会选择收益最大的动作（后退）继续执行，于是输出动作[0,0,1]。选择值最大的作为输出动作，这样做本身没问题，但是在网络中这种取法有个问题是不能计算梯度，也就不能更新网络。</p><h1><span id="softmax采样">softmax采样</span></h1><p>这时通常的做法是加上softmax函数，把向量归一化，这样既能计算梯度，同时值的大小还能表示概率的含义（多项分布）。</p><p>$\pi_k=\frac{e^{x_k}}{\sum_{i=1}^Ke^{x_i}}$</p><p>于是value=[-10,10,15]通过softmax函数后有σ(value)=[0,0.007,0.993]，这样做不会改变动作或者说类别的选取，同时softmax倾向于让最大值的概率显著大于其他值，比如这里15和10经过softmax放缩之后变成了0.993和0.007，这有利于把网络训成一个one-hot输出的形式，这种方式在分类问题中是常用方法。</p><p>但这样就不会体现概率的含义了，因为σ(value)=[0,0.007,0.993]与σ(value)=[0.3,0.2,0.5]在类别选取的结果看来没有任何差别，都是选择第三个类别，但是从概率意义上讲差别是巨大的。</p><p>很直接的方法是依概率采样完事了，比如直接用np.random.choice函数依照概率生成样本值，这样概率就有意义了。所以，经典的采样方法就是用softmax函数加上轮盘赌方法（np.random.choice）。但这样还是会有个问题，这种方式怎么计算梯度？不能计算梯度怎么更新网络？</p><p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">def sample_with_softmax(logits, size):</span><br><span class="line"></span><br><span class="line"># logits为输入数据</span><br><span class="line"></span><br><span class="line"># size为采样数</span><br><span class="line"></span><br><span class="line">    pro = softmax(logits)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> np.random.choice(len(logits), size, p=pro)</span><br></pre></td></tr></table></figure></p><h1><span id="基于gumbel-max的采样">基于gumbel-max的采样</span></h1><p>对于K维概率向量 $\alpha$,对 $\alpha$对应的离散变量 $x_i=log(\alpha_i)$ 添加Gumbel噪声，再取样:</p><p>$x=argmax_{i}(log(\alpha_i)+G_i)$</p><p>其中，$G_i$ 是独立同分布的标准Gumbel分布的随机变量, 标准Gumbel分布的CDF为 $F(x)=e^{-e^{-x}}$, 所以 $G_i$ 可以通过Gumbel分布求逆从均匀分布生成，即 $G_i=-log(-log(U_i)), U_i - U(0,1)$, 这样就得到了基于gumbel-max的采样过程：</p><ul><li>对于网络输出的一个K维向量v,生成K个服从均匀分布U(0,1)的独立样本 $\gamma_1,...,\gamma_K$;</li><li>通过 $G_i$ 计算得到 $G_i$;</li><li>对应相加得到新的值向量</li><li>取最大值作为最终的类别<figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">def sample_with_gumbel_noise(logits, size):</span><br><span class="line"></span><br><span class="line">    noise = sample_gumbel((size, len(logits)))    # 产生gumbel noise</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> np.argmax(logits + noise, axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure></li></ul><h1><span id="基于gumbel-softmax的采样">基于gumbel-softmax的采样</span></h1><p>如果仅仅是提供一种常规 softmax 采样的替代方案， gumbel 分布似乎应用价值并不大。幸运的是，我们可以利用 gumbel 实现多项分布采样的 reparameterization（再参数化）。</p><p>在VAE中，假设隐变量（latent variables）服从标准正态分布。而现在，利用 gumbel-softmax 技巧，我们可以将隐变量建模为服从离散的多项分布。在前面的两种方法中，random.choice和argmax注定了这两种方法不可导，但我们可以将后一种方法中的argmax soft化，变为softmax。</p><p>$x=softmax((log(\alpha_i)+G_i)/temperature)$</p><p>temperature 是在大于零的参数，它控制着 softmax 的 soft 程度。温度越高，生成的分布越平滑；温度越低，生成的分布越接近离散的 one-hot 分布。训练中，可以通过逐渐降低温度，以逐步逼近真实的离散分布。</p><p>这样就得到了基于gumbel-max的采样过程：</p><ul><li>对于网络输出的一个K维向量v,生成K个服从均匀分布U(0,1)的独立样本 $\gamma_1,...,\gamma_K$;</li><li>通过 $G_i$ 计算得到 $G_i$;</li><li>对应相加得到新的值向量</li><li>通过softmax函数计算概率大小得到最终的类别。</li></ul><p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">def differentiable_gumble_sample(logits, temperature=<span class="number">1</span>):</span><br><span class="line"></span><br><span class="line">    noise = tf.random_uniform(tf.shape(logits), seed=<span class="number">11</span>)</span><br><span class="line"></span><br><span class="line">    logits_with_noise = logits - tf.log(-tf.log(noise))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> tf.nn.softmax(logits_with_noise / temperature)</span><br></pre></td></tr></table></figure></p><h1><span id="gumbel分布">Gumbel分布</span></h1><p>首先，我们介绍一样何为gumbel分布，gumbel分布是一种极值型分布。举例而言，假设一天内每次的喝水量为一个随机变量，它可能服从某个概率分布，记下这一天内喝的10次水的量并取最大的一个作为当天的喝水量值。显然，每天的喝水量值也是一个随机变量，并且它的概率分布即为 Gumbel 分布。实际上，只要是指数族分布，它的极值分布都服从Gumbel分布。</p><p>他的概率密度函数：</p><p>$f(s;\mu, \beta)=e^{-Z-e^{-Z}}, Z=\frac{X-\mu}{\beta}$</p><p>公式中，$\mu$ 是位置系数（Gumbel 分布的众数是 $\mu$），$\beta$ 是尺度系数（Gumbel 分布的方差是 $\frac{\pi^2}{6}\beta^2$）。<figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">def gumbel_pdf(x, mu=<span class="number">0</span>, beta=<span class="number">1</span>):</span><br><span class="line"></span><br><span class="line">    z = (x - mu) / beta</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> np.exp(-z - np.exp(-z)) / beta</span><br></pre></td></tr></table></figure></p><h1><span id="为什么方法一与方法三生成一样的效果">为什么方法一与方法三生成一样的效果？</span></h1><p>先定义一个多项分布，作出真实的概率密度图。再通过采样的方式比较各种方法的效果。这里定义了一个8类别的多项分布，其真实的密度函数如下左图。首先我们直接根据真实的分布利用np.random.choice函数采样对比效果（实现代码放在文末）<img src="/Gumbel-softmax/1.JPG" alt>左图为真实概率分布，右图为采用np.random.choice函数采样的结果（采样次数为1000）。可见效果还是非常好的，要是没有不能求梯度这个问题，直接从原分布采样是再好不过的。接着通过前述的方法添加Gumbel噪声采样，同时也添加正态分布和均匀分布的噪声作对比。（基于gumbel-max的采样）<img src="/Gumbel-softmax/2.JPG" alt>可以明显看到Gumbel噪声的采样效果是最好的，正态分布其次，均匀分布最差。也就是说用Gumbel分布的样本点最接近真实分布的样本。<img src="/Gumbel-softmax/3.JPG" alt>最后，我们基于gumbel-softmax做采样，左图设置temperature=0.1，经过softmax函数后得到的概率分布接近one-hot分布，用此概率分布对分类求期望值，得到结果为左图，可以较好地逼近方法一的采样结果；右图设置temperature=5，经过softmax函数后得到的概率分布接近均匀分布，再对分类求期望值，得到的结果集中在类别3、 4（中间的类别）。这和gumbel-softmax具备的性质是一致的，temperature控制着softmax的soft程度，温度越高，生成的分布越平滑（接近这里的均匀分布）；温度越低，生成的分布越接近离散的one-hot分布。因此，训练时可以逐渐降低温度，以逐步逼近真实的离散分布。（基于gumbel-softmax的采样）</p><p>到此为此，我们也算用一组实验去解释了为什么方法二、方法三是可行的。具体的代码放在文末了，感兴趣的可以研究一下。</p><h1><span id="为什么使用gumbel分布就可以逼近多项分布采样">为什么使用Gumbel分布就可以逼近多项分布采样？</span></h1><p>为什么它可以有这样的效果？为什么添加gumbel噪声就可以近似范畴分布（category distribution）采样。</p><p>我们来考虑一个问题，假设一共有K个类别，那么第k个类别恰好是最大的概率是多少？</p><p>对于一个K维的输出向量，每个维度的值记为,通过softmax函数可得，取到每个维度的概率为：</p><p>$\pi_k=\frac{e^{x_k}}{\sum_{i=1}^Ke^{x_i}}$</p><p>设 $x_k=log \alpha_k$，可以看出 $\alpha_k$即 $\pi_k$，这是直接用softmax得到的概率密度函数，它也可以换一种方式去说，对每个 $x_k$ 添加独立的标准Gumbel分布(尺度参数为1，位置参数为0)噪声，并选择值最大的维度作为输出，得到的概率密度同样为$\alpha_k$。</p><h1><span id="为什么再参数化reparameterization-tricks就可以变得可导">为什么再参数化(reparameterization tricks)就可以变得可导？</span></h1><p>reparameterization tricks的思想是说如果我们能把一个复杂变量用一个标准变量来表示，比如 $Z=f(\gamma)$, 其中 $\gamma$ 服从N（0，1）， 那么我们就可以用$\gamma$这个变量取代z。</p><p>这样做是有好处的，一方面在更新梯度时可以将随机变量提取出来，不影响对参数的更新；另一方面假如我们要依据 $p(z;\theta)$ 采样，然后再利用采样处的梯度修正p，这样两次的误差就会叠加，但现在只需要从一个分布非常稳定的random seed的分布中采样，比如N(0,1)所以noise小得多。</p><h1><span id="code">code</span></h1><p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> scipy.optimize <span class="keyword">import</span> curve_fit</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">n_cats = <span class="number">8</span></span><br><span class="line"></span><br><span class="line">n_samples = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line">cats = np.arange(n_cats)</span><br><span class="line"></span><br><span class="line">probs = np.random.randint(low=<span class="number">1</span>, high=<span class="number">20</span>, size=n_cats)</span><br><span class="line"></span><br><span class="line">probs = probs / sum(probs)</span><br><span class="line"></span><br><span class="line">logits = np.log(probs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def plot_probs():   # 真实概率分布</span><br><span class="line"></span><br><span class="line">    plt.bar(cats, probs)</span><br><span class="line"></span><br><span class="line">    plt.xlabel(<span class="string">"Category"</span>)</span><br><span class="line"></span><br><span class="line">    plt.ylabel(<span class="string">"Original Probability"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def plot_estimated_probs(samples,ylabel=<span class="string">''</span>):</span><br><span class="line"></span><br><span class="line">    n_cats = np.max(samples)+<span class="number">1</span></span><br><span class="line"></span><br><span class="line">    estd_probs,_,_ = plt.hist(samples,bins=np.arange(n_cats+<span class="number">1</span>),align=<span class="string">'left'</span>,edgecolor=<span class="string">'white'</span>)</span><br><span class="line"></span><br><span class="line">    plt.xlabel(<span class="string">'Category'</span>)</span><br><span class="line"></span><br><span class="line">    plt.ylabel(ylabel+<span class="string">'Estimated probability'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> estd_probs</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def print_probs(probs):</span><br><span class="line"></span><br><span class="line">    print(probs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">samples = np.random.choice(cats,p=probs,size=n_samples) # 依概率采样</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">plot_probs()</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">estd_probs = plot_estimated_probs(samples)</span><br><span class="line"></span><br><span class="line">plt.tight_layout() # 紧凑显示图片</span><br><span class="line"></span><br><span class="line">plt.savefig(<span class="string">'/home/zhumingchao/PycharmProjects/matplot/gumbel1'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(<span class="string">'Original probabilities:\t'</span>,end=<span class="string">''</span>)</span><br><span class="line"></span><br><span class="line">print_probs(probs)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'Estimated probabilities:\t'</span>,end=<span class="string">''</span>)</span><br><span class="line"></span><br><span class="line">print_probs(estd_probs)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">######################################</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def sample_gumbel(logits):</span><br><span class="line"></span><br><span class="line">    noise = np.random.gumbel(size=len(logits))</span><br><span class="line"></span><br><span class="line">    sample = np.argmax(logits+noise)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> sample</span><br><span class="line"></span><br><span class="line">gumbel_samples = [sample_gumbel(logits) <span class="keyword">for</span> _ <span class="keyword">in</span> range(n_samples)]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def sample_uniform(logits):</span><br><span class="line"></span><br><span class="line">    noise = np.random.uniform(size=len(logits))</span><br><span class="line"></span><br><span class="line">    sample = np.argmax(logits+noise)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> sample</span><br><span class="line"></span><br><span class="line">uniform_samples = [sample_uniform(logits) <span class="keyword">for</span> _ <span class="keyword">in</span> range(n_samples)]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def sample_normal(logits):</span><br><span class="line"></span><br><span class="line">    noise = np.random.normal(size=len(logits))</span><br><span class="line"></span><br><span class="line">    sample = np.argmax(logits+noise)</span><br><span class="line"></span><br><span class="line">    # print('old',sample)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> sample</span><br><span class="line"></span><br><span class="line">normal_samples = [sample_normal(logits) <span class="keyword">for</span> _ <span class="keyword">in</span> range(n_samples)]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">4</span>))</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">4</span>,<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">plot_probs()</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">4</span>,<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">gumbel_estd_probs = plot_estimated_probs(gumbel_samples,<span class="string">'Gumbel '</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">4</span>,<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">normal_estd_probs = plot_estimated_probs(normal_samples,<span class="string">'Normal '</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">4</span>,<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">uniform_estd_probs = plot_estimated_probs(uniform_samples,<span class="string">'Uniform '</span>)</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line"></span><br><span class="line">plt.savefig(<span class="string">'/home/zhumingchao/PycharmProjects/matplot/gumbel2'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(<span class="string">'Original probabilities:\t'</span>,end=<span class="string">''</span>)</span><br><span class="line"></span><br><span class="line">print_probs(probs)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'Gumbel Estimated probabilities:\t'</span>,end=<span class="string">''</span>)</span><br><span class="line"></span><br><span class="line">print_probs(gumbel_estd_probs)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'Normal Estimated probabilities:\t'</span>,end=<span class="string">''</span>)</span><br><span class="line"></span><br><span class="line">print_probs(normal_estd_probs)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'Uniform Estimated probabilities:\t'</span>,end=<span class="string">''</span>)</span><br><span class="line"></span><br><span class="line">print_probs(uniform_estd_probs)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">#######################################</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def softmax(logits):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> np.exp(logits)/np.sum(np.exp(logits))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def differentiable_sample_1(logits, cats_range, temperature=<span class="number">.1</span>):</span><br><span class="line"></span><br><span class="line">    noise = np.random.gumbel(size=len(logits))</span><br><span class="line"></span><br><span class="line">    logits_with_noise = softmax((logits+noise)/temperature)</span><br><span class="line"></span><br><span class="line">    # print(logits_with_noise)</span><br><span class="line"></span><br><span class="line">    sample = np.sum(logits_with_noise*cats_range)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> sample</span><br><span class="line"></span><br><span class="line">differentiable_samples_1 = [differentiable_sample_1(logits,np.arange(n_cats)) <span class="keyword">for</span> _ <span class="keyword">in</span> range(n_samples)]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def differentiable_sample_2(logits, cats_range, temperature=<span class="number">5</span>):</span><br><span class="line"></span><br><span class="line">    noise = np.random.gumbel(size=len(logits))</span><br><span class="line"></span><br><span class="line">    logits_with_noise = softmax((logits+noise)/temperature)</span><br><span class="line"></span><br><span class="line">    # print(logits_with_noise)</span><br><span class="line"></span><br><span class="line">    sample = np.sum(logits_with_noise*cats_range)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> sample</span><br><span class="line"></span><br><span class="line">differentiable_samples_2 = [differentiable_sample_2(logits,np.arange(n_cats)) <span class="keyword">for</span> _ <span class="keyword">in</span> range(n_samples)]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def plot_estimated_probs_(samples,ylabel=<span class="string">''</span>):</span><br><span class="line"></span><br><span class="line">    samples = np.rint(samples)</span><br><span class="line"></span><br><span class="line">    n_cats = np.max(samples)+<span class="number">1</span></span><br><span class="line"></span><br><span class="line">    estd_probs,_,_ = plt.hist(samples,bins=np.arange(n_cats+<span class="number">1</span>),align=<span class="string">'left'</span>,edgecolor=<span class="string">'white'</span>)</span><br><span class="line"></span><br><span class="line">    plt.xlabel(<span class="string">'Category'</span>)</span><br><span class="line"></span><br><span class="line">    plt.ylabel(ylabel+<span class="string">'Estimated probability'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> estd_probs</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>,<span class="number">4</span>))</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">gumbelsoft_estd_probs_1 = plot_estimated_probs_(differentiable_samples_1,<span class="string">'Gumbel softmax'</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">gumbelsoft_estd_probs_2 = plot_estimated_probs_(differentiable_samples_2,<span class="string">'Gumbel softmax'</span>)</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line"></span><br><span class="line">plt.savefig(<span class="string">'/home/zhumingchao/PycharmProjects/matplot/gumbel3'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(<span class="string">'Gumbel Softmax Estimated probabilities:\t'</span>,end=<span class="string">''</span>)</span><br><span class="line"></span><br><span class="line">print_probs(gumbelsoft_estd_probs_1)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p><p>来自 https://blog.csdn.net/weixin_40255337/article/details/83303702</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;以强化学习为例，假设网络输出的三维向量代表三个动作（前进、停留、后退）在下一步的收益，value=[-10,10,15]，那么下一步我们就会选择收益最大的动作（后退）继续执行，于是输出动作[0,0,1]。选择值最大的作为输出动作，这样做本身没问题，但是在网络中这种取法有个问
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>entropy</title>
    <link href="http://dinry.github.io/entropy/"/>
    <id>http://dinry.github.io/entropy/</id>
    <published>2019-11-29T01:45:24.000Z</published>
    <updated>2019-11-29T01:45:24.273Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>GANs notebook</title>
    <link href="http://dinry.github.io/notebook/"/>
    <id>http://dinry.github.io/notebook/</id>
    <published>2019-11-28T02:13:17.000Z</published>
    <updated>2019-11-28T02:32:33.744Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="初识gan">初识GAN</span></h1><ol><li>生成模型与判别模型理解对抗网络，首先要了解生成模型和判别模型。判别模型比较好理解，就像分类一样，有一个判别界限，通过这个判别界限去区分样本。从概率角度分析就是获得样本x属于类别y的概率，是一个条件概率$P（y \mid x)$。而生成模型是需要在整个条件内去产生数据的分布，就像高斯分布一样，需要去拟合整个分布，从概率角度分析就是样本x在整个分布中的产生的概率，即联合概率$P（xy）$。</li></ol><p>原文链接：https://blog.csdn.net/a312863063/article/details/83551569</p><ol start="2"><li>对抗网络思想理解了生成模型和判别模型后，再来理解对抗网络就很直接了，对抗网络只是提出了一种网络结构，总体来说， GANs简单的想法就是用两个模型，一个生成模型，一个判别模型。判别模型用于判断一个给定的图片是不是真实的图片（从数据集里获取的图片），生成模型的任务是去创造一个看起来像真的图片一样的图片。而在开始的时候这两个模型都是没有经过训练的，这两个模型一起对抗训练，生成模型产生一张图片去欺骗判别模型，然后判别模型去判断这张图片是真是假，最终在这两个模型训练的过程中，两个模型的能力越来越强，最终达到稳态。（本书仅介绍GANs在计算机视觉方面的应用，但是GANs的用途很广，不单单是图像，其他方面，譬如文本、语音，或者任何只要含有规律的数据合成，都能用GANs实现。）</li></ol><h1><span id="gans-分类">GANs 分类</span></h1><h2><span id="物理分类">物理分类</span></h2><p>(1)结构变体：eg. cyclegan, stackgan...</p><p>(2)loss variant: WGAN, EBGAN...</p><h2><span id="应用分类">应用分类</span></h2><p>(1)CV</p><p>(2)NLP</p><p>(3)ir</p><h1><span id></span></h1>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;&lt;span id=&quot;初识gan&quot;&gt;初识GAN&lt;/span&gt;&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;生成模型与判别模型
理解对抗网络，首先要了解生成模型和判别模型。判别模型比较好理解，就像分类一样，有一个判别界限，通过这个判别界限去区分样本。从概率角度分析就是获得样本x属于类别y的概
      
    
    </summary>
    
      <category term="deep learning" scheme="http://dinry.github.io/categories/deep-learning/"/>
    
    
      <category term="gans" scheme="http://dinry.github.io/tags/gans/"/>
    
  </entry>
  
  <entry>
    <title>CnGAN  Generative Adversarial Networks for Cross-network user preference generation for non-overlapped users</title>
    <link href="http://dinry.github.io/CnGAN/"/>
    <id>http://dinry.github.io/CnGAN/</id>
    <published>2019-11-02T06:14:12.000Z</published>
    <updated>2019-11-04T10:48:36.188Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="intro">Intro</span></h1><p>cross-network Recommendation(are more robust against cold-start and data sparsity issues)</p><h2><span id="problem">problem</span></h2><p>However, despite the growing success of cross-network recommender solutions, the majority of existing solutions can only be applied to users that exist in multiple networks (overlapped users). The remaining non-overlapped users, which form the majority are unable to enjoy the benefits of cross-network solutions.</p><h2><span id="contribution">contribution</span></h2><ul><li>To the best of our knowledge, this is the first attempt to apply a GAN based model to generate missing source network preferences for non-overlapped users.</li><li>We propose CnGAN, a novel GAN based model which includes a novel content loss function and user-based pairwise loss function for the generator and recommender tasks.</li><li>We carry out extensive experiments to demonstrate the effectiveness of CnGAN to conduct recommendations for non-overlapped users and improve the overall quality of recommendations compared to state-of-the-art methods.</li></ul><h1><span id="model">model</span></h1>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;&lt;span id=&quot;intro&quot;&gt;Intro&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;cross-network Recommendation(are more robust against cold-start and data sparsity issues)&lt;/p&gt;
&lt;h2&gt;
      
    
    </summary>
    
      <category term="recommender systems" scheme="http://dinry.github.io/categories/recommender-systems/"/>
    
    
  </entry>
  
  <entry>
    <title>Deep Learning Based Recommender System A Survey and New Perspectives</title>
    <link href="http://dinry.github.io/Survey/"/>
    <id>http://dinry.github.io/Survey/</id>
    <published>2019-11-01T01:33:38.000Z</published>
    <updated>2019-11-04T10:46:42.543Z</updated>
    
    <content type="html"><![CDATA[<p>This article aimsto provide a comprehensive review of recent research efforts on deep learning-based recommender systems.</p><h1><span id="intro">Intro</span></h1><ul><li>We conduct a comprehensive review for recommendation models based on deep learning techniques and propose a classification scheme to position and organize the current work;</li><li>we provide an overview and summary for the state of the art;</li><li>we discuss the challenges and open issues, and identify the new trends and future directions in this research field to share the vision and expand the horizons of deep learning-based recommender systems research.</li></ul><h1><span id="overview-of-recommender-systems-and-deep-learning">overview of recommender systems and deep Learning</span></h1><ul><li>Introduction to the basic terminology and concepts regarding recommender systems and deep learning techniques.</li><li>The reasons and motivations of introducing deep neural networks into recommender systems.</li></ul><h2><span id="recommender">Recommender</span></h2><ul><li>CF</li><li>CB</li><li>Hrbrid</li></ul><h2><span id="deep-learning-techniques">Deep learning techniques</span></h2><p>In this subsection, we clarify a diverse array of architectural paradigms that are closely related to this survey.</p><ul><li>MLP(The Multilayer Perceptron): a feed-forward neural network with multiple (one or more) hidden layers between the input and output layers.</li><li>AE(An Autoencoder):an unsupervised model attempting to reconstruct its input data in the output layer</li><li>CNN:a special kind of feedforward neural network with convolution layers and pooling operations. It can capture the global and local features and significantly enhances efficiency and accuracy. It performs well in processing data with grid-like topology.</li><li>RNN: is suitable for modelling sequential data. Unlike the feedforward neural network, there are loops and memories in RNN to remember former computations. Variants such as Long Short Term Memory (LSTM) and Gated Recurrent Unit (GRU) networks are often deployed in practice to overcome the vanishing gradient problem.</li><li>RBM：a two-layer neural network consisting of avisible layer and a hidden layer.</li></ul><h2><span id="why-deep-neural-networks-for-recommendation">Why Deep Neural Networks for Recommendation?</span></h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;This article aims
to provide a comprehensive review of recent research efforts on deep learning-based recommender systems.&lt;/p&gt;
&lt;h1&gt;&lt;span 
      
    
    </summary>
    
      <category term="recommender systems" scheme="http://dinry.github.io/categories/recommender-systems/"/>
    
    
  </entry>
  
  <entry>
    <title>RippleNet  Propagating User Preferences on the Knowledge Graph for Recommender Systems</title>
    <link href="http://dinry.github.io/ripplenet/"/>
    <id>http://dinry.github.io/ripplenet/</id>
    <published>2019-10-30T02:41:20.000Z</published>
    <updated>2019-11-04T10:47:23.099Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="introduction">introduction</span></h1><p>CF--&gt;sparsity, the cold start--&gt;side information--&gt;knowledge graph</p><h2><span id="kgs-strength">KG's strength</span></h2><ul><li>KG introduces semantic relatedness among items, which can help find their latent connections and improve the precision of recommended items;</li><li>KG consists of relations with various types, which is helpful for extending a user’s interests reasonably and increasing the diversity of recommended items;</li><li>KG connects a user’s historical records andthe recommended ones, thereby bringing explainability to recommendersystems.</li></ul><h2><span id="kgs-categories">KG's categories:</span></h2><ol><li>Embedding-based methods: DKN, CKE, SHINE------Embedding-based methods show high flexibility in utilizing KGto assist recommender systems, but the adopted KGE algorithmsin these methods are usually more suitable for in-graph applicationssuch as link prediction than for recommendation, thusthe learned entity embeddings are less intuitive and effective tocharacterize inter-item relations.</li><li>Path-based methods: explorethe various patterns of connections among items in KG toprovide additional guidance for recommendations. PER, Meta-GraphBased Recommendation.------Path-basedmethods make use of KG in a more natural and intuitive way, butthey rely heavily on manually designed meta-paths, which is hardto optimize in practice. Another concern is that it is impossibleto design hand-crafted meta-paths in certain scenarios (e.g., newsrecommendation) where entities and relations are not within onedomain.</li></ol><h2><span id="ripplenetctr-prediction">RippleNet(CTR prediction)</span></h2><p>The major differencebetween RippleNet and existing literature is that RippleNet combinesthe advantages of the above mentioned two types of methods:(1) RippleNet incorporates the KGE methods into recommendation naturally by preference propagation; (2) RippleNet can automaticallydiscover possible paths from an item in a user’s history to acandidate item, without any sort of hand-crafted design.</p><h2><span id="contribution">contribution</span></h2><ul><li>To the best of our knowledge, this is the first work to combineembedding-based and path-based methods in KG-awarerecommendation.</li><li>We propose RippleNet, an end-to-end framework utilizingKG to assist recommender systems. RippleNet automaticallydiscovers users’ hierarchical potential interests by iterativelypropagating users’ preferences in the KG.</li><li>We conduct experiments on three real-world recommendationscenarios, and the results prove the efficacy</li></ul><p><img src="/ripplenet/1.JPG" alt></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;&lt;span id=&quot;introduction&quot;&gt;introduction&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;CF--&amp;gt;sparsity, the cold start--&amp;gt;side information--&amp;gt;knowledge graph&lt;/p&gt;
&lt;h2&gt;
      
    
    </summary>
    
      <category term="recommender systems" scheme="http://dinry.github.io/categories/recommender-systems/"/>
    
    
      <category term="KG+rec" scheme="http://dinry.github.io/tags/KG-rec/"/>
    
  </entry>
  
  <entry>
    <title>Algorithms for Non-negative Matrix factorization</title>
    <link href="http://dinry.github.io/NMF/"/>
    <id>http://dinry.github.io/NMF/</id>
    <published>2019-10-29T04:56:19.000Z</published>
    <updated>2019-10-31T10:44:39.485Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="recommender systems" scheme="http://dinry.github.io/categories/recommender-systems/"/>
    
    
      <category term="MF" scheme="http://dinry.github.io/tags/MF/"/>
    
  </entry>
  
  <entry>
    <title>matrix factorization techniques for recommender systems</title>
    <link href="http://dinry.github.io/CF-MF/"/>
    <id>http://dinry.github.io/CF-MF/</id>
    <published>2019-10-28T01:42:31.000Z</published>
    <updated>2019-10-29T04:47:33.881Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="three-strength-of-mf-conclusion">Three strength of MF (conclusion):</span></h1><ul><li>combining good scalability with predictive accuracy.</li><li>offering much flexibility for modeling various rela-life situation.</li><li>allowing incorporation of additional information.</li><li>lower space complexity.</li></ul><h1><span id="recommender-system-strategies">recommender system strategies</span></h1><ol><li>content-based filtering: which creates a profile for each user or product to characterize its nature. However, it requires gathering external information that miht not be available or easy to collect.</li><li>collaborative filtering: which relies only on past user behaviors (previous transactions or ratings)-without requiring the creation of explicit profiles. Although it is domain free and more accurate than content-based filtering, it suffers from the cold start problem, due to its inability to address the system's new products and users.</li></ol><h1><span id="cf">CF</span></h1><ol><li>the neighborhood methods: computing the relatioships between items or, between users.</li></ol><ul><li>item-based CF: evaluates a user's preference for an item based on ratings of &quot;neighboring&quot; items(tend to get similar ratings when rated by the same user) by the same user</li><li>user-based CF:</li></ul><ol start="2"><li>the latent factor model: tries to explain the ratings by characterizing both items and users on, say, 20 to 100 factors inferred from the ratings patterns.</li></ol><h1><span id="mf">MF</span></h1><p>Some of the most successful realization of latent factor models are based on MF, which characterizes both items and users by vectors of factors infered from item rating patterns( combining good scalabilitywith predictive accuracy and offer flexibility).</p><p>Explicit feedback comprises a sparse matrix. Implicit feedback usually represents a densely filled matrix.</p><h1><span id="a-basic-mf-model">A basic MF model</span></h1><p>Matrix factorization models map both users and itemsto a joint latent factor space of dimensionality $f$, such thatuser-item interactions are modeled as inner products inthat space. Accordingly, each item $i$ is associated with a vector $q_i \in \mathbb{R}^f$, and each user $u$ is associatedwith a vector $p_u \in \mathbb{R}^f$. For a given item$i$, the elements of $q_i$ measure the extent towhich the item possesses those factors,positive or negative. For a given user $u$,the elements of $p_u$ measure the extent ofinterest the user has in items that are highon the corresponding factors, again, positiveor negative. The resulting dot product,$q_i^\top p_u$, captures the interaction between user$u$ and item $i$—the user’s overall interest inthe item’s characteristics.</p><p>loss: $min \sum_{(u,i) \in K}(r_{ui}-q_i^\top p_u)^2+\lambda(\mid \mid q_i \mid \mid^2+\mid \mid p_u \mid \mid^2)$</p><h1><span id="learning-algorithms">learning algorithms</span></h1><ul><li><p>stochastic gradient descent</p></li><li><p>Alternating least squares(ALS)</p></li></ul><h1><span id="adding-biases">Adding biases</span></h1><p>$q_i^\top p_u$ tries to capture the interactions between users and items that produce the different rating values. However, much of the observed variation in rating values is due to effects associated with either users or items, known as biases or intercepts, independent of any interactions.</p><p>For example, CF data exhibits large systematic tendencies for some users to give higher ratings than others, and for some items to receive higher ratings than others. Thus, it is unwise to explain the full rating value by an interaction of the form $q_i^\top p_u$. Instead, the system tries to identify the portion of these values that individual user or item biases can explain. A first-order approximation of the bias involved in rating $b_{ui}=\mu +b_i +b_u$ accounts for the user and item effects.</p><p>loss: $min \sum_{(u,i) \in K}(r_{ui}-\mu-b_u-b_i-q_i^\top p_u)^2+\lambda(\mid \mid q_i \mid \mid^2+\mid \mid p_u \mid \mid^2+b_u^2+b_i^2)$</p><h1><span id="additional-input-sources">Additional input sources</span></h1><p>A way to relieve cold start problem is to incorporate additional sources of information about the users.</p><p>$\hat{r}<em>{ui}=\mu+b_i+b_u+q_i^\top[p_u+\mid N(u) \mid^{-0.5}\sum</em>{i \in N(u)}x_i+\sum_{a \in A(u)}y_a]$</p><h1><span id="temporal-dynamics">temporal dynamics</span></h1><p>preference changes over time.</p><p>$\hat{r}_{ui}(t)=\mu+b_i(t)+b_u(t)+q_i^\top p_u(t)$</p><h1><span id="inputs-with-varying-confidence-levels">inputs with varying confidence levels</span></h1><p>In several setups, not all observed ratings deserve the same weight or confidence.</p><p>$min \sum_{(u,i) \in K}c_{ui}(r_{ui}-\mu-b_u-b_i-q_i^\top p_u)^2+\lambda(\mid \mid q_i \mid \mid^2+\mid \mid p_u \mid \mid^2+b_u^2+b_i^2)$</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;&lt;span id=&quot;three-strength-of-mf-conclusion&quot;&gt;Three strength of MF (conclusion):&lt;/span&gt;&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;combining good scalability with predi
      
    
    </summary>
    
      <category term="recommender systems" scheme="http://dinry.github.io/categories/recommender-systems/"/>
    
    
      <category term="MF" scheme="http://dinry.github.io/tags/MF/"/>
    
  </entry>
  
  <entry>
    <title>推荐系统经典论文</title>
    <link href="http://dinry.github.io/recsys-paper/"/>
    <id>http://dinry.github.io/recsys-paper/</id>
    <published>2019-10-28T01:34:37.000Z</published>
    <updated>2019-10-28T01:41:44.749Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="综述类">综述类:</span></h1><p>1、Towards theNext Generation of Recommender Systems: A Survey of the State-of-the-Art andPossible Extensions。最经典的推荐算法综述</p><p>2、Collaborative Filtering Recommender Systems. JB Schafer 关于协同过滤最经典的综述</p><p>3、Hybrid Recommender Systems: Survey and Experiments</p><p>4、项亮的博士论文《动态推荐系统关键技术研究》</p><p>5、个性化推荐系统的研究进展.周涛等</p><p>6、Recommender systems L Lü, M Medo, CH Yeung, YC Zhang, ZK Zhang, T ZhouPhysics Reports 519 (1), 1-49 （https://arxiv.org/abs/1202.1112）个性化推荐系统评价方法综述.周涛等</p><h1><span id="协同过滤">协同过滤：</span></h1><p>1.matrix factorization techniques for recommender systems. Y Koren</p><p>2.Using collaborative filtering to weave an information Tapestry. David Goldberg （协同过滤第一次被提出）</p><p>3.Item-Based Collaborative Filtering Recommendation Algorithms. Badrul Sarwar , George Karypis, Joseph Konstan .etl</p><p>4.Application of Dimensionality Reduction in Recommender System – A Case Study. Badrul M. Sarwar, George Karypis, Joseph A. Konstan etl</p><p>5.Probabilistic Memory-Based Collaborative Filtering. Kai Yu, Anton Schwaighofer, Volker Tresp, Xiaowei Xu,and Hans-Peter Kriegel</p><p>6.Recommendation systems:a probabilistic analysis. Ravi Kumar Prabhakar Raghavan.etl</p><p>7.Amazon.com recommendations: item-to-item collaborative filtering. Greg Linden, Brent Smith, and Jeremy York</p><p>8.Evaluation of Item-Based Top- N Recommendation Algorithms. George Karypis</p><p>9.Probabilistic Matrix Factorization. Ruslan Salakhutdinov</p><p>10.Tensor Decompositions,Alternating Least Squares and other Tales. Pierre Comon, Xavier Luciani, André De Almeida</p><h1><span id="基于内容的推荐">基于内容的推荐：</span></h1><p>1.Content-Based Recommendation Systems. Michael J. Pazzani and Daniel Billsus</p><h1><span id="基于标签的推荐">基于标签的推荐：</span></h1><p>1.Tag-Aware Recommender Systems: A State-of-the-Art Survey. Zi-Ke Zhang(张子柯), Tao Zhou(周 涛), and Yi-Cheng Zhang(张翼成)</p><h1><span id="推荐评估指标">推荐评估指标：</span></h1><p>1、推荐系统评价指标综述. 朱郁筱，吕琳媛</p><p>2、Accurate is not always good：How Accuacy Metrics have hurt Recommender Systems</p><p>3、Evaluating Recommendation Systems. Guy Shani and Asela Gunawardana</p><p>4、Evaluating Collaborative Filtering Recommender Systems. JL Herlocker</p><h1><span id="推荐多样性和新颖性">推荐多样性和新颖性：</span></h1><p>Improving recommendation lists through topic diversification. Cai-Nicolas ZieglerSean M. McNee, Joseph A.Konstan,Georg Lausen</p><p>Fusion-based Recommender System for Improving Serendipity</p><p>Maximizing Aggregate Recommendation Diversity：A Graph-Theoretic Approach</p><p>The Oblivion Problem：Exploiting forgotten items to improve Recommendation diversity</p><p>A Framework for Recommending Collections</p><p>Improving Recommendation Diversity. Keith Bradley and Barry Smyth</p><h1><span id="推荐系统中的隐私性保护">推荐系统中的隐私性保护：</span></h1><p>1、Collaborative Filtering with Privacy. John Canny</p><p>2、Do You Trust Your Recommendations? An Exploration Of Security and Privacy Issues in Recommender Systems. Shyong K “Tony” Lam, Dan Frankowski, and John Ried.</p><p>3、Privacy-Enhanced Personalization. Alfred Kobsa.etl</p><p>4、Differentially Private Recommender Systems：Building Privacy into theNetflix Prize Contenders. Frank McSherry and Ilya Mironov Microsoft Research,Silicon Valley Campus</p><p>5、When being Weak is Brave: Privacy Issues in Recommender Systems. Naren Ramakrishnan, Benjamin J. Keller,and Batul J. Mirza</p><h1><span id="推荐冷启动问题">推荐冷启动问题：</span></h1><p>1.Tied Boltzmann Machines for Cold Start Recommendations. Asela Gunawardana.etl</p><p>2.Pairwise Preference Regression for Cold-start Recommendation. Seung-Taek Park, Wei Chu</p><p>3.Addressing Cold-Start Problem in Recommendation Systems. Xuan Nhat Lam.etl</p><p>4.Methods and Metrics for Cold-Start Recommendations. Andrew I. Schein, Alexandrin P opescul, Lyle H. U ngar</p><p>bandit(老虎机算法,可缓解冷启动问题):</p><p>1、Bandits and Recommender Systems. Jeremie Mary, Romaric Gaudel, Philippe Preux</p><p>2、Multi-Armed Bandit Algorithms and Empirical Evaluation</p><h1><span id="基于社交网络的推荐">基于社交网络的推荐：</span></h1><p>Social Recommender Systems. Ido Guy and David Carmel</p><p>A Social Networ k-Based Recommender System(SNRS). Jianming He and Wesley W. Chu</p><p>Measurement and Analysis of Online Social Networks.</p><p>Referral Web：combining social networks and collaborative filtering</p><h1><span id="基于知识的推荐">基于知识的推荐：</span></h1><p>1、Knowledge-based recommender systems. Robin Burke</p><p>2、Case-Based Recommendation. Barry Smyth</p><p>3、Constraint-based Recommender Systems: Technologies and Research Issues. A. Felfernig. R. Burke</p><h1><span id="其他">其他：</span></h1><p>Trust-aware Recommender Systems. Paolo Massa and Paolo Avesani</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;&lt;span id=&quot;综述类&quot;&gt;综述类:&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;1、Towards the
Next Generation of Recommender Systems: A Survey of the State-of-the-Art and
Possible E
      
    
    </summary>
    
      <category term="recommender systems" scheme="http://dinry.github.io/categories/recommender-systems/"/>
    
    
      <category term="paper" scheme="http://dinry.github.io/tags/paper/"/>
    
  </entry>
  
  <entry>
    <title>graph-attention-networks</title>
    <link href="http://dinry.github.io/graph-attention-networks/"/>
    <id>http://dinry.github.io/graph-attention-networks/</id>
    <published>2019-10-08T11:18:38.000Z</published>
    <updated>2019-10-21T05:12:04.355Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="Deep learning" scheme="http://dinry.github.io/categories/Deep-learning/"/>
    
    
      <category term="deep learning" scheme="http://dinry.github.io/tags/deep-learning/"/>
    
  </entry>
  
  <entry>
    <title>花书第二周--机器学习基本概念</title>
    <link href="http://dinry.github.io/%E8%8A%B1%E4%B9%A6%E7%AC%AC%E4%BA%8C%E5%91%A8%EF%BC%881%EF%BC%89/"/>
    <id>http://dinry.github.io/花书第二周（1）/</id>
    <published>2019-10-08T05:53:29.000Z</published>
    <updated>2019-10-08T07:37:19.588Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="机器学习算法">机器学习算法</span></h1><ol><li>什么是学习？对于某类任务T和性能度量P，一个计算机程序被认为可以从经验E中学习是指，通过经验E改进后，它在任务P上由性能度量P衡量的性能有所提升。</li><li>什么是机器学习算法？能够从数据中学习的算法</li></ol><h2><span id="11-任务t">1.1 任务T</span></h2><h4><span id="机器学习的任务是什么">机器学习的任务是什么？</span></h4><p>机器学习系统应该如何处理样本，即对严办进行一个复杂的非线性变化从而得到正确的结果</p><p>我们通常会将样本表示成一个向量 $x \in \mathbb{R}^n$, 其中向量的每一个元素是一个特征</p><h4><span id="常见的任务有哪些">常见的任务有哪些？</span></h4><ul><li>分类： $f: \mathbb{R}^n \to {1,...,k}$ （输出离散，输出为概率分布）</li><li>回归： $f: \mathbb{R}^n \to \mathbb{R}$ （输出连续）</li><li>转录：OCR, ASR</li><li>机器翻译： seq2seq</li><li>结构化输出：输出值之间内部密切相关，如语法树</li><li>异常检测</li><li>合成与检测</li><li>缺失值填充</li><li>去噪</li><li>密度估计</li></ul><p>本节重点讲了分类回归问题的区别</p><p>度量：</p><p>分类：precision, recall, auc, roc, f1</p><p>回归: mse</p><h2><span id="12-经验">1.2 经验</span></h2><p>无监督学习：</p><p>含有很多特征的数据集，但是没有label</p><p>监督学习：</p><p>（线性回归，LDA,SVM)数据集有label or tag</p><h1><span id="容量过拟合和欠拟合">容量，过拟合和欠拟合</span></h1><p>训练集：测试集：衡量模型的好坏</p><ul><li><p>underfitting: 参数太少，模型简单</p></li><li><p>appropriate capacity: 泛化能力最好</p></li><li><p>overfitting: 模型复杂，训练集误差小，测试集误差大</p></li></ul><p>模型泛化：模型容量</p><p>泛化误差：测试误差</p><h2><span id="model原则">model原则：</span></h2><ul><li>剃刀原则： 若有多个假设与观察一致，选择最简单的</li><li>没有免费午餐定理：不存在能够在所有可能的分类问题中性能均为最优的算法</li><li>解决方案：尽可能深入了解分布，寻找先验知识</li><li>正则化：降低泛化误差而非训练误差，L1,L2（为什么？）</li></ul><p>$J(w)=MSE_{train}+\lambda w^{\top}w$</p><h2><span id="超参数和验证集">超参数和验证集</span></h2><p>超参数：用于挑选超参数的数据子集成为验证集，通常8：2</p><p>验证集：交叉验证，留出法，k折交叉验证</p><p>实际工作经验：训练集，交叉验证集，测试集</p><p>训练集：训练数据</p><p>交叉验证集：判断学习率是否要调整，何时结束训练，每一个epoch都测试</p><p>一般来讲，训练数据每过一个epoch, 都要在交叉验证集上看一下</p><p>性能：损失函数</p><p>测试集：判断模型的性能好坏，最后用</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;&lt;span id=&quot;机器学习算法&quot;&gt;机器学习算法&lt;/span&gt;&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;什么是学习？
对于某类任务T和性能度量P，一个计算机程序被认为可以从经验E中学习是指，通过经验E改进后，它在任务P上由性能度量P衡量的性能有所提升。&lt;/li&gt;
&lt;li&gt;什么是机器学
      
    
    </summary>
    
      <category term="花书" scheme="http://dinry.github.io/categories/%E8%8A%B1%E4%B9%A6/"/>
    
    
      <category term="deep learning" scheme="http://dinry.github.io/tags/deep-learning/"/>
    
  </entry>
  
  <entry>
    <title>花书作业3（梯度下降小程序）</title>
    <link href="http://dinry.github.io/%E8%8A%B1%E4%B9%A6%E4%BD%9C%E4%B8%9A3/"/>
    <id>http://dinry.github.io/花书作业3/</id>
    <published>2019-10-06T08:43:50.000Z</published>
    <updated>2019-10-06T08:47:06.777Z</updated>
    
    <content type="html"><![CDATA[<p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from mpl_toolkits.mplot3d import Axes3D</span><br><span class="line">def f2(x,y):</span><br><span class="line">    return np.exp(x*x+(y-2)*(y-2))</span><br><span class="line">def hx1(x,y):</span><br><span class="line">    return 2*x*np.exp(x*x+(y-2)*(y-2))</span><br><span class="line">def hx2(x,y):</span><br><span class="line">    return 2*(y-2)*np.exp(x*x+(y-2)*(y-2))</span><br><span class="line">X1 = np.arange(0,1,0.1)</span><br><span class="line">X2 = np.arange(0,1,0.1)</span><br><span class="line">X1, X2 = np.meshgrid(X1, X2) # 生成xv、yv，将X1、X2变成n*m的矩阵，方便后面绘图</span><br><span class="line">#pdb.set_trace()</span><br><span class="line">Y = np.array(list(map(lambda t : f2(t[0],t[1]),zip(X1.flatten(),X2.flatten()))))</span><br><span class="line">Y.shape = X1.shape # 1600的Y图还原成原来的（40,40）</span><br><span class="line"></span><br><span class="line">x1 = 1</span><br><span class="line"></span><br><span class="line">x2 = 1</span><br><span class="line"></span><br><span class="line">alpha = 0.01</span><br><span class="line"></span><br><span class="line">GD_X1 = [x1]</span><br><span class="line"></span><br><span class="line">GD_X2 = [x2]</span><br><span class="line"></span><br><span class="line">GD_Y = [f2(x1, x2)]</span><br><span class="line"></span><br><span class="line">y_change = f2(x1, x2)</span><br><span class="line"></span><br><span class="line">iter_num = 0</span><br><span class="line"></span><br><span class="line">while (y_change &gt; 1e-20):</span><br><span class="line">    tmp_x1 = x1 - alpha * hx1(x1, x2)</span><br><span class="line"></span><br><span class="line">    tmp_x2 = x2 - alpha * hx2(x1, x2)</span><br><span class="line"></span><br><span class="line">    tmp_y = f2(tmp_x1, tmp_x2)</span><br><span class="line"></span><br><span class="line">    f_change = np.absolute(tmp_y - f2(x1, x2))</span><br><span class="line">    y_change=f_change</span><br><span class="line"></span><br><span class="line">    x1 = tmp_x1</span><br><span class="line"></span><br><span class="line">    x2 = tmp_x2</span><br><span class="line"></span><br><span class="line">    GD_X1.append(x1)</span><br><span class="line"></span><br><span class="line">    GD_X2.append(x2)</span><br><span class="line"></span><br><span class="line">    GD_Y.append(tmp_y)</span><br><span class="line"></span><br><span class="line">    iter_num += 1</span><br><span class="line"></span><br><span class="line">print(u&quot;最终结果为:(%.5f, %.5f, %.5f)&quot; % (x1, x2, f2(x1, x2)))</span><br><span class="line"></span><br><span class="line">print(u&quot;迭代过程中X的取值，迭代次数:%d&quot; % iter_num)</span><br><span class="line"></span><br><span class="line">print(GD_X1)</span><br><span class="line"></span><br><span class="line">fig = plt.figure(facecolor=&apos;w&apos;, figsize=(20, 18))</span><br><span class="line"></span><br><span class="line">ax = Axes3D(fig)</span><br><span class="line"></span><br><span class="line">ax.plot_surface(X1, X2, Y, rstride=1, cstride=1, cmap=plt.cm.jet)</span><br><span class="line"></span><br><span class="line">ax.plot(GD_X1, GD_X2, GD_Y, &apos;ko-&apos;)</span><br><span class="line"></span><br><span class="line">ax.set_xlabel(&apos;x&apos;)</span><br><span class="line"></span><br><span class="line">ax.set_ylabel(&apos;y&apos;)</span><br><span class="line"></span><br><span class="line">ax.set_zlabel(&apos;z&apos;)</span><br><span class="line"></span><br><span class="line">ax.set_title(u&apos;函数;\n学习率:%.3f; 最终解:(%.3f, %.3f, %.3f);迭代次数:%d&apos; % (alpha, x1, x2, f2(x1, x2), iter_num))</span><br><span class="line"></span><br><span class="line">plt.show()</span><br><span class="line">```js</span><br></pre></td></tr></table></figure></p><p><img src="/%E8%8A%B1%E4%B9%A6%E4%BD%9C%E4%B8%9A3/1.JPG" alt><img src="/%E8%8A%B1%E4%B9%A6%E4%BD%9C%E4%B8%9A3/2.JPG" alt></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span cl
      
    
    </summary>
    
      <category term="花书" scheme="http://dinry.github.io/categories/%E8%8A%B1%E4%B9%A6/"/>
    
    
      <category term="Deep learning" scheme="http://dinry.github.io/tags/Deep-learning/"/>
    
  </entry>
  
  <entry>
    <title>极大似然估计，误差的高斯分布与最小二乘估计的等价性,最优化</title>
    <link href="http://dinry.github.io/MLE/"/>
    <id>http://dinry.github.io/MLE/</id>
    <published>2019-10-04T02:42:22.000Z</published>
    <updated>2019-10-05T06:51:41.691Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="极大似然估计">极大似然估计</span></h1><p>假设随机变量 $X-P(x;\theta)$</p><p>现有样本 $x_1$, $x_2$, ... $x_N$</p><p>定义似然函数为 $L=P(x_1;\theta)P(x_2;\theta) ... P(x_N;\theta)$</p><p>对数似然函数为 $\hat{L}=ln[P(x_1;\theta)P(x_2;\theta) ... P(x_N;\theta)]$</p><p>极大似然估计为 max L</p><p>高斯分布 $P(x)=\frac{1}{\sqrt{2\pi}\sigma}e^{\frac{-(x-\mu)^2}{2\sigma^2}}$</p><p>$L=ln[\frac{1}{\sqrt{2\pi}\sigma}e^{\frac{-(x_1-\mu)^2}{2\sigma^2}},\frac{1}{\sqrt{2\pi}\sigma}e^{\frac{-(x_2-\mu)^2}{2\sigma^2}},...,\frac{1}{\sqrt{2\pi}\sigma}e^{\frac{-(x_N-\mu)^2}{2\sigma^2}}]$</p><p>$\frac{\partial L}{\partial \mu}=0  \to \mu=\frac{x_1+x_2+...+x_N}{N}$</p><p>$\frac{\partial L}{\partial \sigma}=0 \to \sigma^2=\frac{\sum_{i=1}^N(x_i-\mu)^2}{N}$ (有偏方差)</p><h1><span id="误差的高斯分布与最小二乘估计的等价性">误差的高斯分布与最小二乘估计的等价性</span></h1><p>$x_1,x_2,...,x_N, x_i \in \mathbb{R}^n$</p><p>$y_1,y_2,...,y_N, y_i \in \mathbb{R}^n$</p><p>$\hat{y_i}=w^\top x_i, w \in \mathbb{R}^n$</p><p>拟合误差： $e_i=y_i - w^\top x_i$</p><p>若设$e_i-\frac{1}{\sqrt{2\pi}}e^{\frac{e_i^2}{2}}$</p><p>似然函数： $L=ln[\frac{1}{\sqrt{2\pi}}e^{\frac{e_1^2}{2}} \frac{1}{\sqrt{2\pi}}e^{\frac{e_2^2}{2}}...\frac{1}{\sqrt{2\pi}}e^{\frac{e_N^2}{2}}]=-Nln\sqrt{2\pi}-\frac{1}{2}(e_1^2+e_2^2+...+e_N^2)$</p><p>最大化L等价于最小化 $e_1^2+e_2^2+...+e_N^2$</p><p>$min(y_1-w^\top x_1)^2+(y_2-w^\top x_2)^2+...+(y_N-w^\top x_N)^2=J$</p><p>$\frac{\partial J}{\partial w}=0 \to \sum_{i=1}^{N}x_iy_i=\sum_{i=1}^N w^\top x_i x_i$</p><h1><span id="无约束优化">无约束优化</span></h1><p>无约束优化问题是机器学习中最普遍，最简单的优化问题： $x^*=min_{x}f(x)$</p><h2><span id="梯度下降">梯度下降</span></h2><p>沿负梯度方向</p><h2><span id="牛顿法">牛顿法</span></h2><p>$f(x_{t+1})=f(x_t)+f^&quot;(x_t)(x_{t+1}-x_t)$</p><h2><span id="拟牛顿">拟牛顿</span></h2><h2><span id="共轭梯度">共轭梯度</span></h2><h2><span id="收敛速度">收敛速度</span></h2><p>梯度下降是一次收敛，牛顿是二次收敛（速度快，但接近最优点才收敛,否则发散）</p><h1><span id="有约束最优化">有约束最优化</span></h1><h2><span id="拉格朗日乘子法约束为等式">拉格朗日乘子法(约束为等式)</span></h2><p>$min_x f(x)$</p><p>$s.t.g(x)=0$</p><p>$L(x,\lambda)=f(x)+\lambda g(x)$</p><h2><span id="kkt-约束为不等式表示一个范围">KKT （约束为不等式，表示一个范围）</span></h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;&lt;span id=&quot;极大似然估计&quot;&gt;极大似然估计&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;假设随机变量 $X-P(x;\theta)$&lt;/p&gt;
&lt;p&gt;现有样本 $x_1$, $x_2$, ... $x_N$&lt;/p&gt;
&lt;p&gt;定义似然函数为 $L=P(x_1;\theta)P(x_2;
      
    
    </summary>
    
      <category term="花书" scheme="http://dinry.github.io/categories/%E8%8A%B1%E4%B9%A6/"/>
    
    
      <category term="deep learning" scheme="http://dinry.github.io/tags/deep-learning/"/>
    
  </entry>
  
  <entry>
    <title>花书打卡2 （极大似然估计以及优化理论）</title>
    <link href="http://dinry.github.io/%E8%8A%B1%E4%B9%A6%E6%89%93%E5%8D%A12/"/>
    <id>http://dinry.github.io/花书打卡2/</id>
    <published>2019-10-03T06:36:06.000Z</published>
    <updated>2019-10-05T00:38:18.665Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="chapter-3-概率与信息论">Chapter 3: 概率与信息论</span></h1><h2><span id="31-概率的使用">3.1 概率的使用</span></h2><p>机器学习通常必须处理不确定量，有时也要处理随机量，概率用来量化这些不确定性</p><p>不确定性的三种来源：</p><ul><li>被建模系统内在的随机性</li><li>不完全观测</li><li>不完全建模</li></ul><h2><span id="32-随机变量">3.2 随机变量</span></h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;&lt;span id=&quot;chapter-3-概率与信息论&quot;&gt;Chapter 3: 概率与信息论&lt;/span&gt;&lt;/h1&gt;
&lt;h2&gt;&lt;span id=&quot;31-概率的使用&quot;&gt;3.1 概率的使用&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;机器学习通常必须处理不确定量，有时也要处理随机量，概率用来
      
    
    </summary>
    
      <category term="花书" scheme="http://dinry.github.io/categories/%E8%8A%B1%E4%B9%A6/"/>
    
    
      <category term="deep learning" scheme="http://dinry.github.io/tags/deep-learning/"/>
    
  </entry>
  
  <entry>
    <title>python获取交集，并集，差集的方法</title>
    <link href="http://dinry.github.io/%E8%8E%B7%E5%8F%96%E4%BA%A4%E9%9B%86%EF%BC%8C%E5%B9%B6%E9%9B%86%EF%BC%8C%E5%B7%AE%E9%9B%86%E7%9A%84%E6%96%B9%E6%B3%95/"/>
    <id>http://dinry.github.io/获取交集，并集，差集的方法/</id>
    <published>2019-09-21T03:01:53.000Z</published>
    <updated>2019-09-21T03:04:44.294Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="交集">交集</span></h1><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">#方法一:</span><br><span class="line">a=[2,3,4,5]</span><br><span class="line">b=[2,5,8]</span><br><span class="line">tmp = [val for val in a if val in b]</span><br><span class="line">print tmp</span><br><span class="line">#[2, 5]</span><br><span class="line"></span><br><span class="line">#方法二</span><br><span class="line">print list(set(a).intersection(set(b)))</span><br><span class="line"></span><br><span class="line">#方法二比方法一快很多！</span><br><span class="line">```js</span><br></pre></td></tr></table></figure></p><h1><span id="并集">并集</span></h1><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print list(set(a).union(set(b)))</span><br><span class="line">```js</span><br></pre></td></tr></table></figure></p><h1><span id="获取两个-list-的差集">获取两个 list 的差集</span></h1><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print list(set(b).difference(set(a))) # b中有而a中没有的      非常高效！</span><br><span class="line">```js</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;&lt;span id=&quot;交集&quot;&gt;交集&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span 
      
    
    </summary>
    
      <category term="python" scheme="http://dinry.github.io/categories/python/"/>
    
    
      <category term="python" scheme="http://dinry.github.io/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>Word Embedding</title>
    <link href="http://dinry.github.io/embedding/"/>
    <id>http://dinry.github.io/embedding/</id>
    <published>2019-09-19T10:33:25.000Z</published>
    <updated>2019-09-20T00:56:22.540Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="dimension-reduction">dimension reduction</span></h1><p><img src="/embedding/1.JPG" alt></p><h1><span id="word-embedding">word Embedding</span></h1><ul><li>Machine learn the meaning of words from reading a lot of documents without supervision.</li><li>Generating Word Vector is Unsupervised</li><li>A word can be understood by its context.<img src="/embedding/2.JPG" alt></li></ul><h1><span id="how-to-exploit-the-context">How to exploit the context?</span></h1><ul><li>count based: If two words $w_i$ and $w_j$ frequently co-occur, $V(w_i)$ and $V(w_j)$ would be close to each other.(Glove Vector)</li></ul><p>$V(w_i) \cdot V(w_j) \to N_{i,j}$, where number of times $w_i$ and $w_j$ in the same document.</p><ul><li>prediction based: predict next word based on previous words.</li></ul><p><img src="/embedding/3.JPG" alt></p><ul><li>take out he input of the neurons in the first layer.</li><li>use it to represent a word w</li><li>word vector. word embedding feature: V(w)具有相同上下文的单词具有相近的分布<img src="/embedding/4.JPG" alt><img src="/embedding/5.JPG" alt><img src="/embedding/6.JPG" alt>如何让两个weight一样？一样有什么好处？</li><li>Given the same initialization</li><li><img src="/embedding/7.JPG" alt></li><li>cross entropy: <img src="/embedding/8.JPG" alt></li></ul><h2><span id="two-class">two class:</span></h2><ul><li>Cbow</li><li>skip-gram<img src="/embedding/9.JPG" alt>结构信息：结构，包含关系等<img src="/embedding/10.JPG" alt><img src="/embedding/11.JPG" alt></li></ul><h1><span id="document-embedding">document Embedding</span></h1><p><img src="/embedding/12.JPG" alt></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;&lt;span id=&quot;dimension-reduction&quot;&gt;dimension reduction&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;&lt;img src=&quot;/embedding/1.JPG&quot; alt&gt;&lt;/p&gt;
&lt;h1&gt;&lt;span id=&quot;word-embedding&quot;&gt;wor
      
    
    </summary>
    
      <category term="NLP" scheme="http://dinry.github.io/categories/NLP/"/>
    
    
      <category term="NLP" scheme="http://dinry.github.io/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>自然语言处理NLP中的N-gram模型</title>
    <link href="http://dinry.github.io/n-gram/"/>
    <id>http://dinry.github.io/n-gram/</id>
    <published>2019-09-16T11:45:18.000Z</published>
    <updated>2019-09-17T01:03:58.949Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="naive-bayes">Naive Bayes</span></h1><p>见 https://dinry.github.io/%E8%A5%BF%E7%93%9C%E4%B9%A6day13/， 这里再复习一下。</p><p>朴素贝叶斯的关键组成是贝叶斯公式与条件独立性假设。为了方便说明，我们举一个垃圾短信分类的例子。</p><p><strong>&quot;在家日赚百万，惊人秘密...&quot;</strong></p><p>$p(垃圾短信 \mid &quot;在家日赚百万&quot;)∝p(垃圾邮件)p(&quot;在家日赚百万&quot;\mid 垃圾短信)$</p><p>由条件独立性假设：</p><p>$p(&quot;在家日赚百万&quot; \mid J)=p(&quot;在&quot;,&quot;家&quot;,&quot;日&quot;,&quot;赚&quot;,&quot;百&quot;,&quot;万&quot;∣J)=p(&quot;在&quot; \mid J)p(&quot;家&quot;\mid J)p(&quot;日&quot;\mid J)p(&quot;赚&quot;\mid J)p(&quot;百&quot;\mid J)p(&quot;万&quot;\mid J)$</p><p>上面每一项条件概率都可以通过在训练数据的垃圾短信中统计每个字出现的次数得到，然而这里有一个问题，朴素贝叶斯将句子处理为一个 <strong>词袋模型（Bag-of-Words, BoW）</strong> ，以至于不考虑每个单词的顺序。这一点在中文里可能没有问题，因为有时候即使把顺序捣乱，我们还是能看懂这句话在说什么，但有时候不行，例如：</p><p><strong>我烤面筋 = 面筋烤我 ？</strong></p><p>那么有没有模型是考虑句子中单词之间的顺序的呢？有，N-gram就是。</p><h1><span id="n-gram">N-gram</span></h1><h2><span id="n-gram简介">N-gram简介</span></h2><p>在介绍N-gram之前，让我们回想一下**“联想”**的过程是怎样发生的。如果你是一个玩LOL的人，那么当我说“正方形打野”、“你是真的皮”，“你皮任你皮”这些词或词组时，你应该能想到的下一个词可能是“大司马”，而不是“五五开”。如果你不是LOL玩家，没关系，当我说“上火”、“金罐”这两个词，你能想到的下一个词应该更可能“加多宝”，而不是“可口可乐”。</p><p>N-gram正是基于这样的想法，它的第一个特点是某个词的出现依赖于其他若干个词，第二个特点是我们获得的信息越多，预测越准确。我想说，我们每个人的大脑中都有一个N-gram模型，而且是在不断完善和训练的。我们的见识与经历，都在丰富着我们的阅历，增强着我们的联想能力。</p><p>N-gram模型是一种语言模型（Language Model，LM），语言模型是一个基于概率的判别模型，它的输入是一句话（单词的顺序序列），输出是这句话的概率，即这些单词的联合概率（joint probability）。</p><p><img src="/n-gram/1.JPG" alt></p><p>N-gram本身也指一个由N个单词组成的集合，各单词具有先后顺序，且不要求单词之间互不相同。常用的有 $Bi-gram(N=2)$ 和 $Tri-gram(N=3)$，一般已经够用了。例如在上面这句话里，我可以分解的 Bi-gram 和 Tri-gram ：</p><p>Bi-gram :  {I, love}, {love, deep}, {love, deep}, {deep, learning}</p><p>Tri-gram :  {I, love, deep}, {love, deep, learning}</p><h2><span id="n-gram中的概率计算">N-gram中的概率计算</span></h2><p>假设我们有一个由n个词组成的句子 $S=(w_1​,w_2​,⋯,w_n​)$，如何衡量它的概率呢？让我们假设，每一个单词 $w_i$ ​都要依赖于从第一个单词 $w_1$ ​到它之前一个单词 $w_{i−1}$​的影响：</p><p>$p(S)=p(w_1w_2⋯w_n)=p(w_1)p(w_2 \mid w_1)⋯p(w_n \mid w_{n−1}⋯w_2w_1)$</p><p>是不是很简单？是的，不过这个衡量方法有两个缺陷：</p><ul><li>参数空间过大，概率 $p(w_n \mid w_{n−1}⋯w_2w_1)$ 的参数有 $O(n)$ 个。</li><li>数据稀疏严重，词同时出现的情况可能没有，组合阶数高时尤其明显。</li></ul><p>为了解决第一个问题，我们引入马尔科夫假设（Markov Assumption）：一个词的出现仅与它之前的若干个词有关。</p><p>$p(w_1⋯w_n)=\prod p(w_i \mid w_{i-1}⋯w_1)=\prod p(w_i \mid w_{i-1}⋯w_{i-N+1})$</p><ul><li>如果一个词的出现仅依赖于它前面出现的一个词，那么我们就称之为 Bi-gram：$p(S)=p(w_1w_2⋯w_n)=p(w_1)p(w_2 \mid w_1)⋯p(w_n \mid w_{n-1})$</li><li>如果一个词的出现仅依赖于它前面出现的两个词，那么我们就称之为 Tri-gram</li></ul><p>N-gram的N可以取很高，然而现实中一般 bi-gram 和 tri-gram 就够用了。</p><p>那么，如何计算其中的每一项条件概率 $p(w_n \mid w_{n−1}⋯w_2w_1)$ 呢？答案是 <strong>极大似然估计（Maximum Likelihood Estimation，MLE）</strong>，说人话就是数频数：</p><p><img src="/n-gram/2.JPG" alt></p><h1><span id="n-gram-的用途">N-gram 的用途</span></h1><h2><span id="用途一词性标注">用途一：词性标注</span></h2><p><img src="/n-gram/3.JPG" alt></p><h2><span id="用途二垃圾短信分类">用途二：垃圾短信分类</span></h2><p><img src="/n-gram/4.JPG" alt></p><h2><span id="用途三分词器">用途三：分词器</span></h2><p><img src="/n-gram/5.JPG" alt></p><h2><span id="用途四机器翻译和语音识别">用途四：机器翻译和语音识别</span></h2><p><img src="/n-gram/6.JPG" alt></p><h1><span id="n-gram中n的确定">N-gram中N的确定</span></h1><p>为了确定N的取值，《Language Modeling with Ngrams》使用了 Perplexity 这一指标，该指标越小表示一个语言模型的效果越好。文章使用了华尔街日报的数据库，该数据库的字典大小为19,979，训练集包含 38 million 个词，测试集包含 1.5 million 个词。针对不同的N-gram，计算各自的 Perplexity。<img src="/n-gram/7.JPG" alt>结果显示，Tri-gram的Perplexity最小，因此它的效果是最好的。</p><h1><span id="n-gram中的数据平滑方法">N-gram中的数据平滑方法</span></h1><p>上面提到，N-gram的N越大，模型 Perplexity 越小，表示模型效果越好。这在直观意义上是说得通的，毕竟依赖的词越多，我们获得的信息量越多，对未来的预测就越准确。然而，语言是有极强的创造性的（Creative），当N变大时，更容易出现这样的状况：某些n-gram从未出现过，这就是稀疏问题。</p><p>n-gram最大的问题就是稀疏问题（Sparsity）。例如，在bi-gram中，若词库中有20k个词，那么两两组合其中的很多组合在语料库中都没有出现，根据极大似然估计得到的组合概率将会是0，从而整个句子的概率就会为0。最后的结果是，我们的模型只能计算零星的几个句子的概率，而大部分的句子算得的概率是0，这显然是不合理的。</p><p>因此，我们要进行数据平滑（data Smoothing），数据平滑的目的有两个：一个是使所有的N-gram概率之和为1，使所有的n-gram概率都不为0。它的本质，是重新分配整个概率空间，使已经出现过的n-gram的概率降低，补充给未曾出现过的n-gram。<img src="/n-gram/8.JPG" alt>关于N-gram的训练数据，如果你以为 <strong>“只要是英语就可以了”</strong>，那就大错特错了。文献《Language Modeling with Ngrams》**的作者做了个实验，分别用莎士比亚文学作品，以及华尔街日报作为训练集训练两个N-gram，他认为，两个数据集都是英语，那么用他们生成的文本应该也会有所重合。然而结果是，用两个语料库生成的文本没有任何重合性，即使在语法结构上也没有。  这告诉我们，N-gram的训练是很挑数据集的，你要训练一个问答系统，那就要用问答的语料库来训练，要训练一个金融分析系统，就要用类似于华尔街日报这样的语料库来训练。</p><h1><span id="n-gram的进化版nnlm">N-gram的进化版：NNLM</span></h1><p>NNLM 即 Neural Network based Language Model，由Bengio在2003年提出，它是一个很简单的模型，由四层组成，输入层、嵌入层、隐层和输出层。模型接收的输入是长度为nn的词序列，输出是下一个词的类别。首先，输入是单词序列的index序列，例如单词 I 在字典（大小为 $\mid V \mid$）中的index是10，单词 am 的 index 是23， Bengio 的 index 是65，则句子“I am Bengio”的index序列就是 10, 23, 65。嵌入层（Embedding）是一个大小为 $\mid V \mid \times K$ 的矩阵，从中取出第10、23、65行向量拼成 $3\times K$ 的矩阵就是Embedding层的输出了。隐层接受拼接后的Embedding层输出作为输入，以tanh为激活函数，最后送入带softmax的输出层，输出概率。</p><p>NNLM最大的缺点就是参数多，训练慢。另外，NNLM要求输入是定长n，定长输入这一点本身就很不灵活，同时不能利用完整的历史信息。</p><p><img src="/n-gram/9.JPG" alt></p><h1><span id="nnlm的进化版rnnlm">NNLM的进化版：RNNLM</span></h1><p>针对NNLM存在的问题，Mikolov在2010年提出了RNNLM，其结构实际上是用RNN代替NNLM里的隐层，这样做的好处包括减少模型参数、提高训练速度、接受任意长度输入、利用完整的历史信息。同时，RNN的引入意味着可以使用RNN的其他变体，像LSTM、BLSTM、GRU等等，从而在时间序列建模上进行更多更丰富的优化。</p><p>http://www.fit.vutbr.cz/~imikolov/rnnlm/thesis.pdf</p><h1><span id="word2vec">Word2Vec</span></h1><p>https://www.jianshu.com/p/e91f061d6d91</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;&lt;span id=&quot;naive-bayes&quot;&gt;Naive Bayes&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;见 https://dinry.github.io/%E8%A5%BF%E7%93%9C%E4%B9%A6day13/， 这里再复习一下。&lt;/p&gt;
&lt;p&gt;朴素贝叶斯的关键组
      
    
    </summary>
    
      <category term="NLP" scheme="http://dinry.github.io/categories/NLP/"/>
    
    
  </entry>
  
  <entry>
    <title>www2019_recommender system</title>
    <link href="http://dinry.github.io/www2019/"/>
    <id>http://dinry.github.io/www2019/</id>
    <published>2019-09-08T07:00:55.000Z</published>
    <updated>2019-09-16T11:53:46.999Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="1cross-domain-recommendation-without-sharing-user-relevant-data">1.Cross-domain Recommendation Without Sharing User-relevant Data</span></h1><p>研究方向：cross-domain recommendation Task</p><p>Goal: combine data from different websites to improve recommendation task</p><p>Challenge:Despite many research efforts on this task, the main drawback is that they largely assume the data of different systems can be fully shared.</p><p>methods: NATR(short for Neural Attentive Transfer Recommendation)To avoid the leak of user privacy during the data sharing process, it consider sharing only the information of the item side, rather than user behavior data. Specifically, we transfer the item embeddings across domains, making it easier for two companies to reach a consensus (e.g., legal policy) on data sharing since the data to be shared is user-irrelevant and has no explicit semantics.</p><p>step:</p><p><img src="/www2019/1.JPG" alt>Our proposed solution, which has three steps, is illustrated in Figure 1.</p><ul><li>In the first step, an embedding-based recommender model, MF for example, is trained on the user-item interaction matrix of the auxiliary domain to obtain item embeddings.</li><li>In the second step, item embeddings of the auxiliary domain are sent to the target domain; note that only the embeddings of overlapped items are necessary to be sent, which are subjected to the data-sharing policy between two companies.</li><li>Finally, the target domain trains a recommender model with the consideration of the transferred item embeddings.</li></ul><h2><span id="contribution">contribution</span></h2><ul><li>We present a new paradigm for cross-domain recommendation without sharing user-relevant data, in which only item-side data can be shared across domains. To allow the transferring of CF signal, we propose to share the item embeddings which are learned from user-item interactions of the auxiliary domain.</li><li>We propose a new solution NATR to resolve the key challenges in leveraging transferred item embeddings. The twolevel attention design allows NATR to distill useful signal from transferred item embeddings, and appropriately combine them with the data of the target domain.</li><li>We conduct extensive experiments on two real-world datasets to demonstrate our proposed method. More ablation studies verify the efficacy of our designed components, and the utility of transferred item embeddings in addressing the data sparsity issue.</li></ul><h2><span id="framework">framework</span></h2><p><img src="/www2019/2.JPG" alt></p><h1><span id="2dual-graph-attention-networks-for-deep-latent-representation-of-multifaceted-social-effects-in-recommender-systems">2.Dual Graph Attention Networks for Deep Latent Representation of Multifaceted Social Effects in Recommender Systems</span></h1><h2><span id="abstract">Abstract</span></h2><p><img src="/www2019/4.JPG" alt></p><h2><span id="contribution">contribution</span></h2><p><img src="/www2019/5.JPG" alt></p><h2><span id="framework">framework</span></h2><p><img src="/www2019/3.JPG" alt></p><h1><span id="3exploiting-ratings-reviews-and-relationships-for-item-recommendations-in-topic-based-social-networks">3.Exploiting Ratings, Reviews and Relationships for Item Recommendations in Topic Based Social Networks</span></h1><h2><span id="abstract">Abstract</span></h2><p>Many e-commerce platforms today allow users to give their rating scores and reviews on items as well as to establish social relationships with other users. As a result, such platforms accumulate heterogeneous data including numeric scores, short textual reviews, and social relationships. HHowever, many recommender systems only consider historical user feedbacks in modeling user preferences. More specifically, most existing recommendation approaches only use rating scores but ignore reviews and social relationships in the user-generated data. In this paper, we propose TSNPF—a latent factor model to effectively capture user preferences and item features. Employing Poisson factorization, TSNPF fully exploits the wealth of information in rating scores, review text and social relationships altogether. It extracts topics of items and users from the review text and makes use of similarities between user pairs with social relationships, which results in a comprehensive understanding of user preferences. Experimental results on real-world datasets demonstrate that our TSNPF approach is highly effective at recommending items to users.</p><h2><span id="contribution">contribution</span></h2><ul><li>We propose a method based on Gamma-Poisson distribution to extract the topic intensities of items and users from usergenerated textual reviews. Compared to previous techniques, our method is able to address the usual problem of data scarcity.</li><li>We propose TSNPF, a conjugate graphical model based on Poisson factorization which only models non-zero observations in ratings, reviews and social relations simultaneously via interpretable user preferences and item attributes. In addition, we propose a closed form mean-field variational inference method to train TSNPF.</li><li>We evaluate the performance of TSNPF using three publicly available real datasets. The results show that TSNPF outperforms state-of-the-art alternatives.</li></ul><h2><span id="framework">framework</span></h2><p><img src="/www2019/6.JPG" alt></p><p>主题提取与推荐系统的结合</p><h1><span id="4ghostlink-latent-network-inference-for-influence-aware-recommendationintroduction-写的不错">4.GhostLink: Latent Network Inference for Influence-aware Recommendation.(introduction 写的不错)</span></h1><h2><span id="abstract-probabilistic-graphical-model">Abstract (probabilistic graphical model)</span></h2><p>Social influence plays a vital role in shaping a user’s behavior in online communities dealing with items of fine taste like movies, food, and beer. For online recommendation, this implies that users’ preferences and ratings are influenced due to other individuals. Given only time-stamped reviews of users, can we find out whoinfluences- whom, and characteristics of the underlying influence network? Can we use this network to improve recommendation?</p><p>While prior works in social-aware recommendation have leveraged social interaction by considering the observed social network of users, many communities like Amazon, Beeradvocate, and Ratebeer do not have explicit user-user links.Therefore,we propose GhostLink, an unsupervised probabilistic graphical model, to automatically learn the latent influence network underlying a review community – given only the temporal traces (timestamps) of users’ posts and their content. Based on extensive experiments with four real-world datasets with 13 million reviews, we show that GhostLink improves item recommendation by around 23% over state-of-the-art methods that do not consider this influence. As additional use-cases, we show that GhostLink can be used to differentiate between users’ latent preferences and influenced ones, as well as to detect influential users based on the learned influence graph.</p><h2><span id="contribution">contribution</span></h2><ul><li>We propose an unsupervised probabilistic generative model GhostLink based on Latent Dirichlet Allocation to learn a latent influence graph in online communities without requiring explicit user-user links or a social network. This is the first work that solely relies on timestamped review data.</li><li>We propose an efficient algorithm based on Gibbs sampling to estimate the hidden parameters in GhostLink that empirically demonstrates fast convergence.</li><li>We perform large-scale experiments in four communities with 13 million reviews, 0.5 mil. items, and 1 mil. users where we show improved recommendation for item rating prediction by around 23% over state-of-the-art methods. Moreover, we analyze the properties of the influence graph and use it for use-cases like finding influential members in the community.</li></ul><h2><span id="framework">framework</span></h2><p><img src="/www2019/7.JPG" alt></p><h1><span id="5graph-neural-networks-for-social-recommendation">5.Graph Neural Networks for Social Recommendation</span></h1><h2><span id="abstract">Abstract</span></h2><p>In recent years, Graph Neural Networks (GNNs), which can naturally integrate node information and topological structure, have been demonstrated to be powerful in learning on graph data. These advantages of GNNs provide great potential to advance social recommendation since data in social recommender systems can be represented as user-user social graph and user-item graph; and learning latent factors of users and items is the key.</p><p>However, building social recommender systems based on GNNs faces challenges. For example, the user-item graph encodes both interactions and their associated opinions; social relations have heterogeneous strengths; users involve in two graphs (e.g., the useruser social graph and the user-item graph).</p><p>To address the three aforementioned challenges simultaneously, in this paper,we present a novel graph neural network framework (GraphRec) for social recommendations. In particular, we provide a principled approach to jointly capture interactions and opinions in the user-item graph and propose the framework GraphRec, which coherently models two graphs and heterogeneous strengths. Extensive experiments on two real-world datasets demonstrate the effectiveness of the proposed framework GraphRec.</p><h2><span id="contribution">contribution</span></h2><ul><li>We propose a novel graph neural network GraphRec, which can model graph data in social recommendations coherently;</li><li>We provide a principled approach to jointly capture interactions and opinions in the user-item graph;</li><li>We introduce a method to consider heterogeneous strengths of social relations mathematically;</li><li>We demonstrate the effectiveness of the proposed framework on various real-world datasets.</li></ul><h2><span id="framework">framework</span></h2><p><img src="/www2019/8.JPG" alt></p><h2><span id="performance">performance</span></h2><p><img src="/www2019/9.JPG" alt></p><h1><span id="6hierarchical-temporal-convolutional-networks-for-dynamic-recommender-systems工程应用">6.Hierarchical Temporal Convolutional Networks for Dynamic Recommender Systems(工程应用)</span></h1><h2><span id="abstract">Abstract</span></h2><p>Recommender systems that can learn from cross-session data to dynamically predict the next item a user will choose are crucial for online platforms. However, existing approaches often use out-ofthe-box sequence models which are limited by speed and memory consumption, are often infeasible for production environments, and usually do not incorporate cross-session information, which is crucial for effective recommendations.</p><p>Here we propose Hierarchical Temporal Convolutional Networks (HierTCN), a hierarchical deep learning architecture that makes dynamic recommendations based on users’ sequential multi-session interactions with items. HierTCN is designed for web-scale systems with billions of items and hundreds of millions of users. It consists of two levels of models: The high-level model uses Recurrent Neural Networks (RNN) to aggregate users’ evolving long-term interests across different sessions, while the low-level model is implemented with Temporal Convolutional Networks (TCN), utilizing both the long-term interests and the short-term interactions within sessions to predic  the next interaction.</p><h2><span id="contribution">contribution</span></h2><ul><li>HierTCN has a significant performance improvement over existing deep learning models by about 30% on a public XING dataset and 18% on a private large-scale Pinterest dataset.</li><li>Compared with RNN-based approaches, HierTCN is 2.5 times faster in terms of training time and allows for much easier gradient backpropagation.</li><li>Compared with CNN-based approaches, HierTCN requires roughly 10% data memory usage and allows for easy latent feature extraction.</li></ul><h2><span id="framework">framework</span></h2><p><img src="/www2019/10.JPG" alt></p><h1><span id="7how-intention-informed-recommendations-modulate-choices-a-field-study-of-spokenword-content">7.How Intention Informed Recommendations Modulate Choices: A Field Study of SpokenWord Content</span></h1><h2><span id="abstract">Abstract</span></h2><p>People’s content choices are ideally driven by their intentions, aspirations, and plans.</p><p>However, in reality, choices may be modulated by recommendation systems which are typically trained to promote popular items and to reinforce users’ historical behavior. As a result, the utility and user experience of content consumption can be affected implicitly and undesirably.</p><p>To study this problem, we conducteda 2 × 2 randomized controlled field experiment (105 urbancollege students) to compare the effects of intention informed recommendationswith classical intention agnostic systems. The studywas conducted in the context of spokenwordweb content (podcasts)which is often consumed through subscription sites or apps. Wemodified a commercial podcast app to include (1) a recommenderthat takes into account users’ stated intentions at onboarding, and(2) a Collaborative Filtering (CF) recommender during daily use.Our study suggests that: (1) intention-aware recommendations cansignificantly raise users’ interactions (subscriptions and listening)with channels and episodes related to intended topics by over 24%,even if such a recommender is only used during onboarding, and (2)the CF-based recommender doubles users’ explorations on episodesfrom not-subscribed channels and improves satisfaction for usersonboarded with the intention-aware recommender.</p><h2><span id="contribution">contribution</span></h2><p><img src="/www2019/11.JPG" alt></p><h2><span id="framework">framework</span></h2><p><img src="/www2019/12.JPG" alt></p><h1><span id="8how-serendipity-improves-user-satisfaction-with-recommendations-a-large-scale-user-evaluation">8.How Serendipity Improves User Satisfaction with Recommendations? A Large-Scale User Evaluation</span></h1><h2><span id="abstract">Abstract</span></h2><p>Recommendation serendipity is being increasingly recognized asbeing equally important as the other beyond-accuracy objectives(such as novelty and diversity), in eliminating the “filter bubble”phenomenon of the traditional recommender systems.</p><p>However,little work has empirically verified the effects of serendipity onincreasing user satisfaction and behavioral intention.</p><p>In this paper,we report the results of a large-scale user survey (involving over3,000 users) conducted in an industrial mobile e-commerce setting.The study has identified the significant causal relationships fromnovelty, unexpectedness, relevance, and timeliness to serendipity,and from serendipity to user satisfaction and purchase intention.Moreover, our findings reveal that user curiosity plays a moderatingrole in strengthening the relationships from novelty to serendipityand from serendipity to satisfaction. Our third contribution lies inthe comparison of several recommender algorithms, which demonstratesthe significant improvements of the serendipity-orientedalgorithm over the relevance- and novelty-oriented approaches interms of user perceptions. We finally discuss the implications ofthis experiment, which include the feasibility of developing a moreprecise metric for measuring recommendation serendipity, andthe potential benefit of a curiosity-based personalized serendipitystrategy for recommender systems.<img src="/www2019/13.JPG" alt></p><h1><span id="9improving-outfit-recommendation-with-co-supervision-of-fashion-generation-图像衣服类">9.Improving Outfit Recommendation with Co-supervision of Fashion Generation (图像：衣服类)</span></h1><h2><span id="abstract">Abstract</span></h2><p>The task of fashion recommendation includes twomain challenges:visual understanding and visual matching. Visual understandingaims to extract effective visual features. Visual matching aims tomodel a human notion of compatibility to compute a match betweenfashion items. Most previous studies rely on recommendationloss alone to guide visual understanding and matching. Althoughthe features captured by thesemethods describe basic characteristics(e.g., color, texture, shape) of the input items, they arenot directly related to the visual signals of the output items (to berecommended). This is problematic because the aesthetic characteristics(e.g., style, design), based on which we can directly inferthe output items, are lacking. Features are learned under the recommendationloss alone, where the supervision signal is simplywhether the given two items are matched or not.</p><p>To address this problem, we propose a neural co-supervisionlearning framework, called the FAshion RecommendationMachine(FARM). FARM improves visual understanding by incorporatingthe supervision of generation loss, which we hypothesize to beable to better encode aesthetic information. FARMenhances visualmatching by introducing a novel layer-to-layer matching mechanismto fuse aesthetic information more effectively, and meanwhileavoiding paying too much attention to the generation qualityand ignoring the recommendation performance.</p><p>Extensive experiments on two publicly available datasets showthat FARM outperforms state-of-the-art models on outfit recommendation,in terms of AUC and MRR. Detailed analyses of generatedand recommended items demonstrate that FARM can encodebetter features and generate high quality images as references toimprove recommendation performance.</p><h2><span id="contribution">contribution</span></h2><ul><li>We propose a neural co-supervision learning framework, FARM, for outfit recommendation that simultaneously yields recommendation and generation.</li><li>We propose a layer-to-layer matching mechanism that acts as a bridge between generation and recommendation, and improves recommendation by leveraging generation features.</li><li>Our proposed approach is shown to be effective in experiments on two large-scale datasets.</li></ul><h2><span id="framework">framework</span></h2><p><img src="/www2019/14.JPG" alt><img src="/www2019/15.JPG" alt></p><h1><span id="10jointly-learning-explainable-rules-for-recommendation-with-knowledge-graph">10.Jointly Learning Explainable Rules for Recommendation with Knowledge Graph</span></h1><h2><span id="abstract">Abstract</span></h2><p>Explainability and effectiveness are two key aspects for building recommendersystems. Prior efforts mostly focus on incorporating sideinformation to achieve better recommendation performance.</p><p>However,these methods have some weaknesses: (1) prediction of neuralnetwork-based embedding methods are hard to explain and debug;(2) symbolic, graph-based approaches (e.g., meta path-based models)require manual efforts and domain knowledge to define patternsand rules, and ignore the item association types (e.g. substitutableand complementary).</p><p>In this paper, we propose a novel joint learningframework to integrate induction of explainable rules from knowledgegraph with construction of a rule-guided neural recommendationmodel. The framework encourages two modules to complementeach other in generating effective and explainable recommendation:</p><ol><li>inductive rules, mined from item-centric knowledge graphs,summarize common multi-hop relational patterns for inferring differentitem associations and provide human-readable explanationfor model prediction; 2) recommendation module can be augmentedby induced rules and thus have better generalization ability dealingwith the cold-start issue.</li></ol><p>Extensive experiments1 show that ourproposed method has achieved significant improvements in itemrecommendation over baselines on real-world datasets. Our modeldemonstrates robust performance over “noisy&quot; item knowledgegraphs, generated by linking item names to related entities.</p><h2><span id="contribution">contribution</span></h2><ul><li>We utilize a large-scale knowledge graph to derive rules between items from item associations.</li><li>We propose a joint optimization framework that induces rules from knowledge graphs and recommends items based on the rules at the same time.</li><li>We conduct extensive experiments on real-world datasets. Experimental results prove the effectiveness of our framework in accurate and explainable recommendation.</li></ul><h2><span id="framework">framework</span></h2><p><img src="/www2019/16.JPG" alt></p><h1><span id="11jointly-leveraging-intent-and-interaction-signals-to-predict-user-satisfaction-with-slate-recommendations">11.Jointly Leveraging Intent and Interaction Signals to Predict User Satisfaction with Slate Recommendations.</span></h1><h2><span id="abstract">Abstract</span></h2><p>Detecting and understanding implicit measures of user satisfactionare essential for enhancing recommendation quality. When usersinteract with a recommendation system, they leave behind finegrained traces of interaction signals, which contain valuable informationthat could help gauging user satisfaction. User interactionwith such systems is often motivated by a specific need or intent, oftennot explicitly specified by the user, but can nevertheless informon how the user interacts with, and the extent to which the user issatisfied by the recommendations served. In this work, we considera complex recommendation scenario, called Slate Recommendation,wherein a user is presented with an ordered set of collections, calledslates, in a specific page layout. We focus on the context of musicstreaming and leverage fine-grained user interaction signals totackle the problem of predicting user satisfaction.</p><p>We hypothesize that user interactions are conditional on thespecific intent users have when interacting with a recommendationsystem, and highlight the need for explicitly considering userintent when interpreting interaction signals. We present diverseapproaches to identify user intents (interviews, surveys and a quantitativeapproach) and identify a set of common intents users have ina music streaming recommendation setting. Additionally, we identifythe importance of shared learning across intents and propose amulti-level hierarchical model for user satisfaction prediction thatleverages user intent information alongside interaction signals. Ourfindings from extensive experiments on a large scale real world datademonstrate (i) the utility of considering different interaction signals,(ii) the role of intents in interpreting user interactions and (iii)the interplay between interaction signals and intents in predictinguser satisfaction.</p><h1><span id="12modeling-heart-rate-and-activity-data-for-personalized-fitness-recommendation健康推荐">12.Modeling Heart Rate and Activity Data for Personalized Fitness Recommendation(健康推荐)</span></h1><h2><span id="abstract">Abstract</span></h2><p>Activity logs collected from wearable devices (e.g. Apple Watch,Fitbit, etc.) are a promising source of data to facilitate a wide rangeof applications such as personalized exercise scheduling, workoutrecommendation, and heart rate anomaly detection.</p><p>However,such data are heterogeneous, noisy, diverse in scale and resolution,and have complex interdependencies, making them challenging tomodel.</p><p>In this paper, we develop context-aware sequential modelsto capture the personalized and temporal patterns of fitness data.</p><p>Specifically, we propose FitRec – an LSTM-based model that capturestwo levels of context information: context within a specificactivity, and context across a user’s activity history.</p><h2><span id="contribution">contribution</span></h2><p><img src="/www2019/17.JPG" alt></p><h2><span id="framework">framework</span></h2><p><img src="/www2019/18.JPG" alt></p><h1><span id="13modeling-item-specific-temporal-dynamics-of-repeat-consumption-for-recommender-systems">13.Modeling Item-Specific Temporal Dynamics of Repeat Consumption for Recommender Systems</span></h1><h2><span id="abstract">Abstract</span></h2><p>Repeat consumption is a common scenario in daily life, such asrepurchasing items and revisiting websites, and is a critical factorto be taken into consideration for recommender systems. Temporaldynamics play important roles in modeling repeat consumption.It is noteworthy that for items with distinct lifetimes, consumingtendency for the next one fluctuates differently with time. Forexample, users may repurchase milk weekly, but it is possible torepurchase mobile phone after a long period of time. Therefore,how to adaptively incorporate various temporal patterns of repeatconsumption into a holistic recommendation model has been a newand important problem.</p><p>In this paper, we propose a novel unified model with introducingHawkes Process into Collaborative Filtering (CF). Differentfrom most previous work which ignores various time-varying patternsof repeat consumption, the model explicitly addresses twoitem-specific temporal dynamics: (1) short-term effect and (2) lifetimeeffect, which is named as Short-Term and Life-Time RepeatConsumption (SLRC) model. SLRC learns importance of the twofactors for each item dynamically by interpretable parameters.</p><h2><span id="contribution">contribution</span></h2><p><img src="/www2019/19.JPG" alt></p><h1><span id="14multi-task-feature-learning-for-knowledge-graph-enhanced-recommendationcross-domain-recommendation">14.Multi-Task Feature Learning for Knowledge Graph Enhanced Recommendation(cross-domain recommendation)</span></h1><h2><span id="abstract">Abstract</span></h2><p>Collaborative filtering often suffers from sparsity and cold startproblems in real recommendation scenarios, therefore, researchersand engineers usually use side information to address the issuesand improve the performance of recommender systems.</p><p>In thispaper, we consider knowledge graphs as the source of side information.</p><p>We propose MKR, a Multi-task feature learning approachfor Knowledge graph enhanced Recommendation. MKR is a deepend-to-end framework that utilizes knowledge graph embeddingtask to assist recommendation task.</p><h2><span id="contribution">contribution</span></h2><p>We propose MKR, a Multi-task feature learning approachfor Knowledge graph enhanced Recommendation. MKR is a deepend-to-end framework that utilizes knowledge graph embeddingtask to assist recommendation task. knowledge graph embedding, as shown in theoretical analysis and experiment results.</p><h2><span id="framework">framework</span></h2><p><img src="/www2019/20.JPG" alt></p><h1><span id="15multimodal-review-generation-for-recommender-systems">15.Multimodal Review Generation for Recommender Systems</span></h1><h2><span id="abstract">Abstract</span></h2><p>Key to recommender systems is learning user preferences, whichare expressed through various modalities. In online reviews, forinstance, this manifests in numerical rating, textual content, as wellas visual images. In this work, we hypothesize that modelling thesemodalities jointly would result in a more holistic representation ofa review towards more accurate recommendations. Therefore, wepropose Multimodal Review Generation (MRG), a neural approachthat simultaneously models a rating prediction component and areview text generation component. We hypothesize that the shareduser and item representations would augment the rating predictionwith richer information from review text, while sensitizingthe generated review text to sentiment features based on user anditem of interest. Moreover, when review photos are available, visualfeatures could inform the review text generation further. Comprehensiveexperiments on real-life datasets from several major UScities show that the proposed model outperforms comparable multimodalbaselines, while an ablation analysis establishes the relativecontributions of the respective components of the joint model.</p><h2><span id="contribution">contribution</span></h2><p>We design the MRG model (see Section 3), whichjointly models rating prediction and text generation at the reviewlevel by incorporating LSTM cells with a novel fusion gate as akind of soft attention to weigh the relative contributions of sentimentfeatures and visual features that provide context to the textgeneration. We also describe the learning and inference algorithmsrespectively.</p><h2><span id="framework">framework</span></h2><p><img src="/www2019/21.JPG" alt></p><h1><span id="16personalized-bundle-list-recommendation">16.Personalized Bundle List Recommendation</span></h1><h2><span id="abstract">Abstract</span></h2><p>Product bundling, offering a combination of items to customers,is one of the marketing strategies commonly used in online ecommerceand offline retailers. A high-quality bundle generalizesfrequent items of interest, and diversity across bundles boosts theuser-experience and eventually increases transaction volume.</p><p>Inthis paper, we formalize the personalized bundle list recommendationas a structured prediction problem and propose a bundlegeneration network (BGN), which decomposes the problem intoquality/diversity parts by the determinantal point processes (DPPs).BGN uses a typical encoder-decoder framework with a proposedfeature-aware softmax to alleviate the inadequate representationof traditional softmax, and integrates the masked beam search andDPP selection to produce high-quality and diversified bundle listwith an appropriate bundle size.<img src="/www2019/22.JPG" alt></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;&lt;span id=&quot;1cross-domain-recommendation-without-sharing-user-relevant-data&quot;&gt;1.Cross-domain Recommendation Without Sharing User-relevant D
      
    
    </summary>
    
      <category term="recommender systems" scheme="http://dinry.github.io/categories/recommender-systems/"/>
    
    
  </entry>
  
  <entry>
    <title>tensorflow学习率衰减</title>
    <link href="http://dinry.github.io/tensorflow%E5%AD%A6%E4%B9%A0%E7%8E%87%E8%A1%B0%E5%87%8F/"/>
    <id>http://dinry.github.io/tensorflow学习率衰减/</id>
    <published>2019-08-16T03:01:00.000Z</published>
    <updated>2019-08-16T06:31:43.560Z</updated>
    
    <content type="html"><![CDATA[<p>在神经网络的训练过程中，学习率(learning rate)控制着参数的更新速度，tf.train类下面的五种不同的学习速率的衰减方法。</p><ul><li>tf.train.exponential_decay</li><li>tf.train.inverse_time_decay</li><li>tf.train.natural_exp_decay</li><li>tf.train.piecewise_constant</li><li>tf.train.polynomial_decay</li></ul><ol><li>首先使用较大学习率(目的：为快速得到一个比较优的解);</li><li>然后通过迭代逐步减小学习率(目的：为使模型在训练后期更加稳定);</li></ol><p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">tf.train.exponential_decay(</span><br><span class="line">    learning_rate,初始学习率</span><br><span class="line">    global_step,当前迭代次数</span><br><span class="line">    decay_steps,衰减速度（在迭代到该次数时学习率衰减为earning_rate * decay_rate）</span><br><span class="line">    decay_rate,学习率衰减系数，通常介于<span class="number">0</span><span class="number">-1</span>之间。</span><br><span class="line">    staircase=False,(默认值为False,当为True时，（global_step/decay_steps）则被转化为整数) ,选择不同的衰减方式。</span><br><span class="line">    name=None</span><br><span class="line">)</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在神经网络的训练过程中，学习率(learning rate)控制着参数的更新速度，tf.train类下面的五种不同的学习速率的衰减方法。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;tf.train.exponential_decay&lt;/li&gt;
&lt;li&gt;tf.train.inverse_ti
      
    
    </summary>
    
    
      <category term="tensorflow" scheme="http://dinry.github.io/tags/tensorflow/"/>
    
  </entry>
  
</feed>
