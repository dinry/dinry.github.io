<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Dinry</title>
  
  <subtitle>notebook</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://dinry.github.io/"/>
  <updated>2019-07-12T12:56:57.809Z</updated>
  <id>http://dinry.github.io/</id>
  
  <author>
    <name>dinry</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>paper:AdamOptimizer</title>
    <link href="http://dinry.github.io/paper-AdamOptimizer/"/>
    <id>http://dinry.github.io/paper-AdamOptimizer/</id>
    <published>2019-07-12T12:20:39.000Z</published>
    <updated>2019-07-12T12:56:57.809Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="paperadam-a-method-for-stochastic-optimization">paper：Adam: A Method for Stochastic Optimization</span></h1><p>论文链接：<img src="https://arxiv.org/abs/1412.6980" alt></p><p><img src="/paper-AdamOptimizer/1.JPG" alt></p><p>如上算法所述，在确定了参数 $\alpha$,$\beta_1$,$\beta_2$和随机目标函数 $f(\theta)$ 之后，我们需要初始化参数向量、一阶矩向量、二阶矩向量和时间步。然后当参数 $\theta$ 没有收敛时，循环迭代地更新各个部分。即时间步 t 加 1、更新目标函数在该时间步上对参数 $\theta$ 所求的梯度、更新偏差的一阶矩估计和二阶原始矩估计，再计算偏差修正的一阶矩估计和偏差修正的二阶矩估计，然后再用以上计算出来的值更新模型的参数 $\theta$。</p><h1><span id="算法">算法</span></h1>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;&lt;span id=&quot;paperadam-a-method-for-stochastic-optimization&quot;&gt;paper：Adam: A Method for Stochastic Optimization&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;论文链接：&lt;img src=
      
    
    </summary>
    
      <category term="deep learning" scheme="http://dinry.github.io/categories/deep-learning/"/>
    
    
      <category term="tensorflow" scheme="http://dinry.github.io/tags/tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>西瓜书day5,day6(决策树)</title>
    <link href="http://dinry.github.io/%E8%A5%BF%E7%93%9C%E4%B9%A6day5/"/>
    <id>http://dinry.github.io/西瓜书day5/</id>
    <published>2019-07-12T08:44:57.000Z</published>
    <updated>2019-07-13T06:49:35.422Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="决策树定义">决策树定义</span></h1><p>决策树是基于输结构来进行决策的一类常见的机器学习分类方法。</p><h1><span id="解决问题">解决问题</span></h1><p>“当前样本属于正类吗？”</p><p>“这是好瓜吗？”</p><p>“它的根蒂是什么形态”</p><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day5/1.JPG" alt></p><p>决策过程的最终结论（叶子节点）对应了我们所希望的判定结果：好瓜 or 坏瓜</p><h1><span id="结构">结构</span></h1><p>1.一个根节点和若干个内部节点：分别对应一个属性测试</p><p>2.若干个叶节点：对应决策结果</p><p>j决策树学习的目的是为了产生一棵泛化能力强的决策树，基本流程遵循“分而治之”：</p><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day5/2.JPG" alt></p><p>递归返回条件：</p><ul><li>当前节点包含的样本全属于同一类别，无需划分</li><li>当前属性集为空，或是所有样本在所有属性上取值相同，无法划分</li><li>当前节点包含的样本集合为空，不能划分。</li></ul><h1><span id="id3">ID3</span></h1><p>信息熵：</p><p>熵是度量样本集合纯度最常用的一种指标，代表一个系统中蕴含多少信息量，信息量越大表明一个系统不确定性就越大，就存在越多的可能性，即信息熵越大。</p><p>假定当前样本集合D中第K类样本所占的比例为 $p_k(k=1,2,...,\mid y\mid)$, 则D的信息熵为：</p><p>$Ent(D)=-\sum_{k=1}^{\mid y \mid}p_{k}log_{2}p_{k}$</p><p>信息熵满足下列不等式：</p><p>$0 \leq Ent(D) \leq log_{2}\mid y \mid$ ,</p><p>$0 \leq p_k \leq 1$, $\sum_{k=1}^np_k=1$</p><p>其中$y$表示D中的样本类别数。</p><h2><span id="id3推导max-value">ID3推导(max-value)</span></h2><p>若令 $\mid y \mid=n,p_k=x_k$, 那么信息熵 $Ent(D)$ 可以看作一个n元实值函数，即</p><p>$Ent(D)=f(x_1,...,x_n)=-\sum_{k=1}^{n}x_{k}log_{2}x_{k}$, 其中：$0 \leq p_k \leq 1$, $\sum_{k=1}^np_k=1$.</p><p>引入拉格朗日乘子 $\lambda$求最值：</p><p>$L(x_1,...,x_n,\lambda)=-\sum_{k=1}^{n}x_{k}log_{2}x_{k}+\lambda(\sum_{k=1}^nx_k-1)$</p><p>$\frac{\partial L(x_1,...,x_n,\lambda)}{\partial x_1}=-log_2x_1-x_1 \cdot \frac{1}{x_{1}ln2}+\lambda=0$</p><p>$\lambda=log_2x_1+\frac{1}{ln2}$</p><p>同理：</p><p>$\lambda=log_2x_1+\frac{1}{ln2}=log_2x_2+\frac{1}{ln2}=...=log_2x_n+\frac{1}{ln2}$</p><p>so: $x_1=x_2=...=x_n=\frac{1}{n}$</p><p>最大值与最小值需要验证：</p><ul><li>$x_1=x_2=...=x_n=\frac{1}{n}$ 时：$f=-n \cdot \frac{1}{n}log_2\frac{1}{n}=log_2n$</li><li>$x_1=1,x_2=x_3=...=x_n=0$ 时： $f=0$</li></ul><p>所以为最大值</p><h2><span id="id3推导min-value">ID3推导(min-value)</span></h2><p>Assume:</p><p>$f(x_1,...x_n)=\sum_{k=1}^ng(x_k)$</p><p>$g(x_k)=-\sum_{k=1}^{n}x_{k}log_{2}x_{k}$, $0 \leq p_k \leq 1$</p><p>求 $g(x_1)$ 的最小值，首先求导：</p><p>$\frac{d(g(x_1))}{dx_1}=-log_2x_1-\frac{1}{ln2}$</p><p>$\frac{d^2(g(x_1))}{dx^2}=-\frac{1}{x_1ln2}$</p><p>在定义域$0 \leq p_k \leq 1$， 始终有 $\frac{d^2(g(x_1))}{dx^2}=-\frac{1}{x_1ln2} \leq 0$,所以最小值在边界处$x_1=0 或 x_1=1$取得：$min g(x_1)=0$</p><p>由推理可得$f(0,0,0,0,1,...,0)=0$</p><p>所以：</p><p>$0 \leq Ent(D) \leq log_{2}\mid y \mid$</p><h2><span id="信息增益">信息增益</span></h2><p>假定离散属性有V个可能的取值 {${a^1,a^2,...,a^V}$}, 如果使用特征a来对数据集D进行划分，则会产生V个分支结点，其中第 $v$ 个结点包含了数据集D中所有在特征a上取值为 $a^V$ 的样本总数，记为 $D^v$, 特征对样本集D进行划分的“样本增益”为：</p><p>$Gain(D,a)=Ent(D)-\sum_{v=1}^V \frac{\mid D^V \mid}{\mid D \mid}Ent(C^v)$</p><h2><span id="缺点">缺点</span></h2><p>1.ID3没有考虑连续特征</p><p>2.ID3采用信息增益大的特征优先建立决策树的节点，取值比较多的特征比取值少的特征信息增益大</p><p>3.ID3算法对于缺失值的情况没有做考虑</p><p>4.没有考虑过拟合的情况</p><h1><span id="c45算法">C4.5算法</span></h1><p>增益率：</p><p>弥补ID3偏向于取值较多属性,C4.5算法不直接使用信息增益，而是使用一种叫增益率的方法来选择最优属性进行划分：</p><p>$Gain-ration(D,a)=\frac{Gain(D,a)}{IV(a)}$</p><p>$IV(a)$ 是属性 $a$ 的固有值：</p><p>$IV(a)=-\sum_{v=1}^V \frac{\mid D^v \mid}{\mid D \mid}log_2 \frac{\mid D^v \mid}{D}$</p><p>属性越多，熵越大，对分支过多的情况进行惩罚。</p><h2><span id="缺点">缺点</span></h2><p>1.C4.5生成的是多叉树，生成决策树的效率比较慢</p><p>2.C4.5只能用于分类</p><p>3.C4.5由于使用了熵模型，对数运算耗时。</p><h1><span id="cart">CART</span></h1><p>Gini值：</p><p>度量数据集的纯度，Gini(D)反应了从数据集中随机抽取两个样本,类别标记不一致的概率，数据越小，纯度越高。</p><p>$Gini(D)=\sum_{k=1}^{\mid y \mid}\sum_{k' \neq k}p_kp_{k'}=1-\sum_{k=1}^{\mid y \mid}p_k^2$</p><p>$Gini-index(D,a)=\sum_{v=1}^V \frac{\mid D^v \mid}{\mid D \mid}Gini(D^v)$</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;&lt;span id=&quot;决策树定义&quot;&gt;决策树定义&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;决策树是基于输结构来进行决策的一类常见的机器学习分类方法。&lt;/p&gt;
&lt;h1&gt;&lt;span id=&quot;解决问题&quot;&gt;解决问题&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;“当前样本属于正类吗？”&lt;/p&gt;
&lt;p&gt;“这是好
      
    
    </summary>
    
      <category term="ML" scheme="http://dinry.github.io/categories/ML/"/>
    
    
      <category term="西瓜书" scheme="http://dinry.github.io/tags/%E8%A5%BF%E7%93%9C%E4%B9%A6/"/>
    
  </entry>
  
  <entry>
    <title>paper:CFGAN</title>
    <link href="http://dinry.github.io/paper-CFGAN/"/>
    <id>http://dinry.github.io/paper-CFGAN/</id>
    <published>2019-07-11T14:41:11.000Z</published>
    <updated>2019-07-11T14:46:22.352Z</updated>
    
    <content type="html"><![CDATA[<p>本片博客总结paper CFGAN。</p><p>《CFGAN: A Generic Collaborative Filtering Framework based on Generative Adversarial Networks》</p><p>from CIKM 2018</p><p>contribution:  GAN-based CF model</p><p>keyWords: Top-N recommendation, collaborative filtering, generative adversarial networks, implicit feedback</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本片博客总结paper CFGAN。&lt;/p&gt;
&lt;p&gt;《CFGAN: A Generic Collaborative Filtering Framework based on Generative Adversarial Networks》&lt;/p&gt;
&lt;p&gt;from CIKM 
      
    
    </summary>
    
      <category term="recommender systems" scheme="http://dinry.github.io/categories/recommender-systems/"/>
    
    
      <category term="Recommender systems" scheme="http://dinry.github.io/tags/Recommender-systems/"/>
    
  </entry>
  
  <entry>
    <title>tensorflow loss分析</title>
    <link href="http://dinry.github.io/train-loss/"/>
    <id>http://dinry.github.io/train-loss/</id>
    <published>2019-07-11T13:19:46.000Z</published>
    <updated>2019-07-11T14:47:38.930Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="train-loss与test-loss结果分析">train loss与test loss结果分析</span></h1><p>train loss 不断下降，test loss不断下降，说明网络仍在学习;</p><p>train loss 不断下降，test loss趋于不变，说明网络过拟合;</p><p>train loss 趋于不变，test loss不断下降，说明数据集100%有问题;</p><p>train loss 趋于不变，test loss趋于不变，说明学习遇到瓶颈，需要减小学习率或批量数目;</p><p>train loss 不断上升，test loss不断上升，说明网络结构设计不当，训练超参数设置不当，数据集经过清洗等问题。</p><h1><span id="loss和神经网络训练">Loss和神经网络训练</span></h1><h2><span id="训练前的检查工作">训练前的检查工作</span></h2><p>1.loss:在用很小的随机数初始化神经网络后，第一遍计算loss可以做一次检查(当然要记得把正则化系数设为0)。</p><p>2.接着把正则化系数设为正常的小值，加回正则化项，这时候再算损失/loss，应该比刚才要大一些。</p><p>3.试着去拟合一个小的数据集。最后一步，也是很重要的一步，在对大数据集做训练之前，先训练一个小的数据集，然后看看你的神经网络能够做到0损失/loss(当然，是指的正则化系数为0的情况下)，因为如果神经网络实现是正确的，在无正则化项的情况下，完全能够过拟合这一小部分的数据。</p><h2><span id="监控">监控</span></h2><p>开始训练之后，我们可以通过监控一些指标来了解训练的状态。我们还记得有一些参数是我们认为敲定的，比如学习率，比如正则化系数。</p><p>1.损失/loss随每轮完整迭代后的变化</p><p><img src="/train-loss/1.JPG" alt></p><p>合适的学习率可以保证每轮完整训练之后，loss都减小，且能在一段时间后降到一个较小的程度。太小的学习率下loss减小的速度很慢，如果太激进，设置太高的学习率，开始的loss减小速度非常可观，可是到了某个程度之后就不再下降了，在离最低点一段距离的地方反复，无法下降了。</p><p>2.训练集/验证集上的准确度:判断分类器所处的拟合状态。</p><p><img src="/train-loss/2.JPG" alt></p><p>随着时间推进，训练集和验证集上的准确度都会上升，如果训练集上的准确度到达一定程度后，两者之间的差值比较大，那就要注意一下，可能是过拟合现象，如果差值不大，那说明模型状况良好。</p><p>3.权重：权重更新幅度和当前权重幅度的比值权重更新部分是梯度和学习率的乘积，可以独立的检查这个比例，一个合适的比例大概是1e-3。如果得到的比例比这个值小很多，那么说明学习率设定太低了，反之则是设定太高了。</p><p>4.每一层的 激励/梯度值 分布：如果参数初始化不正确，那整个训练过程会越来越慢，甚至直接停掉。</p><h2><span id="关于参数更新部分的注意点">关于参数更新部分的注意点</span></h2><p>当确信解析梯度实现正确后，那就该在后向传播算法中使用它更新权重参数了。就单参数更新这个部分，也是有讲究的：</p><p>1.拿到梯度之后，乘以设定的学习率，用现有的权重减去这个部分，得到新的权重参数(因为梯度表示变化率最大的增大方向，减去这个值之后，损失函数值才会下降)。</p><p>2.在实际训练过程中，随着训练过程推进，逐渐衰减学习率是很有必要的。我们继续回到下山的场景中，刚下山的时候，可能离最低点很远，那我步子迈大一点也没什么关系，可是快到山脚了，我还激进地大步飞奔，一不小心可能就迈过去了。所以还不如随着下山过程推进，逐步减缓一点点步伐。不过这个『火候』确实要好好把握，衰减太慢的话，最低段震荡的情况依旧；衰减太快的话，整个系统下降的『动力』衰减太快，很快就下降不动了。下面提一些常见的学习率衰减方式：</p><ul><li>步伐衰减：这是很常见的一个衰减模式，每过一轮完整的训练周期(所有的图片都过了一遍)之后，学习率下降一些。比如比较常见的一个衰减率可能是每20轮完整训练周期，下降10%。不过最合适的值还真是依问题不同有变化。如果你在训练过程中，发现交叉验证集上呈现很高的错误率，还一直不下降，你可能就可以考虑考虑调整一下(衰减)学习率了。</li><li>指数级别衰减：需要自己敲定的超参数，是迭代轮数。</li><li>1/t衰减：有着数学形式为的衰减模式，其中是需要自己敲定的超参数，是迭代轮数。</li></ul><h2><span id="超参数的设定与优化">超参数的设定与优化</span></h2><p>神经网络的训练过程中，不可避免地要和很多超参数打交道，需要手动设定，大致包括：</p><p>1.初始学习率2.学习率衰减程度3.正则化系数/强度(包括l2正则化强度，dropout比例)</p><p>对于大的深层次神经网络而言，我们需要很多的时间去训练。因此在此之前我们花一些时间去做超参数搜索，以确定最佳设定是非常有必要的。最直接的方式就是在框架实现的过程中，设计一个会持续变换超参数实施优化，并记录每个超参数下每一轮完整训练迭代下的验证集状态和效果。实际工程中，神经网络里确定这些超参数，我们一般很少使用n折交叉验证，一般使用一份固定的交叉验证集就可以了。</p><p>一般对超参数的尝试和搜索都是在log域进行的。例如，一个典型的学习率搜索序列就是learning_rate = 10 ** uniform(-6, 1)。我们先生成均匀分布的序列，再以10为底做指数运算，其实我们在正则化系数中也做了一样的策略。比如常见的搜索序列为[0.5, 0.9, 0.95, 0.99]。另外还得注意一点，如果交叉验证取得的最佳超参数结果在分布边缘，要特别注意，也许取的均匀分布范围本身就是不合理的，也许扩充一下这个搜索范围会有更好的参数。</p><h2><span id="模型融合与优化">模型融合与优化：</span></h2><p>实际工程中，一个能有效提高最后神经网络效果的方式是，训练出多个独立的模型，在预测阶段选结果中的众数。模型融合能在一定程度上缓解过拟合的现象，对最后的结果有一定帮助，我们有一些方式可以得到同一个问题的不同独立模型：</p><ul><li>使用不同的初始化参数。先用交叉验证确定最佳的超参数，然后选取不同的初始值进行训练，结果模型能有一定程度的差别。</li><li>选取交叉验证排序靠前的模型。在用交叉验证确定超参数的时候，选取top的部分超参数，分别进行训练和建模。</li><li>选取训练过程中不同时间点的模型。神经网络训练确实是一件非常耗时的事情，因此有些人在模型训练到一定准确度之后，取不同的时间点的模型去做融合。不过比较明显的是，这样模型之间的差异性其实比较小，好处是一次训练也可以有模型融合的收益。</li></ul><p>检查你的初始权重是否合理，在关掉正则化项的系统里，是否可以取得100%的准确度。</p><p>在训练过程中，对损失函数结果做记录，以及训练集和交叉验证集上的准确度。</p><p>最常见的权重更新方式是SGD+Momentum，推荐试试RMSProp自适应学习率更新算法。</p><p>随着时间推进要用不同的方式去衰减学习率。</p><p>用交叉验证等去搜索和找到最合适的超参数。</p><p>记得也做做模型融合的工作，对结果有帮助。</p><h1><span id="loss保持常数的采坑记录">loss保持常数的采坑记录</span></h1><p>1.loss等于87.33这个问题是在对Inception-V3网络不管是fine-tuning还是train的时候遇到的，无论网络迭代多少次，网络的loss一直保持恒定。</p><p>原因（溢出）：</p><p>由于loss的最大值由FLT_MIN计算得到，FLT_MIN使其对应的自然对数正好是-87.3356，这也就对应上了loss保持87.3356了。这说明softmax在计算的过程中得到了概率值出现了零，由于softmax是用指数函数计算的，指数函数的值都是大于0的，所以应该是计算过程中出现了float溢出的异常，也就是出现了inf，nan等异常值导致softmax输出为0.当softmax之前的feature值过大时，由于softmax先求指数，会超出float的数据范围，成为inf。inf与其他任何数值的和都是inf，softmax在做除法时任何正常范围的数值除以inf都会变成0.然后求loss就出现了87.3356的情况。</p><p>solution:</p><p>由于softmax输入的feature由两部分计算得到：一部分是输入数据，另一部分是各层的权值等组成:</p><p>(1).减小初始化权重，以使得softmax的输入feature处于一个比较小的范围</p><p>(2).降低学习率，这样可以减小权重的波动范围</p><p>(3).如果有BN(batch normalization)层，finetune时最好不要冻结BN的参数，否则数据分布不一致时很容易使输出值变得很大(注意将batch_norm_param中的use_global_stats设置为false )。</p><p>(4).观察数据中是否有异常样本或异常label导致数据读取异常</p><h1><span id="loss不下降的常见原因">loss不下降的常见原因</span></h1><p>1）数据的输入是否正常，data和label是否一致。</p><p>2）网络架构的选择，一般是越深越好，也分数据集。 并且用不用在大数据集上pre-train的参数也很重要的。</p><p>3）loss 对不对。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;&lt;span id=&quot;train-loss与test-loss结果分析&quot;&gt;train loss与test loss结果分析&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;train loss 不断下降，test loss不断下降，说明网络仍在学习;&lt;/p&gt;
&lt;p&gt;train loss 不断
      
    
    </summary>
    
    
      <category term="tensorflow" scheme="http://dinry.github.io/tags/tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>西瓜书day2,day3,day4(线性模型)</title>
    <link href="http://dinry.github.io/%E8%A5%BF%E7%93%9C%E4%B9%A6day2/"/>
    <id>http://dinry.github.io/西瓜书day2/</id>
    <published>2019-07-09T08:20:52.000Z</published>
    <updated>2019-07-11T11:07:25.218Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="基本形式">基本形式</span></h1><p>example:</p><p>$\mathbb{x}=(x_1;x_2;...;x_d)$</p><p>$x_i$是 $\mathbb{x}$ 在第i个属性上的取值线性模型试图学得$f(\mathbb{x})=\mathbb{w}^T\mathbb{x}+b$ 来预测函数，$\mathbb{w}$ 和 $b$ 为参数</p><p>线性模型优点：可解释性强</p><p>分类：</p><ul><li>回归</li><li>分类</li></ul><h1><span id="回归">回归</span></h1><p>均方误差是回归任务中最常用的性能度量</p><h2><span id="一元线性回归">一元线性回归</span></h2><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day2/1.png" alt><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day2/2.png" alt><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day2/3.png" alt><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day2/4.png" alt><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day2/5.png" alt></p><h2><span id="多元线性回归">多元线性回归</span></h2><p>更一般的情形，样本由多个属性决定，此时$f(\mathbb{x}_i)=\mathbb{w}^T\mathbb{x}_i+b$, 称为多元线性回归</p><p>依旧用最小二乘法<img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day2/6.png" alt><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day2/7.png" alt><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day2/8.png" alt><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day2/9.png" alt></p><h2><span id="对数几率回归">对数几率回归</span></h2><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day2/10.jpg" alt><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day2/11.jpg" alt><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day2/12.jpg" alt></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;&lt;span id=&quot;基本形式&quot;&gt;基本形式&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;example:&lt;/p&gt;
&lt;p&gt;$\mathbb{x}=(x_1;x_2;...;x_d)$&lt;/p&gt;
&lt;p&gt;$x_i$是 $\mathbb{x}$ 在第i个属性上的取值线性模型试图学得$f(\math
      
    
    </summary>
    
      <category term="ML" scheme="http://dinry.github.io/categories/ML/"/>
    
    
      <category term="西瓜书" scheme="http://dinry.github.io/tags/%E8%A5%BF%E7%93%9C%E4%B9%A6/"/>
    
  </entry>
  
  <entry>
    <title>西瓜书day1（绪论）</title>
    <link href="http://dinry.github.io/%E8%A5%BF%E7%93%9C%E4%B9%A6day1/"/>
    <id>http://dinry.github.io/西瓜书day1/</id>
    <published>2019-07-08T07:30:32.000Z</published>
    <updated>2019-07-08T08:33:51.010Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="绪论">绪论</span></h1><p>机器学习致力于研究如何通过计算的手段，利用经验来改善系统自身的性能。经验即数据。</p><p>机器学习所研究的主要内容，是关于在计算机上从数据中产生“模型”的算法，learning algorithms.再用模型来预测未来数据。</p><h1><span id="术语">术语</span></h1><p>记录：</p><p>数据集：记录的集合</p><p>训练：从数据中学习模型的过程</p><p>训练集：训练过程中使用的数据样本的集合</p><p>分类任务：预测的结果为离散值（好瓜，坏瓜）</p><p>回归任务：预测值是连续值</p><p>根据训练数据是否有label，学习任务可划分为：“监督学习”，“无监督学习”</p><p>泛化能力：学得模型适用于新样本的能力</p><h1><span id="归纳演绎">归纳演绎</span></h1><p>归纳：从特殊到一般（机器学习）</p><p>演绎：从一般到特殊</p><h1><span id="发展历程">发展历程</span></h1><p>机器学习是人工智能研究发展到一定阶段的必然产物。</p><table><thead><tr><th>年代</th><th>事件</th><th>代表工作</th></tr></thead><tbody><tr><td>二十世纪而五十年代到七十年代</td><td>人工智能的推理期</td><td>感知机、Adaline</td></tr><tr><td>五十年代中后期</td><td>符号主义蓬勃发展，决策理论。增强学习</td><td>结构学习系统，概念学习系统</td></tr><tr><td>八十年代</td><td>决策树学习</td><td>由于复杂度过高而陷入低潮</td></tr><tr><td>九十年代</td><td>基于神将网络的连接学习</td><td>hopfield,BP,产生黑箱模型</td></tr><tr><td>九十年代中期</td><td>统计学习</td><td>SVM, 核方法</td></tr><tr><td>二十一世纪初</td><td>深度学习</td><td>对数据，硬件要求高</td></tr></tbody></table><h1><span id="应用现状">应用现状</span></h1><p>今天，在计算机学科的诸多分支学科中，无论是多媒体，图形学，还是网络通信，软件工程，体系结构，芯片设计都能找到机器学习的身影，尤其是CV与NLP。</p><p>交叉学科：生物信息学</p><p>大数据时代的三大技术：机器学习，云计算，众包</p><p>数据挖掘与机器学习的关系：</p><p>数据挖掘技术在二十世纪九十年代形成，受数据库，机器学习，统计学影响最大。数据挖掘是从海量知识中发掘知识，这就必然涉及对海量数据的管理分析。数据库领域的研究为数据挖掘提供数据管理技术，而机器学习和统计学研究为数据挖掘提供数据分析技术，统计学主要是通过机器学习对数据挖掘发挥影响，机器学习领域与数据库领域是数据挖掘的两大支撑。</p><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day1/1.jpg" alt></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;&lt;span id=&quot;绪论&quot;&gt;绪论&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;机器学习致力于研究如何通过计算的手段，利用经验来改善系统自身的性能。经验即数据。&lt;/p&gt;
&lt;p&gt;机器学习所研究的主要内容，是关于在计算机上从数据中产生“模型”的算法，learning algorithms.再
      
    
    </summary>
    
      <category term="ML" scheme="http://dinry.github.io/categories/ML/"/>
    
    
      <category term="西瓜书" scheme="http://dinry.github.io/tags/%E8%A5%BF%E7%93%9C%E4%B9%A6/"/>
    
  </entry>
  
  <entry>
    <title>tensorflow深度学习(2):tf.nn.top_k()</title>
    <link href="http://dinry.github.io/tensorflow%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-2-tf-nn-top-k/"/>
    <id>http://dinry.github.io/tensorflow深度学习-2-tf-nn-top-k/</id>
    <published>2019-07-05T03:42:07.000Z</published>
    <updated>2019-07-05T03:47:15.683Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="introduction">introduction</span></h1><p>def top_k(input, k=1, sorted=True, name=None)</p><p>Finds values and indices of the k largest entries for the last dimension.</p><p>If the input is a vector (rank=1), finds the k largest entries in the vector and outputs their values and indices as vectors.Thus values[j] is the j-th largest entry in input, and its index is indices[j].</p><p>For matrices (resp. higher rank input), computes the top k entries in each row (resp. vector along the last dimension).Thus, values.shape = indices.shape = input.shape[:-1] + [k]</p><p>If two elements are equal, the lower-index element appears first.</p><h1><span id="parameters">parameters</span></h1><p><img src="/tensorflow%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-2-tf-nn-top-k/1.JPG" alt></p><h1><span id="code">code</span></h1><p><img src="/tensorflow%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-2-tf-nn-top-k/2.JPG" alt></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;&lt;span id=&quot;introduction&quot;&gt;introduction&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;def top_k(input, k=1, sorted=True, name=None)&lt;/p&gt;
&lt;p&gt;Finds values and indices of the
      
    
    </summary>
    
    
      <category term="tensorflow" scheme="http://dinry.github.io/tags/tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>temsorflow常用集合(colection)</title>
    <link href="http://dinry.github.io/tensorflow%E5%B8%B8%E7%94%A8%E9%9B%86%E5%90%88/"/>
    <id>http://dinry.github.io/tensorflow常用集合/</id>
    <published>2019-07-05T02:55:07.000Z</published>
    <updated>2019-07-05T03:23:05.388Z</updated>
    
    <content type="html"><![CDATA[<p>tensorflow 用集合collection组织不同类别的对象，tf.GraphKeys中包含了所有默认集合的名称。</p><p>collection在对应的scope内提供了“零存整取”的思想：任意位置，任意层次的对象，统一提取。</p><p>tf.optimizer只优化tf.GraphKeys.TRAINABLE_VARIABLES中的变量</p><h2><span id="常用集合">常用集合</span></h2><ul><li>Variable集合：模型参数</li><li>summary 集合：监测</li><li>自定义集合</li></ul><h1><span id="variable">Variable</span></h1><p>Variable被收集在tf.GraphKeys.VARIABLES的collection中</p><h2><span id="定义">定义</span></h2><p>k=tf.Variable()<img src="/tensorflow%E5%B8%B8%E7%94%A8%E9%9B%86%E5%90%88/1.JPG" alt></p><h1><span id="summary">summary</span></h1><p>Summary被收集在名为tf.GraphKeys.SUMMARIES的collection中</p><h2><span id="define">define</span></h2><p>对网络中tensor取值进行监测</p><p>调用tf.scalar_summary系列函数，会向默认的collection中添加一个operation</p><p><img src="/tensorflow%E5%B8%B8%E7%94%A8%E9%9B%86%E5%90%88/2.JPG" alt></p><h1><span id="自定义">自定义</span></h1><p>tf.add_to_collection(&quot;losses&quot;,l1)losses=tf.get_collection('losses')</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;tensorflow 用集合collection组织不同类别的对象，tf.GraphKeys中包含了所有默认集合的名称。&lt;/p&gt;
&lt;p&gt;collection在对应的scope内提供了“零存整取”的思想：任意位置，任意层次的对象，统一提取。&lt;/p&gt;
&lt;p&gt;tf.optimiz
      
    
    </summary>
    
    
      <category term="tensorflow" scheme="http://dinry.github.io/tags/tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>机器学习之线性模型推导</title>
    <link href="http://dinry.github.io/machine-learning-2/"/>
    <id>http://dinry.github.io/machine-learning-2/</id>
    <published>2019-07-02T05:50:36.000Z</published>
    <updated>2019-07-02T06:24:26.420Z</updated>
    
    <content type="html"><![CDATA[<p>西瓜书，南瓜书</p><h1><span id="一元线性回归">一元线性回归</span></h1><p>最小二乘法推导</p><h2><span id="b的公式推导3638">b的公式推导（3.6，3.8）</span></h2><p>（二元函数求最值）</p><p>1.由最小二乘法导出损失函数E（w,b）</p><p>2.证明损失函数是关于w,b的凸函数</p><p>3.对损失函数关于B求偏导数</p><p>4.另一接偏导数为0求b</p><p>由最小二乘法导出损失函数：</p><p>$E_{w,b}=\sum_{i=1}^m$</p><h2><span id="w的公式推导3537">w的公式推导（3.5，3.7）</span></h2><h1><span id="多元线性回归">多元线性回归</span></h1>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;西瓜书，南瓜书&lt;/p&gt;
&lt;h1&gt;&lt;span id=&quot;一元线性回归&quot;&gt;一元线性回归&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;最小二乘法推导&lt;/p&gt;
&lt;h2&gt;&lt;span id=&quot;b的公式推导3638&quot;&gt;b的公式推导（3.6，3.8）&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;（二元函数求最值）&lt;/p
      
    
    </summary>
    
    
      <category term="machine learning" scheme="http://dinry.github.io/tags/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title>machine learning(1)</title>
    <link href="http://dinry.github.io/machine-learning-1/"/>
    <id>http://dinry.github.io/machine-learning-1/</id>
    <published>2019-07-02T01:36:05.000Z</published>
    <updated>2019-07-02T05:47:00.271Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="机器学习的四大应用领域及其应用">机器学习的四大应用领域及其应用</span></h1><h2><span id="数据挖掘发现数据之间的关系">数据挖掘：发现数据之间的关系</span></h2><p>1.回归问题</p><p>2.分类问题</p><p>根据已知数据，学习函数。</p><h2><span id="计算机视觉像人一样看懂世界">计算机视觉：像人一样看懂世界</span></h2><p>图像分类</p><p>目标检测（无人驾驶）</p><p>语义分割（无人驾驶）</p><p>场景理解（无人驾驶）</p><h2><span id="nlp像人一样看懂文字">NLP：像人一样看懂文字</span></h2><p>文本分类（新闻分类）</p><p>自动生成文本摘要</p><p>翻译</p><p>QA</p><p>人机对话（小冰）</p><p>image to text</p><p>end to end级自动驾驶</p><h2><span id="机器人决策像人一样具有决策能力">机器人决策：像人一样具有决策能力</span></h2><p>TORCS平台（玩赛车游戏）：增强学习（agent,action）</p><p>机器人开门（自动执行）：增强学习</p><h1><span id="机器学习理论分类">机器学习理论分类</span></h1><p>常用的三类：</p><p>1.传统的监督学习（分类，回归）</p><p>2.深度学习（视觉，NLP）</p><p>3.强化学习（机器人）</p><p>三种分类学习按标号顺序循序渐进</p><h1><span id="先重点再难点">先重点，再难点</span></h1><p><img src="/machine-learning-1/1.jpg" alt></p><p><img src="/machine-learning-1/2.jpg" alt></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;&lt;span id=&quot;机器学习的四大应用领域及其应用&quot;&gt;机器学习的四大应用领域及其应用&lt;/span&gt;&lt;/h1&gt;
&lt;h2&gt;&lt;span id=&quot;数据挖掘发现数据之间的关系&quot;&gt;数据挖掘：发现数据之间的关系&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;1.回归问题&lt;/p&gt;
&lt;p&gt;2.分类问题&lt;/
      
    
    </summary>
    
    
      <category term="machine learning" scheme="http://dinry.github.io/tags/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title>调参技巧汇总</title>
    <link href="http://dinry.github.io/%E8%B0%83%E5%8F%82%E6%8A%80%E5%B7%A7%E6%B1%87%E6%80%BB/"/>
    <id>http://dinry.github.io/调参技巧汇总/</id>
    <published>2019-06-28T02:33:02.000Z</published>
    <updated>2019-06-28T03:31:40.553Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>推荐系统评估指标(Rank)</title>
    <link href="http://dinry.github.io/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87/"/>
    <id>http://dinry.github.io/推荐系统评估指标/</id>
    <published>2019-06-24T11:09:54.000Z</published>
    <updated>2019-06-24T11:54:46.854Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="mean-average-precision-map">Mean Average Precision (MAP)</span></h1><p>$AP=\frac {\sum_{j=1}^{n_i}P(j)\cdot y_{i,j}}{\sum_{j=1}^{n_i}y_{i,j}}$</p><p>其中，$y_{i,j}$: 排序中第j个元素对于查询i是否是相关的；相关为1，不相关为0。</p><p>$P(j)=\frac {\sum_{k:\pi_{i}(k)\leq\pi_{i}(j)} y_{i,k}}{\pi_{i}(j)}$</p><p>其中，$\pi_{i}(j)$为J的排序位置。</p><p>例如：</p><table><thead><tr><th>rank_no</th><th>是否相关</th></tr></thead><tbody><tr><td>1</td><td>1</td></tr><tr><td>2</td><td>0</td></tr><tr><td>3</td><td>1</td></tr><tr><td>4</td><td>0</td></tr><tr><td>5</td><td>1</td></tr><tr><td>6</td><td>0</td></tr></tbody></table><p>则根据AP计算公式：$AP=(1*1 + (1/2) *0+ (2/3)*1 + (2/4)*0 + (3/5)*0 + (3/6)*0) /3$</p><p>AP的最大值是1，MAP就是对所有user求均值。</p><h1><span id="mean-reciprocal-rank-mrr">Mean Reciprocal Rank (MRR)</span></h1><p>$MRR=\frac{1}{\mid Q \mid} \sum_{i=1}^{\mid Q \mid} \frac{1}{rank_i}$</p><p>其中|Q|是查询个数，ranki是第i个查询，第一个相关的结果所在的排列位置。</p><p>例如：</p><table><thead><tr><th>Query</th><th>Result</th><th>Correct response</th><th>Rank</th><th>Reciprocal rank</th></tr></thead><tbody><tr><td>cat</td><td>catten,cati,cats</td><td>cats</td><td>3</td><td>1/3</td></tr><tr><td>tori</td><td>torii,tori,toruses</td><td>tori</td><td>2</td><td>1/2</td></tr><tr><td>virus</td><td>viruses,virii,viri</td><td>viruses</td><td>1</td><td>1</td></tr></tbody></table><p>对于三个查询，每个查询的ranki分别为3、2、1。所以，MRR=1/3∗(1/3+1/2+1/1)</p><h1><span id="ndcgprerec的计算较为简单已在csdn中介绍这里省略">NDCG，pre,rec的计算较为简单，已在CSDN中介绍，这里省略。</span></h1>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;&lt;span id=&quot;mean-average-precision-map&quot;&gt;Mean Average Precision (MAP)&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;$AP=\frac {\sum_{j=1}^{n_i}P(j)\cdot y_{i,j}}{\sum_{j=
      
    
    </summary>
    
      <category term="recommender systems" scheme="http://dinry.github.io/categories/recommender-systems/"/>
    
    
      <category term="评估指标（Rec）" scheme="http://dinry.github.io/tags/%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87%EF%BC%88Rec%EF%BC%89/"/>
    
  </entry>
  
  <entry>
    <title>cluster</title>
    <link href="http://dinry.github.io/cluster/"/>
    <id>http://dinry.github.io/cluster/</id>
    <published>2019-06-21T02:30:54.000Z</published>
    <updated>2019-06-24T00:47:17.731Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="概述">概述</span></h1><p>聚类（Clustering）的本质是对数据进行分类，将相异的数据尽可能地分开，而将相似的数据聚成一个类别（簇），使得同一类别的数据具有尽可能高的同质性（homogeneity），类别之间有尽可能高的异质性（heterogeneity），从而方便从数据中发现隐含的有用信息。聚类算法的应用包含如下几方面：</p><ul><li>其他数据挖掘任务的关键中间环节：用于构建数据概要，用于分类、模式识别、假设生成和测试；用于异常检测，检测远离群簇的点。</li><li>数据摘要、数据压缩、数据降维：例如图像处理中的矢量量化技术。创建一个包含所有簇原型的表，即每个原型赋予一个整数值，作为它在表中的索引。每个对象用与它所在簇相关联的原型的索引表示。</li><li>协同过滤：用于推荐系统和用户细分。</li><li>动态趋势检测：对流数据进行聚类，检测动态趋势和模式。</li><li>用于多媒体数据、生物数据、社交网络数据的应用。</li></ul><h1><span id="聚类算法的分类">聚类算法的分类</span></h1><p>1.hierarchical methods：主要讲给定的数据集进行逐层分解，直到满足某种条件为止。具体可分为“自底向上”和“自顶向下”两种方案。在“自底向上”方案中，初始时每个数据点组成一个单独的组，在接下来的迭代中，按一定的距离度量将相互邻近的组合并成一个组，直至所有的记录组成一个分组或者满足某个条件为止。代表算法有：<img src="https://www2.cs.sfu.ca/CourseCentral/459/han/papers/zhang96.pdf" alt="BIRCH">，<img src="https://www2.cs.sfu.ca/CourseCentral/459/han/papers/guha98.pdf" alt="CURE">，CHAMELEON等。自底向上的凝聚层次聚类如下图所示。</p><p><img src="/cluster/p1.jpg" alt></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;&lt;span id=&quot;概述&quot;&gt;概述&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;聚类（Clustering）的本质是对数据进行分类，将相异的数据尽可能地分开，而将相似的数据聚成一个类别（簇），使得同一类别的数据具有尽可能高的同质性（homogeneity），类别之间有尽可能高的异质性（h
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>gans problem</title>
    <link href="http://dinry.github.io/gans-problem/"/>
    <id>http://dinry.github.io/gans-problem/</id>
    <published>2019-06-18T13:31:22.000Z</published>
    <updated>2019-06-18T13:34:29.985Z</updated>
    
    <content type="html"><![CDATA[<p>自从2014年Ian Goodfellow提出以来，GAN就存在着训练困难、生成器和判别器的loss无法指示训练进程、生成样本缺乏多样性等问题。从那时起，很多论文都在尝试解决，但是效果不尽人意，比如最有名的一个改进DCGAN依靠的是对判别器和生成器的架构进行实验枚举，最终找到一组比较好的网络架构设置，但是实际上是治标不治本，没有彻底解决问题。而今天的主角Wasserstein GAN（下面简称WGAN）成功地做到了以下爆炸性的几点：</p><ul><li>彻底解决GAN训练不稳定的问题，不再需要小心平衡生成器和判别器的训练程度</li><li>基本解决了collapse mode的问题，确保了生成样本的多样性</li><li>训练过程中终于有一个像交叉熵、准确率这样的数值来指示训练的进程，这个数值越小代表GAN训练得越好，代表生成器产生的图像质量越高</li><li>以上一切好处不需要精心设计的网络架构，最简单的多层全连接网络就可以做到</li></ul><p>推荐阅读：《Towards Principled Methods for Training Generative Adversarial Networks》，《Wasserstein GAN》</p><p>而改进后相比原始GAN的算法实现流程却只改了四点：</p><ul><li>判别器最后一层去掉sigmoid</li><li>生成器和判别器的loss不取log</li><li>每次更新判别器的参数之后把它们的绝对值截断到不超过一个固定常数c</li><li>不要用基于动量的优化算法（包括momentum和Adam），推荐RMSProp，SGD也行</li></ul><h1><span id="1原始gan有什么问题">1.原始GAN有什么问题</span></h1><p>原始GAN中：</p><p>对于D，需要最小化如下损失函数，尽可能把真实样本分为正例，生成样本分为负例:<img src="/generate-model/p17.JPG" alt>  (1)</p><p>对于G，Goodfellow一开始提出来一个损失函数，后来又提出了一个改进的损失函数，分别是</p><p>$E_{x\sim P_g}[log(1-D(x))]$  (2)</p><p>$E_{x\sim P_g}[-log(D(x))]$  (3)</p><p>《Towards Principled Methods for Training Generative Adversarial Networks》分别分析了这两种形式的原始GAN各自的问题所在，下面分别说明。</p><h2><span id="第一种原始gan形式的问题">第一种原始GAN形式的问题</span></h2><p>一句话概括：判别器越好，生成器梯度消失越严重。WGAN前作从两个角度进行了论证，第一个角度是从生成器的等价损失函数切入的。</p><p>首先，从Eq.(1)可以知道，固定G，最优的D是 $D^*(x)=\frac{p_r(x)}{p_r(x)+p_g(x)}$       Eq.(4)这个结果就是公式1的最优值，求导而得，就是看一个样本x来自真实分布和生成分布的可能性的相对比例。如果 $p_r(x)=0$且$p_g(x) \neq 0$, 最优判别器就应该非常自信地给出概率0；如果$p_r(x)=p_g(x)$, 说明该样本是真是假的可能性刚好一半一半，此时最优判别器也应该给出概率0.5。</p><p>然而GAN训练有一个trick，就是别把判别器训练得太好，否则在实验中生成器会完全学不动（loss降不下去），为了探究背后的原因，我们就可以看看在极端情况——判别器最优时，生成器的损失函数变成什么。给公式2加上一个不依赖于生成器的项，使之变成:</p><p>$E_{x\sim P_r}[logD(x)]+E_{x\sim P_g}[log(1-D(x))]$</p><p>注意，最小化这个损失函数等价于最小化公式2，而且它刚好是判别器损失函数的反。代入最优判别器即公式4，再进行简单的变换可以得到:</p><p>$E_{x\sim P_r}[log\frac{p_r(x)}{\frac{1}{2}[p_r(x)+p_g(x)]}]+E_{x\sim P_g}[log\frac{p_g(x)}{\frac{1}{2}[p_r(x)+p_g(x)]}]-2log2$=$2JS(P_r||P_g)-2log2$.  Eq.(5)</p><p>变换成这个样子是为了引入Kullback–Leibler divergence（简称KL散度）和Jensen-Shannon divergence（简称JS散度）这两个重要的相似度衡量指标，后面的主角之一Wasserstein距离，就是要来吊打它们两个的。所以接下来介绍这两个重要的配角——KL散度和JS散度：</p><p>$KL(P_1\mid \mid P_2)=E_{x\sim P_1}log\frac{P_1}{P_2}$.  Eq.(6)</p><p>$JS(P1\mid \mid P2)=\frac{1}{2}KL(P_1\mid \mid \frac{P_1+P_2}{2})+\frac{1}{2}KL(P_2\mid \mid \frac{P_1+P_2}{2})$. Eq.(7)</p><p>根据原始GAN定义的判别器loss，我们可以得到最优判别器的形式；而在最优判别器的下，我们可以把原始GAN定义的生成器loss等价变换为最小化真实分布P_r与生成分布P_g之间的JS散度。我们越训练判别器，它就越接近最优，最小化生成器的loss也就会越近似于最小化$P_r$和$P_g$之间的JS散度。</p><p>问题就出在这个JS散度上。我们会希望如果两个分布之间越接近,它们的JS散度越小，我们通过优化JS散度就能将$P_g$“拉向”$P_r$，最终以假乱真。这个希望在两个分布有所重叠的时候是成立的，但是如果两个分布完全没有重叠的部分，或者它们重叠的部分可忽略（下面解释什么叫可忽略），它们的JS散度是多少呢？</p><p>答案是$log2$,因为对于任意$x$, 只有如下四种可能性：</p><p>$P_1(x)=0$且$P_2(x)=0$</p><p>$P_1(x)\neq0$且$P_2(x)\neq0$</p><p>$P_1(x)=0$且$P_2(x)\neq0$</p><p>$P_1(x)\neq0$且$P_2(x)=0$</p><p>第一种对计算JS散度无贡献，第二种情况由于重叠部分可忽略所以贡献也为0，第三种情况对公式7右边第一个项的贡献是$log\frac{P_2}{\frac{1}{2}(P_2+0)}=log2$,第四种情况与之类似，所以最终$JS(P_1\mid \mid P_2)=log2$</p><p>换句话说，无论$P_r$跟$P_g$是远在天边，还是近在眼前，只要它们俩没有一点重叠或者重叠部分可忽略，JS散度就固定是常数$log 2$，而这对于梯度下降方法意味着——梯度为0！此时对于最优判别器来说，生成器肯定是得不到一丁点梯度信息的；即使对于接近最优的判别器来说，生成器也有很大机会面临梯度消失的问题。</p><p>那么$P_r$与$P_g$不重叠或重叠部分可忽略的可能性有多大？不严谨的答案是：非常大。比较严谨的答案是：当$P_r$与$P_g$的支撑集（support）是高维空间中的低维流形（manifold）时，$P_r$与$P_g$重叠部分测度（measure）为0的概率为1。</p><ul><li>支撑集（support）其实就是函数的非零部分子集，比如ReLU函数的支撑集就是(0, +\infty)，一个概率分布的支撑集就是所有概率密度非零部分的集合。</li><li>流形（manifold）是高维空间中曲线、曲面概念的拓广，我们可以在低维上直观理解这个概念，比如我们说三维空间中的一个曲面是一个二维流形，因为它的本质维度（intrinsic dimension）只有2，一个点在这个二维流形上移动只有两个方向的自由度。同理，三维空间或者二维空间中的一条曲线都是一个一维流形。</li><li>测度（measure）是高维空间中长度、面积、体积概念的拓广，可以理解为“超体积”。</li></ul><p>回过头来看第一句话，“当$P_r$与$P_g$的支撑集是高维空间中的低维流形时”，基本上是成立的。原因是GAN中的生成器一般是从某个低维（比如100维）的随机分布中采样出一个编码向量，再经过一个神经网络生成出一个高维样本（比如64x64的图片就有4096维）。当生成器的参数固定时，生成样本的概率分布虽然是定义在4096维的空间上，但它本身所有可能产生的变化已经被那个100维的随机分布限定了，其本质维度就是100，再考虑到神经网络带来的映射降维，最终可能比100还小，所以生成样本分布的支撑集就在4096维空间中构成一个最多100维的低维流形，“撑不满”整个高维空间。</p><p>“撑不满”就会导致真实分布与生成分布难以“碰到面”，这很容易在二维空间中理解：一方面，二维平面中随机取两条曲线，它们之间刚好存在重叠线段的概率为0；另一方面，虽然它们很大可能会存在交叉点，但是相比于两条曲线而言，交叉点比曲线低一个维度，长度（测度）为0，可忽略。三维空间中也是类似的，随机取两个曲面，它们之间最多就是比较有可能存在交叉线，但是交叉线比曲面低一个维度，面积（测度）是0，可忽略。从低维空间拓展到高维空间，就有了如下逻辑：因为一开始生成器随机初始化，所以$P_g$几乎不可能与$P_r$有什么关联，所以它们的支撑集之间的重叠部分要么不存在，要么就比$P_r$和$P_g$的最小维度还要低至少一个维度，故而测度为0。所谓“重叠部分测度为0”，就是上文所言“不重叠或者重叠部分可忽略”的意思。</p><p>我们就得到了WGAN前作中关于生成器梯度消失的第一个论证：在（近似）最优判别器下，最小化生成器的loss等价于最小化$P_r$与$P_g$之间的JS散度，而由于$P_r$与$P_g$几乎不可能有不可忽略的重叠，所以无论它们相距多远JS散度都是常数$log 2$，最终导致生成器的梯度（近似）为0，梯度消失。</p><h3><span id="从第二个角度论证梯度消失">从第二个角度论证梯度消失</span></h3><ul><li>首先，P_r与P_g之间几乎不可能有不可忽略的重叠，所以无论它们之间的“缝隙”多狭小，都肯定存在一个最优分割曲面把它们隔开，最多就是在那些可忽略的重叠处隔不开而已。</li><li>由于判别器作为一个神经网络可以无限拟合这个分隔曲面，所以存在一个最优判别器，对几乎所有真实样本给出概率1，对几乎所有生成样本给出概率0，而那些隔不开的部分就是难以被最优判别器分类的样本，但是它们的测度为0，可忽略。</li><li>最优判别器在真实分布和生成分布的支撑集上给出的概率都是常数（1和0），导致生成器的loss梯度为0，梯度消失。</li></ul><p>有了这些理论分析，原始GAN不稳定的原因就彻底清楚了：判别器训练得太好，生成器梯度消失，生成器loss降不下去；判别器训练得不好，生成器梯度不准，四处乱跑。只有判别器训练得不好不坏才行，但是这个火候又很难把握，甚至在同一轮训练的前后不同阶段这个火候都可能不一样，所以GAN才那么难训练。</p><p><img src="/gans-problem/1.JPG" alt></p><h2><span id="第二种原始gan形式的问题">第二种原始GAN形式的问题</span></h2><p>一句话概括：最小化第二种生成器loss函数，会等价于最小化一个不合理的距离衡量，导致两个问题，一是梯度不稳定，二是collapse mode即多样性不足。《Towards Principled Methods for Training Generative Adversarial Networks》又是从两个角度进行了论证，下面只说第一个角度.</p><p>上文提到固定G，最优的D是$D^<em>(x)=\frac{p_r(x)}{p_r(x)+p_g(x)}$， 这里，我们可以把KL散度变化成含$D^</em>$的模式：</p><p><img src="/gans-problem/9.JPG" alt></p><p>由以上公式可知：</p><p><img src="/gans-problem/10.JPG" alt></p><p>注意上式最后两项不依赖于生成器G，最终得到最小化公式3等价于最小化</p><p>$KL(P_g\mid \mid P_r)-2JS(P_r\mid \mid P_g)$ Eq.(11)</p><p>这个等价最小化目标存在两个严重的问题。</p><p>第一是它同时要最小化生成分布与真实分布的KL散度，却又要最大化两者的JS散度，一个要拉近，一个却要推远！这在直观上非常荒谬，在数值上则会导致梯度不稳定，这是后面那个JS散度项的毛病。</p><p>第二，即便是前面那个正常的KL散度项也有毛病。因为KL散度不是一个对称的衡量，$KL(P_g\mid \mid P_r)$ 与 $KL(P_r\mid \mid P_g)$ 是有差别的。以前者为例：</p><ul><li>当$P_g(x)\rightarrow0$而$P_r(x)\rightarrow1$时，$P_g(x)log\frac{P_g(x)}{P_r(x)}\rightarrow0$, 对$KL(P_g \mid \mid P_r)$的贡献趋于0.</li><li>当$P_g(x)\rightarrow1$而$P_r(x)\rightarrow0$时，$P_g(x)log\frac{P_g(x)}{P_r(x)}\rightarrow+\infty$, 对$KL(P_g \mid \mid P_r)$的贡献趋于无穷大.</li></ul><p>换言之，$KL(P_g \mid \mid  P_r)$ 对于上面两种错误的惩罚是不一样的，第一种错误对应的是“生成器没能生成真实的样本”，惩罚微小；第二种错误对应的是“生成器生成了不真实的样本” ，惩罚巨大。第一种错误对应的是缺乏多样性，第二种错误对应的是缺乏准确性。这一放一打之下，生成器宁可多生成一些重复但是很“安全”的样本，也不愿意去生成多样性的样本，因为那样一不小心就会产生第二种错误，得不偿失。这种现象就是大家常说的collapse mode。</p><p>第一部分小结：在原始GAN的（近似）最优判别器下，第一种生成器loss面临梯度消失问题，第二种生成器loss面临优化目标荒谬、梯度不稳定、对多样性与准确性惩罚不平衡导致mode collapse这几个问题。</p><p>关于实验证明，可以参考paper原文</p><h1><span id="2wgan之前的一个过渡解决方案">2.WGAN之前的一个过渡解决方案</span></h1><p>原始GAN问题的根源可以归结为两点，一是等价优化的距离衡量（KL散度、JS散度）不合理，二是生成器随机初始化后的生成分布很难与真实分布有不可忽略的重叠。</p><p>WGAN前作其实已经针对第二点提出了一个解决方案，就是对生成样本和真实样本加噪声，直观上说，使得原本的两个低维流形“弥散”到整个高维空间，强行让它们产生不可忽略的重叠。而一旦存在重叠，JS散度就能真正发挥作用，此时如果两个分布越靠近，它们“弥散”出来的部分重叠得越多，JS散度也会越小而不会一直是一个常数，于是（在第一种原始GAN形式下）梯度消失的问题就解决了。在训练过程中，我们可以对所加的噪声进行退火（annealing），慢慢减小其方差，到后面两个低维流形“本体”都已经有重叠时，就算把噪声完全拿掉，JS散度也能照样发挥作用，继续产生有意义的梯度把两个低维流形拉近，直到它们接近完全重合。以上是对原文的直观解释。</p><p>在这个解决方案下我们可以放心地把判别器训练到接近最优，不必担心梯度消失的问题。而当判别器最优时，对公式9取反可得判别器的最小loss为：</p><p><img src="/gans-problem/11.JPG" alt></p><p>其中$P_{r+\epsilon},P_{g+\epsilon}$ 分别是加噪声后的真实分布与生成分布。反过来说，从最优判别器的loss可以反推出当前两个加噪分布的JS散度。两个加噪分布的JS散度可以在某种程度上代表两个原本分布的距离，也就是说可以通过最优判别器的loss反映训练进程！</p><p>但是，因为加噪JS散度的具体数值受到噪声的方差影响，随着噪声的退火，前后的数值就没法比较了，所以它不能成为$P_r$和$P_g$距离的本质性衡量。加噪方案是针对原始GAN问题的第二点根源提出的，解决了训练不稳定的问题，不需要小心平衡判别器训练的火候，可以放心地把判别器训练到接近最优，但是仍然没能够提供一个衡量训练进程的数值指标。但是WGAN本作就从第一点根源出发，用Wasserstein距离代替JS散度，同时完成了稳定训练和进程指标的问题！</p><h1><span id="3wasserstein距离的优越性质">3.Wasserstein距离的优越性质</span></h1><p>Wasserstein距离又叫Earth-Mover（EM）距离，定义如下：</p><p>$W(P_r,P_g)=\mathop{inf}\limits_{r\sim \prod(P_r,P_g)}E_{(x,y)\sim\gamma}[\mid \mid x-y\mid \mid ]$ Eq.(12)</p><p>解释说明：$\prod(P_r,P_g)$ 是$P_r$,$P_g$组合起来的所有可能的联合分布的集合，反过来讲，$\prod(P_r,P_g)$ 中每一个分布的边缘分布都是 $P_r$ 和$P_g$. 对于每一个可能的联合分布 $\gamma$ 而言，可以从中采样 $(x,y)\sim \gamma$  得到一个真实样本 $x$ 和一个生成样本 $y$ , 并算出这对样本的距离 $\mid \mid x-y\mid \mid$, 所以可以计算该联合分布 $\gamma$ 下样本对距离的期望值 $\mathbb{E}_{(x, y) \sim \gamma} [\mid \mid x - y\mid \mid]$ 。在所有可能的联合分布中能够对这个期望值取到的下界 $W(P_r,P_g)$ ，就定义为Wasserstein距离。</p><p>直观上可以把 $\mathbb{E}_{(x, y) \sim \gamma} [\mid \mid x - y\mid \mid]$ 理解为在 $\gamma$ 这个“路径规划”下把 $P_r$ 这堆“沙土”挪到 $P_g$ “位置”所需的“消耗”，而 $W(P_r, P_g)$ 就是“最优路径规划”下的“最小消耗”，所以才叫Earth-Mover（推土机）距离。</p><p>Wasserstein距离相比KL散度、JS散度的优越性在于，即便两个分布没有重叠，Wasserstein距离仍然能够反映它们的远近。WGAN本作通过简单的例子展示了这一点。考虑如下二维空间中的两个分布 $P_1$ 和 $P_2$，$P_1$在线段AB上均匀分布， $P_2$ 在线段CD上均匀分布，通过控制参数 $\theta$ 可以控制着两个分布的距离远近。</p><p><img src="/gans-problem/2.JPG" alt></p><p>此时容易得到</p><p><img src="/gans-problem/3.JPG" alt></p><p>KL散度和JS散度是突变的，要么最大要么最小，Wasserstein距离却是平滑的，如果我们要用梯度下降法优化 $\theta$ 这个参数，前两者根本提供不了梯度，Wasserstein距离却可以。类似地，在高维空间中如果两个分布不重叠或者重叠部分可忽略，则KL和JS既反映不了远近，也提供不了梯度，但是Wasserstein却可以提供有意义的梯度。</p><h1><span id="4从wasserstein距离到wgan">4.从Wasserstein距离到WGAN</span></h1><p>既然Wasserstein距离有如此优越的性质，如果我们能够把它定义为生成器的loss，不就可以产生有意义的梯度来更新生成器，使得生成分布被拉向真实分布吗？</p><p>没那么简单，因为Wasserstein距离定义（公式12）中的 $\inf_{\gamma \sim \Pi (P_r, P_g)}$ 没法直接求解，不过没关系，作者用了一个已有的定理把它变换为如下形式:</p><p>$W(P_r, P_g) = \frac{1}{K} \sup_{\mid \mid f\mid\mid_L \leq K} \mathbb{E}<em>{x \sim P_r} [f(x)] - \mathbb{E}</em>{x \sim P_g} [f(x)]$（公式13）</p><p>证明过程见paper附录。</p><p>首先需要介绍一个概念——Lipschitz连续。它其实就是在一个连续函数 $f$ 上面额外施加了一个限制，要求存在一个常数 $K\geq 0$ 使得定义域内的任意两个元素 $x_1$ 和 $x_2$ 都满足</p><p>$\mid f(x_1) - f(x_2)\mid \leq K \mid x_1 - x_2\mid$</p><p>此时称函数 $f$ 的Lipschitz常数为K。</p><p>简单理解，比如说 $f$ 的定义域是实数集合，那上面的要求就等价于 $f$ 的导函数绝对值不超过K。再比如说 $\log (x)$ 就不是Lipschitz连续，因为它的导函数没有上界。Lipschitz连续条件限制了一个连续函数的最大局部变动幅度。</p><p>公式13的意思就是在要求函数f的Lipschitz常数 $\mid \mid f\mid \mid_L$ 不超过K的条件下，对所有可能满足条件的 $f$ 取到 $\mathbb{E}<em>{x \sim P_r} [f(x)] - \mathbb{E}</em>{x \sim P_g} [f(x)]$ 的上界，然后再除以 $K$。特别地，我们可以用一组参数w来定义一系列可能的函数 $f_w$，此时求解公式13可以近似变成求解如下形式</p><p>$K \cdot W(P_r, P_g) \approx \max_{w: \mid f_w\mid_L \leq K} \mathbb{E}<em>{x \sim P_r} [f_w(x)] - \mathbb{E}</em>{x \sim P_g} [f_w(x)]$（公式14）</p><p>由于神经网络的拟合能力足够强大，我们有理由相信，这样定义出来的一系列 $f_w$ 虽然无法囊括所有可能，但是也足以高度近似公式13要求的那个 $sup_{\mid \mid f\mid \mid_L \leq K}$ 了。</p><p>最后，还不能忘了满足公式14中 $\mid \mid f_w\mid \mid_L \leq K$ 这个限制。我们其实不关心具体的K是多少，只要它不是正无穷就行，因为它只是会使得梯度变大K倍，并不会影响梯度的方向。所以作者采取了一个非常简单的做法，就是限制神经网络 $f_\theta$ 的所有参数 $w_i$ 的不超过某个范围 $[-c, c]$，比如 $w_i \in [- 0.01, 0.01]$，此时关于输入样本x的导数 $\frac{\partial f_w}{\partial x}$ 也不会超过某个范围，所以一定存在某个不知道的常数K使得 $f_w$ 的局部变动幅度不会超过它，Lipschitz连续条件得以满足。具体在算法实现中，只需要每次更新完w后把它clip回这个范围就可以了。</p><p>到此为止，我们可以构造一个含参数w、最后一层不是非线性激活层的判别器网络 $f_w$ ，在限制w不超过某个范围的条件下，使得</p><p>$L = \mathbb{E}<em>{x \sim P_r} [f_w(x)] - \mathbb{E}</em>{x \sim P_g} [f_w(x)]$ （公式15）</p><p>尽可能取到最大，此时L就会近似真实分布与生成分布之间的Wasserstein距离（忽略常数倍数K）。注意原始GAN的判别器做的是真假二分类任务，所以最后一层是sigmoid，但是现在WGAN中的判别器 $f_w$ 做的是近似拟合Wasserstein距离，属于回归任务，所以要把最后一层的sigmoid拿掉。</p><p>接下来生成器要近似地最小化Wasserstein距离，可以最小化L，由于Wasserstein距离的优良性质，我们不需要担心生成器梯度消失的问题。再考虑到L的第一项与生成器无关，就得到了WGAN的两个loss。</p><p>$- \mathbb{E}_{x \sim P_g} [f_w(x)]$（公式16，WGAN生成器loss函数）</p><p>$\mathbb{E}<em>{x \sim P_g} [f_w(x)]- \mathbb{E}</em>{x \sim P_r} [f_w(x)]$（公式17，WGAN判别器loss函数）</p><p>公式15是公式17的反，可以指示训练进程，其数值越小，表示真实分布与生成分布的Wasserstein距离越小，GAN训练得越好。</p><p><img src="/gans-problem/4.JPG" alt></p><p>上文说过，WGAN与原始GAN第一种形式相比，只改了四点：</p><ul><li>判别器最后一层去掉sigmoid</li><li>生成器和判别器的loss不取log</li><li>每次更新判别器的参数之后把它们的绝对值截断到不超过一个固定常数c</li><li>不要用基于动量的优化算法（包括momentum和Adam），推荐RMSProp，SGD也行</li></ul><p>前三点都是从理论分析中得到的，已经介绍完毕；第四点却是作者从实验中发现的，属于trick，相对比较“玄”。作者发现如果使用Adam，判别器的loss有时候会崩掉，当它崩掉时，Adam给出的更新方向与梯度方向夹角的cos值就变成负数，更新方向与梯度方向南辕北辙，这意味着判别器的loss梯度是不稳定的，所以不适合用Adam这类基于动量的优化算法。作者改用RMSProp之后，问题就解决了，因为RMSProp适合梯度不稳定的情况。</p><p>实验验证：</p><p>1.判别器所近似的Wasserstein距离与生成器的生成图片质量高度相关，如下所示（此即题图）：</p><p><img src="/gans-problem/5.JPG" alt></p><p>2.WGAN如果用类似DCGAN架构，生成图片的效果与DCGAN差不多：</p><p><img src="/gans-problem/6.JPG" alt></p><p>但是厉害的地方在于WGAN不用DCGAN各种特殊的架构设计也能做到不错的效果，比如如果大家一起拿掉Batch Normalization的话，DCGAN就崩了：</p><p><img src="/gans-problem/7.JPG" alt></p><p>如果WGAN和原始GAN都使用多层全连接网络（MLP），不用CNN，WGAN质量会变差些，但是原始GAN不仅质量变得更差，而且还出现了collapse mode，即多样性不足：</p><p><img src="/gans-problem/8.JPG" alt></p><p>3.在所有WGAN的实验中未观察到collapse mode。</p><p>相比于判别器迭代次数的改变，对判别器架构超参的改变会直接影响到对应的Lipschitz常数K，进而改变近似Wasserstein距离的倍数，前后两轮训练的指标就肯定不能比较了，这是需要在实际应用中注意的。对此我想到了一个工程化的解决方式，不是很优雅：取同样一对生成分布和真实分布，让前后两个不同架构的判别器各自拟合到收敛，看收敛到的指标差多少倍，可以近似认为是后面的K_2相对前面K_1的变化倍数，于是就可以用这个变化倍数校正前后两轮训练的指标。</p><h1><span id="总结">总结</span></h1><p>《Towards Principled Methods for Training Generative Adversarial Networks》分析了Ian Goodfellow提出的原始GAN两种形式各自的问题，第一种形式等价在最优判别器下等价于最小化生成分布与真实分布之间的JS散度，由于随机生成分布很难与真实分布有不可忽略的重叠以及JS散度的突变特性，使得生成器面临梯度消失的问题；第二种形式在最优判别器下等价于既要最小化生成分布与真实分布直接的KL散度，又要最大化其JS散度，相互矛盾，导致梯度不稳定，而且KL散度的不对称性使得生成器宁可丧失多样性也不愿丧失准确性，导致collapse mode现象。</p><p>《Towards Principled Methods for Training Generative Adversarial Networks》针对分布重叠问题提出了一个过渡解决方案，通过对生成样本和真实样本加噪声使得两个分布产生重叠，理论上可以解决训练不稳定的问题，可以放心训练判别器到接近最优，但是未能提供一个指示训练进程的可靠指标，也未做实验验证。</p><p>WGAN引入了Wasserstein距离，由于它相对KL散度与JS散度具有优越的平滑特性，理论上可以解决梯度消失问题。接着通过数学变换将Wasserstein距离写成可求解的形式，利用一个参数数值范围受限的判别器神经网络来最大化这个形式，就可以近似Wasserstein距离。在此近似最优判别器下优化生成器使得Wasserstein距离缩小，就能有效拉近生成分布与真实分布。WGAN既解决了训练不稳定的问题，也提供了一个可靠的训练进程指标，而且该指标确实与生成样本的质量高度相关。作者对WGAN进行了实验验证。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;自从2014年Ian Goodfellow提出以来，GAN就存在着训练困难、生成器和判别器的loss无法指示训练进程、生成样本缺乏多样性等问题。从那时起，很多论文都在尝试解决，但是效果不尽人意，比如最有名的一个改进DCGAN依靠的是对判别器和生成器的架构进行实验枚举，最终找
      
    
    </summary>
    
      <category term="Deep learning" scheme="http://dinry.github.io/categories/Deep-learning/"/>
    
    
      <category term="GAN" scheme="http://dinry.github.io/tags/GAN/"/>
    
  </entry>
  
  <entry>
    <title>gan application</title>
    <link href="http://dinry.github.io/gan-application/"/>
    <id>http://dinry.github.io/gan-application/</id>
    <published>2019-06-18T13:28:59.000Z</published>
    <updated>2019-06-18T13:35:34.478Z</updated>
    
    <content type="html"><![CDATA[<p>自2014年Ian Goodfellow提出了GAN（Generative Adversarial Network）以来，对GAN的研究可谓如火如荼。各种GAN的变体不断涌现，下图是GAN相关论文的发表情况：</p><p><img src="/gan-application/1.jpg" alt></p><h1><span id="gans-现在可以做什么">GANs 现在可以做什么？</span></h1><p><img src="/gan-application/3.jpg" alt></p><h1><span id="gan应用史">GAN应用史</span></h1><p>首先简单介绍一下GAN出现以来GAN变体们的进化史：</p><h4><span id="gan的cv史">GAN的CV史</span></h4><ul><li>GAN最初用来生成一维信号（语言，语音）以及简单的二维信号（minist）</li><li>后续研究者提出DCGAN， 可以相对更有效的生成二维的图像信号（但分辨率仍然很小，多数只有 64<em>64 或 128</em>128 ）,这是 GAN 首次在图像生成取得很大的进步。</li><li>2016年，商汤-香港中文大学联合实验室与罗格斯大学等机构提出了 StackGAN 算法，发明了更好的神经网路结构，将生成图像的分辨率从 $128<em>128$ 大幅提升到 $256</em>256$。</li><li>随后， NVIDIA 一篇以名人的脸孔为训练素材，生成出相当逼真的假名人照的论文，将分辨率一举拉高到 1024*1024，立刻令外界惊叹，GAN 一战成名。</li><li>今天，GAN不仅在二维图像的生成上有成熟的发展与应用，在三维信号以及高维信号的应用上也取得了不错的进步，例如视频生成，三维重建等。</li></ul><p>详细的展示将以几篇优秀的论文呈现</p><h4><span id="gan新的网络结构">GAN新的网络结构</span></h4><p>GAN变体如火如荼地今天，不仅出现了很多应用，也出现了一些网络结构上的改进.例如 CGAN, cycleGAN, DualGAN, DiscoGAN, TripleGAN...</p><p>本博客将展示CGAN, cycleGAN，stackgan,stylegan等</p><h4><span id="gan的对抗思想被其他深度学习应用引入目标检测-对抗攻击-信息检索-贝叶斯理论-capsule-强化学习-离散输出nlp-自编码器-半监督学习增强了原始应用的性能">GAN的对抗思想被其他深度学习应用引入(目标检测、对抗攻击、信息检索、贝叶斯理论、Capsule、强化学习、离散输出“NLP”、自编码器、半监督学习，增强了原始应用的性能。</span></h4><p>一开始外界普遍认为 GAN 只是一个生成模型，不过其实对抗性的思想对于改进现有 AI 算法同样很有帮助。举例来说，传统的深度学习算法可以看作 GAN 的生成器，引入鉴别器后，可以改良原有模型的任务表现，让现有 AI 算法做的更好、生成更接近真实的结果。商汤－香港中大联合实验室教授吕建勤从事研究 GAN 进行图像超分辨率，不仅是把低分辨率的图像提高，将其变为高分辨率图像，还可以近一步自动美化图像的风格和细节。</p><p>另一位商汤－香港中大联合实验室教授林达华则是以 GAN 增强图像标题生成的真实性。图像标题生成主要是希望通过计算机看懂图像，并且用自然语言来描述图像内容，加入鉴别器可以判断这句话是人类撰写还是电脑生成的，借由这种方式让原来 AI 模型生成的标题更有“人味”、更自然。也有许多从业者将 GAN 引入机器翻译、人脸识别、信息检索等方向，在去年取得很好的突破。</p><p><img src="/gan-application/2.jpg" alt></p><p>本博客主要介绍IRGAN，graphgan,SeqGAN</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;自2014年Ian Goodfellow提出了GAN（Generative Adversarial Network）以来，对GAN的研究可谓如火如荼。各种GAN的变体不断涌现，下图是GAN相关论文的发表情况：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/gan-applicatio
      
    
    </summary>
    
      <category term="Deep learning" scheme="http://dinry.github.io/categories/Deep-learning/"/>
    
    
      <category term="GAN" scheme="http://dinry.github.io/tags/GAN/"/>
    
  </entry>
  
  <entry>
    <title>GAN theory</title>
    <link href="http://dinry.github.io/GAN-theory/"/>
    <id>http://dinry.github.io/GAN-theory/</id>
    <published>2019-06-18T13:23:27.000Z</published>
    <updated>2019-06-18T13:27:41.404Z</updated>
    
    <content type="html"><![CDATA[<p>from 《Generative Adversarial Nets》 NIPS 2014 by Goodfellow.</p><h1><span id="1gan的基本思想">1.GAN的基本思想</span></h1><p>GAN通过博弈的思想来训练生成模型与对狼模型，基本思想不再重复阐述，可用如下图替代。</p><p><img src="/GAN-theory/1.JPG" alt></p><h1><span id="2gan的基本框架">2.GAN的基本框架</span></h1><p>在下面的示例图像中，蓝色区域显示了图像空间中包含真实图像的部分，具有很高的概率(超过某个阈值)，黑点表示我们的数据点(每个点是数据集中的一个图像)。现在，生成模型描述分布 $\hat{p}_\theta(x)$ (绿色)，它是通过从一个单位高斯分布(红色)中取点并通过一个(确定性)神经网络映射它们隐式定义的——我们的生成模型(黄色)。我们的神经网络是含参数 $\theta$ 的函数， 调整这些参数将调整生成的采样分布。我们的目标是生成一个分布（参数θ）匹配真实数据分布(例如,通过KL散度)。因此,你可以想象绿色分布随机,然后开始训练，迭代的改变参数使生成分布更接近真实分布。</p><p><img src="/GAN-theory/2.JPG" alt></p><h1><span id="3常用散度">3.常用散度</span></h1><p>散度是用来衡量两个分布之间差异的指标，因此，在讲解GAN原理之前，我要首先讲一下在GAN中用到的几个散度。s</p><h3><span id="31kl">3.1.KL</span></h3><p>KL散度又称relative entropy, 是信息论中的定义，是是两个概率分布P和Q差别的非对称性的度量。</p><h5><span id="维基百科中这样定义">维基百科中这样定义：</span></h5><ul><li><p>对于离散随机变量，概率分布P 和 Q的KL散度可按下式定义为：</p><p>$KL(P \mid \mid Q)= \sum_i P(i)log\frac{P(i)}{Q(i)}$.</p><p>即按概率P求得的P和Q的对数商的平均值。KL散度仅当概率P和Q各自总和均为1，且对于任何i皆满足 $Q(i)&gt;0$及 $P(i)&gt;0$ 时，才有定义。式中出现 $0log 0$ 的情况，其值按0处理。</p></li><li><p>对于连续随机变量，其概率分布P和Q可按积分方式定义为:</p><p>$KL(P \mid \mid Q)= E_{i\sim P}log\frac{P}{Q}$</p><p>即为P关于Q的相对熵。</p></li></ul><h5><span id="特性">特性</span></h5><ul><li>相对熵的值为非负数</li><li>当且仅当P=Q时，相对熵为0</li><li>尽管从直觉上KL散度是个度量或距离函数, 但是它实际上并不是一个真正的度量或距离。因为KL散度不具有对称性：从分布P到Q的距离通常并不等于从Q到P的距离。$KL(P\mid \mid Q)\neq KL(Q\mid \mid P)$, 这也是在距离度量中的一大忌。</li></ul><h3><span id="32js">3.2.JS</span></h3><p>由于KL散度不具有对称性，用其衡量距离是行不通的，所以，在KL散度的基础上又出现了JS散度，JS散度既保留了KL散度的优点，又解决的对称问题：</p><p>$JS(P1\mid \mid P2)=\frac{1}{2}KL(P_1\mid \mid \frac{P_1+P_2}{2})+\frac{1}{2}KL(P_2\mid \mid \frac{P_1+P_2}{2})$</p><p>原始GAN是基于JS散度的度量，但经过实践与理论的分析，人们渐渐摒弃了这种度量方式，改用Wasserstein距离，关于原因参见我的另一篇博客《GAN'S problem》,这里只简要介绍Wasserstein距离的定义。</p><h3><span id="33wasserstein距离">3.3.Wasserstein距离</span></h3><p>Wasserstein距离又叫Earth-Mover距离(EM距离)，用于衡量两个分布之间的距离，定义：</p><p>$W(P_r,P_g)=\mathop{inf}\limits_{r\sim \prod(P_r,P_g)}E_{(x,y)\sim\gamma}[\mid \mid x-y\mid \mid ]$</p><p>解释说明：$\prod(P_r,P_g)$ 是$P_r$,$P_g$组合起来的所有可能的联合分布的集合，反过来讲，$\prod(P_r,P_g)$ 中每一个分布的边缘分布都是 $P_r$ 和$P_g$. 对于每一个可能的联合分布 $\gamma$ 而言，可以从中采样 $(x,y)\sim \gamma$  得到一个真实样本 $x$ 和一个生成样本 $y$ , 并算出这对样本的距离 $\mid \mid x-y\mid \mid$, 所以可以计算该联合分布 $\gamma$ 下样本对距离的期望值 $\mathbb{E}_{(x, y) \sim \gamma} [\mid \mid x - y\mid \mid]$ 。在所有可能的联合分布中能够对这个期望值取到的下界 $W(P_r,P_g)$ ，就定义为Wasserstein距离。</p><p>直观上可以把 $\mathbb{E}_{(x, y) \sim \gamma} [\mid \mid x - y\mid \mid]$ 理解为在 $\gamma$ 这个“路径规划”下把 $P_r$ 这堆“沙土”挪到 $P_g$ “位置”所需的“消耗”，而 $W(P_r, P_g)$ 就是“最优路径规划”下的“最小消耗”，所以才叫Earth-Mover（推土机）距离。</p><p>Wasserstein距离相比KL散度、JS散度的优越性在于，即便两个分布没有重叠，Wasserstein距离仍然能够反映它们的远近。WGAN本作通过简单的例子展示了这一点。考虑如下二维空间中的两个分布 $P_1$ 和 $P_2$，$P_1$在线段AB上均匀分布， $P_2$ 在线段CD上均匀分布，通过控制参数 $\theta$ 可以控制着两个分布的距离远近。</p><h1><span id="4gan原理">4.GAN原理</span></h1><p>GAN的思想启发自博弈论中的零和游戏，包含一个生成网络G和一个判别网络D。</p><h4><span id="41-目标函数">4.1 目标函数：</span></h4><p><img src="/GAN-theory/3.JPG" alt="GAN_objective function"></p><h4><span id="42-workflow">4.2 workflow</span></h4><p><img src="/GAN-theory/4.JPG" alt></p><h4><span id="43-算法">4.3 算法：</span></h4><p><img src="/GAN-theory/5.JPG" alt></p><h4><span id="44-优化-p_gp_data">4.4 优化 $p_g=p_{data}$</span></h4><p>1.首先固定G，优化D。 对D的目标函数求导，并验证最优解即最大值为：</p><p>$D_G^*(x)=\frac{p_{data}}{p_{data}(x)+p_{g}(x)}$</p><p>proof 如下：</p><p><img src="/GAN-theory/6.JPG" alt></p><p>因此目标函数可重写为：</p><p><img src="/GAN-theory/7.JPG" alt></p><p>2.接下来固定D， 训练G，在G的全局最小值处，目标函数为$-log4$.</p><p>证明过程如下：</p><p><img src="/GAN-theory/8.JPG" alt></p><p>在当前最优的D下，G的目标函数为 $-log4+2*JS(p_{data}\mid \mid p_{g})$,由于两分布是非负的，所以G的全局最优解为-log4, 此时 $p_{data}=p_{g}$.</p><p>最后可以证明当且仅当$p_{data}=p_{g}$,</p><h4><span id="45-收敛性">4.5 收敛性</span></h4><p>原文中给出证明，如果G和D有足够的能力，那么给定G，D可以达到最优解， 并且$p_g$ 可以更新来优化目标函数，使得 $p_{g}$ 收敛于$p_{data}$.</p><p>证明过程：</p><p><img src="/GAN-theory/9.JPG" alt></p><h1><span id="gan特性">GAN特性</span></h1><h4><span id="优点">优点：</span></h4><ul><li>计算梯度时只用到了反向传播，而不需要马尔科夫链。</li><li>训练时不需要对隐变量做推断。</li><li>理论上，只要是可微分函数都能用于构建D和G，因而能够与深度学习结合来学   习深度产生式网络（deep generative model）。</li><li>统计角度上来看，G的参数更新不是直接来自于数据样本，而是使用来自D的反传梯度。</li></ul><h4><span id="缺点">缺点</span></h4><ul><li>生成器的分布没有显示的表达</li><li>比较难训练，D与G之间需要很好的同步，例如D更新k次而G更新1次。将在后文中介绍GAN的缺点与训练技巧</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;from 《Generative Adversarial Nets》 NIPS 2014 by Goodfellow.&lt;/p&gt;
&lt;h1&gt;&lt;span id=&quot;1gan的基本思想&quot;&gt;1.GAN的基本思想&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;GAN通过博弈的思想来训练生成模型与对狼模型
      
    
    </summary>
    
      <category term="Deep learning" scheme="http://dinry.github.io/categories/Deep-learning/"/>
    
    
      <category term="GAN" scheme="http://dinry.github.io/tags/GAN/"/>
    
  </entry>
  
  <entry>
    <title>generate model</title>
    <link href="http://dinry.github.io/generate-model/"/>
    <id>http://dinry.github.io/generate-model/</id>
    <published>2019-06-18T05:54:41.000Z</published>
    <updated>2019-06-18T13:20:25.827Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="生成模型">生成模型</span></h1><p>生成模型(generative model)描述的是这一类的模型：接收了从分布 $p_{data}$ 取样的若干样本构成我们的训练集，然后让模型学习到一个模拟这一分布的概率分布$p_{model}$.</p><p><img src="/generate-model/p5.JPG" alt></p><p>在有些情况下，我们可以直接的估计概率分布，如下图所示的密度概率分布模型：</p><p><img src="/generate-model/p1.jpg" alt="Image of gen models"></p><p>有些情况，我们需要从中生成一些样本，如下图所示训练数据为ImageNet中的样本，训练的生成模型可以生成以假乱真的图片：</p><p><img src="/generate-model/p2.JPG" alt="Image of gen models"></p><h1><span id="为什么研究生成模型">为什么研究生成模型</span></h1><p>那么研究生成模型的意义何在呢？尤其是对于非直接密度估计而只能从模型中生成样本的一类情况，特别是对于图像，这类模型只能提供更多的图像，而我们并不缺少海量的图像。</p><p>主要原因如下：</p><ul><li>这是对我们能够表示和操控高维概率分布的能力的有效检验。</li><li>我们可以将生成模型结合到强化学习(reinforcement learning)中，例如对于model-based RL可用生成模型来模拟可能发生的未来情况，以便RL算法进行规划(planning)，例如 Deep Visual Foresight for Planning Robot Motion。</li><li>生成模型可以用有损失（部分样本无标记）的数据进行训练，进行半监督学习(semi-supervised learning)，降低了我们获得数据样本的难度。</li><li>生成模型可以处理多峰值(multi-modal)的输出。对于很多任务，一个输入可能对应多个可能的输出，一些传统的机器学习模型只能学到一种输出而无法学习多种可能的输出。</li><li>还有一些任务需要产生看起来真实的样本。如由低分辨率图片产生高分辨率图片，图像转换等等。</li></ul><p><img src="/generate-model/p3.JPG" alt="Image of gen models"></p><p>输入低分辨率图片，生成模型产生接近原分辨率的图片。</p><p><img src="/generate-model/p4.JPG" alt="Image of gen models"></p><p>从街道轮廓图生成真实图，从卫星图片生成地图，从草图生成真实图片</p><h1><span id="生成模型分类">生成模型分类</span></h1><p>那么生成模型是如何工作的呢？为了简化讨论，我们这里考虑符合最大似然(maximum likelihood)原则(可参考最大似然法与最大后验概率估计——深度学习花书第五章（三）)的生成模型。其基本思想是模型是带有参数 $\theta$ 的概率分布的估计，则模型给予m个训练样本的似然率为 $\prod_{i=1}^m p_{model}(c^{(i)};\theta)$, 最大似然原则就是选择使该概率最大的参数。即</p><p>$\theta^* = \mathop{argmax}\limits_{\theta}\prod_{i=1}^m p_{model}(c^{(i)};\theta)$</p><p>$=\mathop{argmax}\limits_{\theta} log \prod_{i=1}^m p_{model}(c^{(i)};\theta)$</p><p>$=\mathop{argmax}\limits_{\theta}\sum_{i=1}^m log p_{model}(c^{(i)};\theta)$</p><p>其过程如下图所示，模型会逐渐将训练数据所处的概率增大。</p><p><img src="/generate-model/p7.JPG" alt="Image of gen models"></p><p>另一方面，我们也可以将最大似然近似看做是使模型与数据分布KL divergence（可参考概率论——深度学习花书第三章）最小的参数,即：</p><p>$\theta^* = \mathop{argmin}\limits_{\theta}D_{KL}(p_{data}(x) \mid\mid p_{model}(x;\theta))$</p><p><img src="/generate-model/p6.JPG" alt></p><p>先来看看左边一支Explicit density显性密度模型，即显性的定义密度分布 $p_{model}(x;\theta)$ ，对于这类模型，似然率最大化的过程比较直接：我们将密度分布代入到似然率的表达式中，然后沿着梯度上升的方向更新模型即可，但其难点在于如何定义模型使得其既能表达数据的复杂度同时又方便计算。大致有两种方式：</p><ul><li><p>Tractable explicit model（易解显性模型），即定义一个方便计算的密度分布，主要一类模型是Fully visible belief nets，简称FVBN，也被称作Auto-Regressive Network，这一类模型利用了概率的链式法则，转化为条件概率的联乘积形式,NADE,PixelRNN,PixelCNN都属于这一类模型，许多更复杂的模型也是基于这一类模型，例如DeepMind的语音合成模型WaveNet。这类模型一大缺点是模型之后的元素值值得生成依赖于之前的元素值，即我们需要先生成$x_1$再生成$x_2$，其效率较低。其优点是由于直接定义了可解的密度分布，我们可直接应用基于训练数据对数似然率的优化模型，但同时这也限制了可供选择的密度分布类型。</p></li><li><p>Approximate explicit model（近似显性模型）可以避免需要设定可解的密度分布的限制，其密度分布可以是那一计算的，但可用一些近似方法来求最大似然率。这又可以分为两类，即确定性近似（deterministic approximation），通常是指变分近似（可参考变分推断——深度学习第十九章），即转化为Evidence lower bound的极值问题，之后会详细总结变分自编码器VAE。这一方法的缺点是现在VAE生成的图片都比较模糊，对于这一现象暂时还没有很好的解释。另一类是随机近似(stochastic approximation)，如MCMC方法（可参考蒙特卡罗方法——深度学习第十七章），如果样本可以较快的产生且各样本之间的方差较小，可以利用MCMC，但我们之前在第十七章也看到这一方法混合时间较长且没有很好的方法判断是否已经converge，所以效率较低。</p></li></ul><p>再来看右边一支Implicit density model隐性密度模型，即不明确定义模型密度分布，而是非直接的与  作用，即从中取样，也可以分为两类：</p><ul><li>也是利用达到平稳分布后的马尔科夫链来取样，如generative stochastic network(生成随机网络)，简称GSN。马尔科夫链的缺点如难以拓展到高维空间，巨大的计算量等缺点也适用于这种模型。</li><li>Generative Adversarial Network(生成对抗网络)，简称GAN，这一模型取样时只需要进行一步，而不需要利用马尔科夫链运行若干次直至达到平稳分布，所以采样效率很高。其基本思想是利用生成神经网络和鉴别神经网络两个网络相互对抗，达到纳什均衡。其优点是可以并行的产生样本，不需要马尔科夫链，效率高；生成函数没有限制，可以表达很多种分布；实际中GAN生成的样本视觉上较其他方法好。当然，由于它不再是优化问题，而是需要找到纳什均衡，所以训练过程不够稳定。</li></ul><p>现在比较常用的是FVBN，VAE与GAN</p><h2><span id="玻尔兹曼机">玻尔兹曼机</span></h2><p>玻尔兹曼机是一种基于能量函数的概率模型，其联合分布概率可表示为 $p(\overline{v},\overline{h}) = \frac {exp(-E(\overline{v},\overline{h}))}{Z}$, 其中$\overline{v}$ 代表了输入的观察到的变量，$\overline{h}$代表了隐藏变量，Z是分配函数，Restricted Boltzmann machine对这一能量函数进一步简化，假定了网络中仅有隐藏变量与观察变量的连接，而观察变量间没有连接，隐藏变量间也没有连接，且隐藏变量可用$n_h$个二进制随机变量表示，如下图的无向图所示:</p><p><img src="/generate-model/p8.JPG" alt></p><h2><span id="生成随机网络">生成随机网络</span></h2><p>再来看看另一种利用马尔科夫链采样的生成模型，生成随机网络GSN，与玻尔兹曼机相比，它不是显性的定义观察量与隐藏量的联合分布，而是在马尔科夫链中利用了两个条件概率分布：</p><p>1.$p(x^k\mid h^k)$ 指导如何根据现在的隐藏变量产生下一个观察量。</p><p>2.$p(h^k\mid h^{k-1},x^{k-1})$ 根据前一个状态的隐藏变量和观察量更新隐藏变量。</p><p>联合概率分布只是隐性定义的，是马尔科夫链的稳态分布。</p><h2><span id="自回归网络">自回归网络</span></h2><p>自回归网络Auto-Regressive Networks，又叫做Fully-visible Bayes networks(FVBN)，是一种有向概率图，其中条件概率用神经网络来表示，利用概率的链式法则，它将关于观察量的联合概率分布，分为一系列条件概率$p(x_i\mid x_{i-1},...,x_1)$ 的乘积形式</p><p>$p(x)=\prod_{i=1}^{n_i} p(x_i\mid x_{i-1},...,x_1)$</p><p>简单的线性自回归网络结构没有隐藏变量，也不共享特征或参数，如下图所示</p><p><img src="/generate-model/p9.JPG" alt="上图是FVBN的有向图表示，下图是相应的计算图"></p><p>如果我们想增大模型的容量，使其可以近似任意联合概率分布，则可以加入隐藏变量，另外还可以通过特征或参数共享使得泛化效果更好，其计算图如下所示:</p><p><img src="/generate-model/p10.JPG" alt></p><p>其优点有在可以表述随机变量的高阶依赖关系的同时减少了模型所需要的参数，例如假设变量可取离散的k种不同的值，则每个$p(x_i\mid x_{i-1},...,x_1)$ 可用有$(i-1)*k$ 个输入及k个输出的神经网络表示，而不需要指数级别的参数。另一个优点是我们不需要对于每一个$x_i$ 都采用一个不同的神经网络，而是将它们合并为一个神经网络，即用来预测$x_i$ 的隐藏特征可以被重复利用来对$x_{i+k}(k&gt;0)$ 进行预测，这些隐藏单位的参数因此可以通过联合优化使得序列中所有变量的预测都得到改善。</p><p>在生成图像时，FVBN类模型通常能够得到更高质量的图片，由于其直接模拟概率分布，更容易评估训练效果，其训练过程也较GAN稳定，但是由于其训练过程的序列性，训练过程较为缓慢。</p><p>FVBN有两类模型PixelRNN和PixelCNN.在图像合成方面应用广泛，尤其是由残缺图像补全完整图像的应用。其基本思想是从某个角落里开始，依据之前的像素信息利用RNN或CNN来预测下一个位置的像素值。对于PixelRNN其过程如下图所示，其中与之前变量的依赖关系用RNN如LSTM结构来模拟：</p><p><img src="/generate-model/p11.JPG" alt></p><p>另外在语音合成领域，FVBN也有较好的效果，例如DeepMind的WaveNet模型就是基于FVBN的原理。</p><h2><span id="变分自编码器">变分自编码器</span></h2><p>自编码器的结构如下，利用神经网络将输入信息编码到其特征空间，再利用神经网络将这些特征重构为与输入类似的信息。通常特征z相较输入x的维度要小，只包含重要特征。</p><p><img src="/generate-model/p12.JPG" alt></p><p>而为了从模型中生成新的样本，我们只需要从分布$p_{model}(z)$ 中采样z,再经过解码网络得到样本x, 其概率分布表示为<img src="/generate-model/p13.JPG" alt>，但是这个积分是难以计算的，其后验概率$p_{model}(z\mid x)=p_{model}(x\mid z)p_{model}(z)/p_{model}(x)$ 同样是难以计算的，所以我们就要利用变分近似来求其lower bound，而我们就是利用加码网络$q(z\mid x)$ 来近似$p_{model}(z\mid x)$.</p><p>可以做如下推导：</p><p><img src="/generate-model/p14.JPG" alt></p><p>其中第一项我们可以通过从加码网络中采样来近似，而第二项由于$q(z\mid x)$ 和$p_{model}(z)$ 我们均可以选取可适的函数使其有闭合的解析形式，也是容易计算的。这两项合起来就是我们之前在变分推断中定义的evidence lower bound，简称ELBO函数，我们可以用梯度上升方法来逐渐优化它。</p><p>总结一下，VAE就是在训练时利用加码网络和解码网络利用变分法来极大化evidence lower bound，这样使得  的下限提高，在要利用模型生成样本时则可从解码网络取样得到生成样本。VAE的理论原理比较自然，实现也比较容易，而且中间学习到的特征空间也可以用来迁移到其他的任务，但是虽然它显性的定义了概率分布，但并不是精确的求解概率分布，而是用lower bound来近似其概率分布，所以在做模型评估时不如上一篇总结的PixelRNN/PixelCNN好，而且其生成的样本较之之后要总结的GAN的样本通常要更模糊些，一些例子如下图所示：</p><p><img src="/generate-model/p15.JPG" alt></p><p>当然关于VAE为何生成样本模糊，如何改善VAE的研究仍然很有意义，而且还有将VAE与GAN相结合的研究也可以同时利用二者的优势.</p><h2><span id="生成对抗网络">生成对抗网络</span></h2><p>我们之前总结的两个主要的模型FVBN与VAE都是显性的定义了概率密度分布，假如我们并不需要求密度分布，而只是希望模型能产生合理的样本，那么我就可以放弃对密度分布的定义，而GAN就是这样一种模型，它采取了博弈论的解决方法：通过两个神经网络的相互博弈，其中一个叫做生成网络Generator Network，一个叫做判别网络Discriminator Network，生成网络尽力产生可以以假乱真的样本来迷惑判别网络，判别网络尽力区分真实样本与生成网络生成的假样本，通过不断的交替学习，两个网络的准确度都越来越高，最后生成网络可以模拟与训练集分布相同的样本分布，如下图所示。</p><p><img src="/generate-model/p16.JPG" alt></p><p>详细来说，用D来表示判别函数，$\theta^{(D)}$ 来表示该网络的参数，用$J^{(D)}(\theta^{(D)},\theta^{(G)})$ 来表示其损失函数，用G来表示生成网络，用 $\theta^{(G)}$ 来表示该网络的参数，用$J^{(G)}(\theta^{(D)},\theta^{(G)})$ 来表示其损失函数。生成网络的作用是在只能控制 $\theta^{(G)}$ 的情况下尽量减少 $J^{(G)}(\theta^{(D)},\theta^{(G)})$ ，而判别网络的作用是在只能控制$\theta^{(D)}$ 的情况下尽量减小$J^{(D)}(\theta^{(D)},\theta^{(G)})$ 。把这两个网络看做两个玩家，每个玩家都只能控制自己的参数，而不能改变另一个玩家的参数，所以相较于将该问题看做一个优化问题，更自然的是当做博弈论中的博弈问题，而该问题的解就是纳什均衡(Nash equilibrium)状态，即 $(\theta^{(D)},\theta^{(G)})$ 使得 $J^{(D)}$ 相对于 $\theta^{(D)}$ 极小同时  $J^{G}$ 相对于 $\theta^{(G)}$ 极小。</p><p>对于判别网络，其损失函数就是经典的二元分类器的交叉熵损失</p><p><img src="/generate-model/p17.JPG" alt>其中来自于真实分布的样本标记是1，而来自于生成网络的样本标记为0。</p><p>对于生成网络的损失函数，最简单的假设就是假设这是一个零和博弈 zero-sum game。由于它与判别网络损失恰恰相反，所以我们可以用minmax的形式表示我们希望得到的解</p><p>$\theta^*=\mathop{argmin}\limits_{\theta_{(G)}} \mathop{max}\limits_{\theta_{(D)}}V(\theta^{(D)},\theta^{(G)})$</p><p>其中 $V(\theta^{(D)},\theta^{(G)})$ 为上文提到的交叉熵损失。</p><p>上表达可以做如下解释：判别器的目的是令  $V(\theta^{(D)},\theta^{(G)})$ 尽量大就是使真实样本 $D_{\theta_D}(x)$ 接近1，而伪造样本 $D_{\theta_D}(G(<em>{\theta_G}(z)))$ 接近0。而生成网络的目的是令 $V(\theta^{(D)},\theta^{(G)})$ 尽量小，即使伪造样本 $D</em>{\theta_{D}}(G(<em>{\theta</em>{G}}(z)))$ 也接近1.</p><p>以上就是GAN的基本原理，即从博弈的角度来使生成网络与判别网络共同进步，最后使生成网络可以以假乱真。而GAN的变种模型也很多，可以参考hindupuravinash/the-gan-zoo中列举的各种GAN模型。</p><p>近两年关于GAN的研究和应用非常多，比如图像风格迁移，根据文字生成图像等等。 另一方面，GAN也由于训练过程的不稳定性常受诟病，为了增强GAN的稳定性，也有Wasserstein GAN, LSGAN等改进模型方面的研究。这些将在下一篇博客中介绍。总结一下，做为深度学习花书的最后一部分，GAN是近些年生成模型研究比较活跃的方向，它的原理不再是对显性概率分布做直接计算或近似处理，而是利用了生成网络与判别网络的相互博弈，是一种新颖而有效的思路。希望这方面的模型能够更加稳定，得到更多的应用。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;&lt;span id=&quot;生成模型&quot;&gt;生成模型&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;生成模型(generative model)描述的是这一类的模型：接收了从分布 $p_{data}$ 取样的若干样本构成我们的训练集，然后让模型学习到一个模拟这一分布的概率分布$p_{model}$.
      
    
    </summary>
    
      <category term="Deep learning" scheme="http://dinry.github.io/categories/Deep-learning/"/>
    
    
      <category term="GAN" scheme="http://dinry.github.io/tags/GAN/"/>
    
  </entry>
  
</feed>
