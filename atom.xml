<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Dinry</title>
  
  <subtitle>notebook</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://dinry.github.io/"/>
  <updated>2019-08-01T11:06:18.611Z</updated>
  <id>http://dinry.github.io/</id>
  
  <author>
    <name>dinry</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>神经网络训练问题排查</title>
    <link href="http://dinry.github.io/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%AE%AD%E7%BB%83%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/"/>
    <id>http://dinry.github.io/神经网络训练问题排查/</id>
    <published>2019-08-01T09:01:14.000Z</published>
    <updated>2019-08-01T11:06:18.611Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="数据标准化">数据标准化</span></h1><p>数据的分布情况如何？数据是否经过适当的缩放？总体上的规则是：</p><ul><li>如果数据是连续值：范围应当在-1到1、0到1，或者呈平均值为0、标准差为1的正态分布。实际的范围不用如此精确，但确保输入数据大致处于上述区间内会有助于训练。缩小过大的输入，放大过小的输入。</li><li>如果数据是离散的类别（以及对于分类问题的输出而言），则通常使用one-hot表示。也就是说，如果有三种类别，那么这三种不同类别的数据将分别以[1,0,0]、[0,1,0]、[0,0,1]的方式表示。</li></ul><p>请注意：训练数据和测试数据的标准化方法必须完全相同，这非常重要。</p><h1><span id="权重初始化">权重初始化</span></h1><p>您需要确保权重不会过大，也不会过小。Xavier权重初始化方法通常是比较好的选择。对于使用修正线性（relu）或带泄露的修正线性（leaky relu）激活函数的网络而言，RELU权重初始化方法比较合适。</p><h1><span id="epoch数量和迭代次数">Epoch数量和迭代次数</span></h1><p>一个epoch周期的定义是完整地遍历数据集一次。DL4J将迭代次数定义为每个微批次中的参数更新次数。</p><p>在训练中，一般应让训练持续多个epoch，而将迭代次数设为一次（.iterations(1)选项）；一般仅在对非常小的数据集进行完整批次的训练时才会采用大于1的迭代次数。</p><p>如果epoch数量太少，网络就没有足够的时间学会合适的参数；epoch数量太多则有可能导致网络对训练数据过拟合。选择epoch数量的方式之一是早停法。早停法还可以避免神经网络发生过拟合（即可以帮助网络更好地适应未曾见过的数据）。</p><h1><span id="学习速率">学习速率</span></h1><p>学习速率是最重要的超参数之一。如果学习速率过高或过低，网络可能学习效果非常差、学习速度非常慢，甚至完全没有进展。学习速率的取值范围一般在0.1到1e-6之间，最理想的速率通常取决于具体的数据（以及网络架构）。一种简单的建议是，一开始可以尝试三种不同的学习速率：1e-1、1e-3、1e-6，先大致了解一下应该设为怎样的值，然后再进一步微调。理想状态下，可以同时以不同的学习速率运行模型，以便节省时间。</p><p>选择合适的学习速率的常用方法是借助DL4J的可视化界面来将训练进程可视化。您需要关注损失随时间变化的情况以及更新值与参数的绝对值之比（通常可以先考虑1:1000左右的比例）。</p><h1><span id="策略与学习速率计划">策略与学习速率计划</span></h1><p>您可以选择为神经网络设定学习速率策略，让学习速率随着时间推移逐渐“放缓”，帮助网络收敛至更接近局部极小值的位置，进而取得更好的学习效果。一种常用的策略是学习速率计划（learning rate schedule）。</p><h1><span id="损失函数">损失函数</span></h1><p>神经网络不同层中的损失函数的作用包括预训练、学习改善权重，以及在分类问题中得出结果（位于输出层上）。（在上述例子中，分类发生在重写段中。）</p><p>网络目的决定了所用的损失函数类型。预训练可选择重构熵函数。分类可选择多类叉熵函数。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;&lt;span id=&quot;数据标准化&quot;&gt;数据标准化&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;数据的分布情况如何？数据是否经过适当的缩放？总体上的规则是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果数据是连续值：范围应当在-1到1、0到1，或者呈平均值为0、标准差为1的正态分布。实际的范围不用如此精确
      
    
    </summary>
    
      <category term="Deep learning" scheme="http://dinry.github.io/categories/Deep-learning/"/>
    
    
      <category term="Deep learning" scheme="http://dinry.github.io/tags/Deep-learning/"/>
    
  </entry>
  
  <entry>
    <title>深度学习调参技巧</title>
    <link href="http://dinry.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%B0%83%E5%8F%82%E6%8A%80%E5%B7%A7/"/>
    <id>http://dinry.github.io/深度学习调参技巧/</id>
    <published>2019-08-01T04:48:50.000Z</published>
    <updated>2019-08-01T09:02:44.427Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="初始化">初始化</span></h1><p>一次惨痛的教训是用normal初始化cnn的参数，最后acc只能到70%多，仅仅改成xavier，acc可以到98%。还有一次给word embedding初始化，最开始使用了TensorFlow中默认的initializer（即glorot_uniform_initializer，也就是大家经常说的无脑使用xavier），训练速度慢不说，结果也不好。改为uniform，训练速度飙升，结果也飙升。所以，初始化就跟黑科技一样，用对了超参都不用调；没用对，跑出来的结果就跟模型有bug一样不忍直视。</p><p>记得刚开始研究深度学习时，做过两个小例子。一个是用tensorflow构建了一个十分简单的只有一个输入层和一个softmax输出层的Mnist手写识别网络，第一次我对权重矩阵W和偏置b采用的是正态分布初始化，一共迭代了20个epoch，当迭代完第一个epoch时，预测的准确度只有10%左右（和随机猜一样，Mnist是一个十分类问题），当迭代完二十个epoch，精度也仅仅达到了60%的样子。然后我仅仅是将权重矩阵W初始化方法改成了全为0的初始化，其他的参数均保持不变，结果在训练完第一个epoch后预测精度就达到了85%以上，最终20个epoch后精度达到92%。另一个例子是回归问题的预测，当时采用的SGD优化器，一开始学习率设定的0.1，模型可以正常训练，只是训练速度有些慢，我试着将学习率调整到0.3，希望可以加速训练速度，结果没迭代几轮loss就变成Nan了。于是从那时起我就深刻的感受到参数调节在深度学习模型训练中的重要意义。</p><p>其实上述问题产生的原因也很好理解，对于参数初始化，因为我们学习的本来就是权重W与偏置b，如果初始化足够好，直接就初始化到最优解，那都不用进行训练了。良好的初始化，可以让参数更接近最优解，这可以大大提高收敛速度，也可以防止落入局部极小。</p><h4><span id="tensorflow常用的初始化方法">tensorflow常用的初始化方法</span></h4><h1><span id="激活函数选择">激活函数选择：</span></h1><p>常用的激活函数有relu、leaky-relu、sigmoid、tanh等。对于输出层，多分类任务选用softmax输出，二分类任务选用sigmoid输出，回归任务选用线性输出。而对于中间隐层，则优先选择relu激活函数（relu激活函数可以有效的解决sigmoid和tanh出现的梯度弥散问题，多次实验表明它会比其他激活函数以更快的速度收敛）。另外，构建序列神经网络（RNN）时要优先选用tanh激活函数。</p><h1><span id="学习率设定">学习率设定：</span></h1><p>一般学习率从0.1或0.01开始尝试。学习率设置太大会导致训练十分不稳定，甚至出现Nan，设置太小会导致损失下降太慢。学习率一般要随着训练进行衰减。衰减系数设0.1，0.3，0.5均可，衰减时机，可以是验证集准确率不再上升时，或固定训练多少个周期以后自动进行衰减。</p><h1><span id="防止过拟合">防止过拟合：</span></h1><p>一般常用的防止过拟合方法有使用L1正则项、L2正则项、dropout、提前终止、数据集扩充等。如果模型在训练集上表现比较好但在测试集上表现欠佳可以选择增大L1或L2正则的惩罚力度（L2正则经验上首选1.0，超过10很少见），或增大dropout的随机失活概率（经验首选0.5）；或者当随着训练的持续在测试集上不增反降时，使用提前终止训练的方法。当然最有效的还是增大训练集的规模，实在难以获得新数据也可以使用数据集增强的方法，比如CV任务可以对数据集进行裁剪、翻转、平移等方法进行数据集增强，这种方法往往都会提高最后模型的测试精度。</p><h1><span id="优化器选择">优化器选择：</span></h1><p>如果数据是稀疏的，就用自适应方法，即 Adagrad, Adadelta, RMSprop, Adam。整体来讲，Adam 是最好的选择。SGD 虽然能达到极小值，但是比其它算法用的时间长，而且可能会被困在鞍点。如果需要更快的收敛，或者是训练更深更复杂的神经网络，需要用一种自适应的算法。</p><h1><span id="残差块与bn层">残差块与BN层</span></h1><p>如果你希望训练一个更深更复杂的网络，那么残差块绝对是一个重要的组件，它可以让你的网络训练的更深。</p><p>BN层具有加速训练速度，有效防止梯度消失与梯度爆炸，具有防止过拟合的效果，所以构建网络时最好要加上这个组件。</p><h1><span id="自动调参方法">自动调参方法：</span></h1><ul><li>Grid Search：网格搜索，在所有候选的参数选择中，通过循环遍历，尝试每一种可能性，表现最好的参数就是最终的结果。其原理就像是在数组里找最大值。缺点是太费时间了，特别像神经网络，一般尝试不了太多的参数组合。</li><li>Random Search：经验上，Random Search比Gird Search更有效。实际操作的时候，一般也是先用Gird Search的方法，得到所有候选参数，然后每次从中随机选择进行训练。另外Random Search往往会和由粗到细的调参策略结合使用，即在效果比较好的参数附近进行更加精细的搜索。</li><li>Bayesian Optimization：贝叶斯优化，考虑到了不同参数对应的 实验结果值，因此更节省时间，贝叶斯调参比Grid Search迭代次数少， 速度快；而且其针对非凸问题依然稳健。</li></ul><h1><span id="深度学习debug的流程策略">深度学习debug的流程策略</span></h1><p>既然消除模型中的错误很难，我们不如先从简单模型入手，然后逐渐增加模型的复杂度。</p><ul><li>从最简单模型入手；</li><li>成功搭建模型，重现结果；</li><li>分解偏差各项，逐步拟合数据；</li><li>用由粗到细随机搜索优化超参数；</li><li>如果欠拟合，就增大模型；如果过拟合，就添加数据或调整。</li></ul><p><img src="https://pcc.cs.byu.edu/2017/10/02/practical-advice-for-building-deep-neural-networks/" alt></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;&lt;span id=&quot;初始化&quot;&gt;初始化&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;一次惨痛的教训是用normal初始化cnn的参数，最后acc只能到70%多，仅仅改成xavier，acc可以到98%。还有一次给word embedding初始化，最开始使用了TensorFlow中默认的
      
    
    </summary>
    
      <category term="Deep learning" scheme="http://dinry.github.io/categories/Deep-learning/"/>
    
    
      <category term="Deep learning" scheme="http://dinry.github.io/tags/Deep-learning/"/>
    
  </entry>
  
  <entry>
    <title>python-excel</title>
    <link href="http://dinry.github.io/python-excel/"/>
    <id>http://dinry.github.io/python-excel/</id>
    <published>2019-07-25T11:57:58.000Z</published>
    <updated>2019-07-25T12:42:39.803Z</updated>
    
    <content type="html"><![CDATA[<p>python存excel数据</p><pre><code class="language-js">import xlwtimport pdbworkbook=xlwt.Workbook(encoding='utf-8')booksheet=workbook.add_sheet('data', cell_overwrite_ok=True)DATA=(('学号','姓名','年龄','性别','成绩'),      ('1001','A','11','男','12'),      ('1002','B','12','女','22'),      ('1003','C','13','女','32'),      ('1004','D','14','男','52'),      )pdb.set_trace()for i,row in enumerate(DATA):    for j,col in enumerate(row):        booksheet.write(i,j,col)workbook.save('grade.xls')</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;python存excel数据&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-js&quot;&gt;import xlwt
import pdb
workbook=xlwt.Workbook(encoding=&#39;utf-8&#39;)
booksheet=workbook.add_
      
    
    </summary>
    
      <category term="python" scheme="http://dinry.github.io/categories/python/"/>
    
    
      <category term="python语法" scheme="http://dinry.github.io/tags/python%E8%AF%AD%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>西瓜书day16，day17,day18,day19,day20(神经网络)</title>
    <link href="http://dinry.github.io/%E8%A5%BF%E7%93%9C%E4%B9%A6day16/"/>
    <id>http://dinry.github.io/西瓜书day16/</id>
    <published>2019-07-24T07:14:48.000Z</published>
    <updated>2019-07-27T01:39:36.338Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="神经元模型">神经元模型</span></h1><p>神经网络中最基本的成分是神经元模型。</p><h2><span id="m-p神经元模型">M-P神经元模型</span></h2><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day16/1.JPG" alt></p><h2><span id="激活函数">激活函数</span></h2><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day16/2.JPG" alt></p><h1><span id="感知机与多层网络">感知机与多层网络</span></h1><h2><span id="感知机">感知机</span></h2><p>感知机由两层神经元组成，如图，<img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day16/3.JPG" alt></p><p>感知机能够容易的实现逻辑与、或、非运算， $f(\sum_iw_ix_i-\theta)$, 假定f是阶跃函数，有</p><ul><li>与：令 $w_1=w_2=1,\theta=2$, 则 $y=f(1 \cdot x_1+1 \cdot x_2-2)$,仅在$x_1=x_2=1$ 时，y=1;</li><li>或：令 $w_1=w_2=1,\theta=0.5$, 则 $y=f(1 \cdot x_1+1 \cdot x_2-0.5)$,仅在$x_1=1 or x_2=1$ 时，y=1;</li><li>非：令令 $w_1=-06，w_2=0,\theta=-0.5$, 则 $y=f(-0.6 \cdot x_1+0 \cdot x_2+0.5)$,当$x_1=1$ 时，$y=0$,当 $x_1=0$ 时， $y=1$.</li></ul><p>给定训练数据集，权重与阈值可以通过学习得到。</p><p>感知机学习规则：对训练样例(x,y)，若当前感知机的输出为 $\hat{y}$, 则感知机权重将这样调整：</p><p>$w_i \leftarrow w_i +\Delta w_i$</p><p>$\Delta w_i=\eta(y-\hat{y})x_i$</p><p>其中 $\eta \in (0,1)$ 代表learning rate,.</p><h2><span id="感知机的局限性">感知机的局限性</span></h2><p>感知机只拥有一层功能神经元，学习能力非常有限，只能处理线性可分问题，不能解决抑或问题。<img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day16/4.JPG" alt>要解决非线性可分问题，需要考虑多层神经元，例如添加一个隐藏层的两层神经元可以解决“异或”问题。<img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day16/5.JPG" alt>神经网络的学习过程，就是根据训练数据来调整神经元之间的权重以及每个功能神经元的阈值。</p><h1><span id="误差逆传播算法bp">误差逆传播算法（BP）</span></h1><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day16/6.JPG" alt><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day16/7.JPG" alt><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day16/8.JPG" alt><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day16/9.JPG" alt></p><h1><span id="全局最小与局部最小">全局最小与局部最小</span></h1><p>神经网络的训练过程可以看作参数寻优过程，在参数空间中寻找一组最优参数使神经网络在训练集上的误差达到最小。</p><p>局部最优解：参数空间中的某个点，其邻域点的误差函数值均不小于该点的函数值</p><p>全局最小解：参数空间中所有点的误差函数值均不小于该点的函数值</p><p>基于梯度的搜索是使用最为广泛的参数寻优方法</p><h4><span id="局部最小跳出策略">局部最小跳出策略</span></h4><ul><li>以多组不同参数值初始化多个神经网络，取误差最小的参数</li><li>“模拟退火”：以一定概率接受比当前解更差的结果</li><li>随机梯度下降 在计算梯度时加入了随机因素，即使陷入局部极小，也有可能跳出。</li></ul><h1><span id="其他常见的神经网络">其他常见的神经网络</span></h1><h4><span id="rbf">RBF</span></h4><h4><span id="art">ART</span></h4><h4><span id="smo">SMO</span></h4><h4><span id="级联相关网络">级联相关网络</span></h4><h4><span id="elman网络">Elman网络</span></h4><h4><span id="boltzmann">Boltzmann</span></h4><h1><span id="神经网络">神经网络</span></h1>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;&lt;span id=&quot;神经元模型&quot;&gt;神经元模型&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;神经网络中最基本的成分是神经元模型。&lt;/p&gt;
&lt;h2&gt;&lt;span id=&quot;m-p神经元模型&quot;&gt;M-P神经元模型&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;/%E8%A5%BF%E7%93%
      
    
    </summary>
    
      <category term="ML" scheme="http://dinry.github.io/categories/ML/"/>
    
    
      <category term="西瓜书" scheme="http://dinry.github.io/tags/%E8%A5%BF%E7%93%9C%E4%B9%A6/"/>
    
  </entry>
  
  <entry>
    <title>西瓜书day13,day14,day15（贝叶斯分类器）</title>
    <link href="http://dinry.github.io/%E8%A5%BF%E7%93%9C%E4%B9%A6day13/"/>
    <id>http://dinry.github.io/西瓜书day13/</id>
    <published>2019-07-19T23:55:41.000Z</published>
    <updated>2019-07-22T10:56:08.546Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="以多分类为例">以多分类为例</span></h1><h1><span id="贝叶斯判定准则">贝叶斯判定准则</span></h1><p>为最小化总体风险，只需在每个样本上选择能使条件风险 $R(c \mid x)$ 最小的类别标记，即为： $h^*(x)=argmin_{c \in y}R(c \mid x)=argmax_{c \in y}P(c \mid x)$,</p><p>此时，$h^*$ 为贝叶斯最优分类器。条件风险：</p><p>$R(c_i \mid x)=\sum_{j=1}^N \lambda_{ij}P(c_j \mid x)=1-P(c_i \mid x)$,</p><p>$\lambda_{ij}$ 是将一个真实标记为 $c_j$ 的样本误分类为 $c_i$ 所产生的损失。</p><h1><span id="多元正态分布的mle">多元正态分布的MLE</span></h1><p>概率模型的训练过程就是参数估计过程。</p><ul><li><p>频率主义学派：参数虽然未知，但却是客观存在的固定值，因此，可通过优化似然函数等准则来确定参数值</p></li><li><p>贝叶斯学派：参数是为观察到的随机变量，其本身也可以有分布，因此，可假定参数服从一个先验分布，然后基于观测到的数据来计算参数的后验分布。</p></li></ul><p>MLE源自频率主义学派。</p><p>$P(D_c \mid \theta_c)=\prod_{x \in D_c}P(x \mid \theta_c)$</p><p>其中 $D_c$ 表示训练集D中第c类样本组成的集合。</p><p>推导：</p><p>$LL(\theta_c)$</p><p>$=logP(D_c \mid \theta_c)$</p><p>$=\sum_{x \in D_c}logP(x \mid \theta_c)$</p><h2><span id="多元正态分布的概率密度函数">多元正态分布的概率密度函数：</span></h2><p>由于 $P(x \mid \theta_c)=P(x \mid c) -N(\mu_c,\sigma_c^2)$, 那么</p><p>$P(x \mid \theta_c)=\frac{1}{\sqrt{(2\pi)^d\mid\sum_c\mid}}exp(-\frac{1}{2}(x-\mu_c)^T\sum_c^{-1}(x-\mu_c))$</p><p>其中d表示xde维数，$\sum_c=\sigma_c^2$ 为对称正定协方差矩阵，$\mid\sum_c\mid$ 表示行列式，将上式代入对数似然函数可得</p><p>$LL(\theta_c)=\sum_{x \in D_c}ln[\frac{1}{\sqrt{(2\pi)^d\mid\sum_c\mid}}exp(-\frac{1}{2}(x-\mu_c)^T\sum_c^{-1}(x-\mu_c))]$</p><p>$=\sum_{i=1}^Nln[\frac{1}{\sqrt{(2\pi)^d\mid\sum_c\mid}}exp(-\frac{1}{2}(x_i-\mu_c)^T\sum_c^{-1}(x_i-\mu_c))]$</p><p>$=\sum_{i=1}^N{ln\frac{1}{\sqrt{(2\pi)^d}}+ln\frac{1}{\sqrt{\mid \sum_c \mid}}+ln[exp(-\frac{1}{2}(x_i-\mu_c)^T\sum_c^{-1}(x_i-\mu_c))]}$</p><p>$=-\frac{Nd}{2}ln(2\pi)-\frac{N}{2}ln\mid \sum_c\mid-\frac{1}{2}\sum_{i=1}^N(x_i-\mu_c)^T\sum_c^{-1}(x_i-\mu_c))$</p><p>由于参数 $\theta_c$ 的极大似然估计 $\hat{\theta_c}$ 为 $\hat{\theta_c}=argmax_{\theta_c}LL(\theta_c)$，</p><p>对 $LL(\theta_c)$ 关于 $\mu_c$ 求偏导：</p><p>$\frac{\partial LL(\theta_c)}{\partial \mu_c}=-\frac{1}{2}\sum_{i=1}^{N}\frac{\partial (x_i^T-\mu_c^T)\sum_c^{-1}(x_i-\mu_c)}{\partial \mu_c}$</p><p>$=-\frac{1}{2}\sum_{i=1}^{N}\frac{\partial [x_i^T\sum_c^{-1}x_i-x_i^T\sum_c^{-1}\mu_c-\mu_c^T\sum_c^{-1}x_i+\mu_c^T\sum_c^{-1}\mu_c]}{\partial \mu_c}$</p><p>由于 $x_i^T\sum_c^{-1}\mu_c=(x_i^T\sum_c^{-1}\mu_c)^T=\mu_c^T(\sum_c^T)^{-1}x_i=\mu_c^T\sum_c^{-1}x_i$</p><p>$=-\frac{1}{2}\sum_{i=1}^{N}\frac{\partial [x_i^T\sum_c^{-1}x_i-2x_i^T\sum_c^{-1}\mu_c+\mu_c^T\sum_c^{-1}\mu_c]}{\partial \mu_c}$</p><p>$=-\frac{1}{2}\sum_{i=1}^{N}[0-(2x_i^T\sum_c^{-1})^T+(\sum_c^{-1}+(\sum_c^{-1})^T)\mu_c]$</p><p>$=-\frac{1}{2}\sum_{i=1}^{N}[-(2\sum_c^{-1}x_i)+2\sum_c^{-1}\mu_c]$</p><p>$=\sum_{i=1}^{N}\Sigma_c^{-1}x_i-N\Sigma_c^{-1}\mu_c$</p><p>$=0$</p><p>$\hat{\mu_c}=\frac{\sum_{i=1}^Nx_i}{N}$</p><p>对 $LL(\theta_c)$ 关于 $\Sigma_c$ 求偏导：</p><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day13/4.JPG" alt><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day13/5.JPG" alt><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day13/6.JPG" alt></p><h2><span id="评估">评估</span></h2><p>这种参数化的方法虽然能使类条件概率估计变得相对简单，但估计结果的准确性严重依赖于所假设的概率分布形式是否符合潜在的真实数据分布。</p><h1><span id="朴素贝叶斯分类器">朴素贝叶斯分类器</span></h1><p>$h^*(x)=argmax P(c \mid x)=argmax \frac{P(c)P(x \mid c)}{P(x)}=argmaxP(c)P(x \mid c)$ ++++++属性条件独立性假设</p><p>属性条件独立性假设定义：$P(x \mid c)=P(x_1,x_2,...,x_d \mid c)=\prod_{i=1}^{d}P(x_i \mid c)$ -----(牺牲准确度换取计算效率)</p><h2><span id="naive-bayes">naive bayes</span></h2><p>$h^*(x)=argmaxP(c)\prod_{i=1}^dP(x_i \mid c)$</p><h2><span id="先验概率-pc">先验概率 $P(c)$</span></h2><p>$P(c)=\frac{\mid D_c \mid}{\mid D \mid}$</p><h2><span id="似然概率-px_i-mid-c">似然概率 $P(x_i \mid c)$</span></h2><h4><span id="连续值">连续值</span></h4><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day13/2.JPG" alt></p><h4><span id="离散值">离散值</span></h4><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day13/1.JPG" alt></p><h2><span id="laplacian-correction">Laplacian correction</span></h2><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day13/3.JPG" alt>拉普拉斯修正避免了因训练集样本不充足而导致概率估值为0的问题，当训练集样本增大，这个误差会被忽略。</p><h1><span id="em算法">EM算法</span></h1><h2><span id="em算法的引入">EM算法的引入</span></h2><h4><span id="为什么需要em">为什么需要EM？</span></h4><p>训练样本含有隐变量Z</p><h2><span id="em算法的例子">EM算法的例子</span></h2><p>《统计学习方法》-三硬币模型  9.1</p><p>迭代求解参数,近似极大化</p><h2><span id="em算法的导出">EM算法的导出</span></h2><h4><span id="jensen-不等式">Jensen 不等式</span></h4><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day13/7.JPG" alt></p><p>可以将a看作概率，则f表示为期望</p><p>Jensen不等式在概率论中的应用：$\varphi(E[X]) \leq E[\varphi(X)]$</p><h4><span id="推导">推导</span></h4><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day13/8.JPG" alt><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day13/9.JPG" alt><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day13/10.JPG" alt><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day13/11.JPG" alt><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day13/12.JPG" alt><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day13/13.JPG" alt></p><h2><span id="em算法求解例子">EM算法求解例子</span></h2><p>用EM求解三硬币</p><ul><li>E:求Q</li><li>M：寻找参数最大化期望</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;&lt;span id=&quot;以多分类为例&quot;&gt;以多分类为例&lt;/span&gt;&lt;/h1&gt;
&lt;h1&gt;&lt;span id=&quot;贝叶斯判定准则&quot;&gt;贝叶斯判定准则&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;为最小化总体风险，只需在每个样本上选择能使条件风险 $R(c \mid x)$ 最小的类别标记，即为： $
      
    
    </summary>
    
      <category term="ML" scheme="http://dinry.github.io/categories/ML/"/>
    
    
      <category term="西瓜书" scheme="http://dinry.github.io/tags/%E8%A5%BF%E7%93%9C%E4%B9%A6/"/>
    
  </entry>
  
  <entry>
    <title>西瓜书day9,day10,day11,day12(支持向量机)</title>
    <link href="http://dinry.github.io/%E8%A5%BF%E7%93%9C%E4%B9%A6day9/"/>
    <id>http://dinry.github.io/西瓜书day9/</id>
    <published>2019-07-16T00:53:00.000Z</published>
    <updated>2019-07-19T03:21:05.443Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="预备知识">预备知识</span></h1><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day9/3.JPG" alt><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day9/4.JPG" alt></p><h1><span id="间隔与支持向量">间隔与支持向量</span></h1><p>分类学习最基本的想法就是基于训练集D在样本空间中找到一个划分超平面，将不同类别的样本分开。<img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day9/1.JPG" alt></p><p>直观来说，应该找位于两类训练样本“正中间”的划分超平面，因为其对训练样本局部扰动的“容忍”性最好。</p><p>在训练样本中，划分超平面可以通过线性方程 $\mathbb{w}^T\mathbb{x}+b=0$ 来描述。其中 $\mathbb{w}=(w_1;w_2;...;d_d)$ 为法向量，决定了超平面的方向；b为位移，决定了超平面与原点之间的距离。样本空间中任意点 $x$ 到超平面$(\mathbb{w},b)$ 的距离可写为：</p><p>$r=\frac{\mid \mathbb{w}^T\mathbb{x}+b \mid}{\mid \mid \mathbb{w} \mid \mid}$.</p><p>证明：</p><p>任意取超平面上一个点 $x'$，则点 $x$ 到超平面的距离等于向量 $(x-x')$ 在法向量 $w$（参考预备2）的投影长度（参考预备1）:</p><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day9/5.JPG" alt>注意：上式推导过程中，分子之所有取绝对值是由于向量内积可能小于零；另外，由于 $x'$ 是超平上面的点，因此 $\mathbb{w}^T\mathbb{x'}+b=0$，即 $b=-\mathbb{w}^T\mathbb{x'}$。</p><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day9/6.JPG" alt></p><p>注意到，距离超平面最近的训练样本可以使上式的等号成立，由6.2知这些训练样本到超平面的距离为：</p><p>$dist=\frac{\mid \mathbb{w}^T\mathbb{x}+b \mid}{\mid \mid \mathbb{w} \mid \mid}=\frac{1}{\mid \mid w \mid \mid}$.</p><p>那么很容易知道，两个异类支持向量到超平面的距离之和是 $\frac{2}{\mid \mid w \mid \mid}$<img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day9/2.JPG" alt></p><h1><span id="支持向量基本型">支持向量基本型</span></h1><p>最大间隔超平面条件等同于最小化如下公式：</p><p>$min_{w,b} \frac{1}{2} \mid \mid \mathbb{w} \mid \mid^2$</p><p>s.t. $y_i(\mathbb{w}^T\mathbb{x}_i+b) \ge 1$, i=1,2,...,m.</p><p>式(6.6)的约束条件意思是训练样本线性可分，也就是说不存在被分类错误的样本，因此也就不存在欠拟合问题；已知优化式(6.6)目标函数是在寻找“最大间隔”的划分超平面，而“最大间隔”划分超平面所产生的分类结果是最鲁棒的，对未见示例的泛化能力最强，因此可将式(6.6)优化目标进一步解释为寻找最不可能过拟合的分类超平面，这一点与正则化不谋而合。</p><h1><span id="对偶问题">对偶问题</span></h1><h2><span id="拉格朗日乘子法">拉格朗日乘子法</span></h2><p>此出假设优化问题一定有解<img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day9/7.JPG" alt></p><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day9/8.JPG" alt></p><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day9/9.JPG" alt></p><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day9/10.JPG" alt></p><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day9/11.JPG" alt></p><h1><span id="核函数">核函数</span></h1><p>使训练样本在高维空间可分的映射函数。<img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day9/12.JPG" alt>$f(x)=\mathbb{w}^T \phi(x)+b$, 此时w的维度与 $\phi(x)$ 同。</p><p>核函数可以分解成两个向量的内积。要想了解某个核函数是如何将原始特征空间映射到更高维的特征空间的，只需要将核函数分解为两个表达形式完全一样的向量 $\phi(x_i)$ 和 $\phi(x_j)$ 即可（有时很难分解）。以下是LIBSVM中的几个核函数：<img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day9/13.JPG" alt><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day9/14.JPG" alt>遗留问题：核函数的几何意义是什么？核矩阵正定核函数就存在？</p><h1><span id="软间隔与正则化">软间隔与正则化</span></h1><p>软间隔的引入：</p><p>在前面的学习中，一直假设训练样本在样本空间或特征空间是线性可分的，要求所有样本都必须正确划分，称为“硬间隔”，然而现实中很难确定核函数使训练样本线性可分，缓解这一问题的方法是允许SVM在一些样本上出错，因此，引入软间隔：允许某些样本不满足约束 $y_i(w^Tx_i+b) \geq 1$<img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day9/15.JPG" alt></p><h2><span id="预备知识替代损失函数">预备知识：替代损失函数</span></h2><ul><li>凸函数</li><li>连续函数<img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day9/16.JPG" alt><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day9/19.JPG" alt></li></ul><h2><span id="软间隔优化目标函数">软间隔优化目标函数</span></h2><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day9/17.JPG" alt></p><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day9/18.JPG" alt></p><p>引入松弛变量后的目标函数</p><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day9/20.JPG" alt></p><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day9/21.JPG" alt></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;&lt;span id=&quot;预备知识&quot;&gt;预备知识&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;&lt;img src=&quot;/%E8%A5%BF%E7%93%9C%E4%B9%A6day9/3.JPG&quot; alt&gt;
&lt;img src=&quot;/%E8%A5%BF%E7%93%9C%E4%B9%A6day9/4.
      
    
    </summary>
    
      <category term="ML" scheme="http://dinry.github.io/categories/ML/"/>
    
    
      <category term="西瓜书" scheme="http://dinry.github.io/tags/%E8%A5%BF%E7%93%9C%E4%B9%A6/"/>
    
  </entry>
  
  <entry>
    <title>paper:AdamOptimizer</title>
    <link href="http://dinry.github.io/paper-AdamOptimizer/"/>
    <id>http://dinry.github.io/paper-AdamOptimizer/</id>
    <published>2019-07-12T12:20:39.000Z</published>
    <updated>2019-07-12T12:56:57.809Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="paperadam-a-method-for-stochastic-optimization">paper：Adam: A Method for Stochastic Optimization</span></h1><p>论文链接：<img src="https://arxiv.org/abs/1412.6980" alt></p><p><img src="/paper-AdamOptimizer/1.JPG" alt></p><p>如上算法所述，在确定了参数 $\alpha$,$\beta_1$,$\beta_2$和随机目标函数 $f(\theta)$ 之后，我们需要初始化参数向量、一阶矩向量、二阶矩向量和时间步。然后当参数 $\theta$ 没有收敛时，循环迭代地更新各个部分。即时间步 t 加 1、更新目标函数在该时间步上对参数 $\theta$ 所求的梯度、更新偏差的一阶矩估计和二阶原始矩估计，再计算偏差修正的一阶矩估计和偏差修正的二阶矩估计，然后再用以上计算出来的值更新模型的参数 $\theta$。</p><h1><span id="算法">算法</span></h1>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;&lt;span id=&quot;paperadam-a-method-for-stochastic-optimization&quot;&gt;paper：Adam: A Method for Stochastic Optimization&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;论文链接：&lt;img src=
      
    
    </summary>
    
      <category term="deep learning" scheme="http://dinry.github.io/categories/deep-learning/"/>
    
    
      <category term="tensorflow" scheme="http://dinry.github.io/tags/tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>西瓜书day5,day6,day7,day8(决策树)</title>
    <link href="http://dinry.github.io/%E8%A5%BF%E7%93%9C%E4%B9%A6day5/"/>
    <id>http://dinry.github.io/西瓜书day5/</id>
    <published>2019-07-12T08:44:57.000Z</published>
    <updated>2019-07-15T06:05:15.300Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="决策树定义">决策树定义</span></h1><p>决策树是基于输结构来进行决策的一类常见的机器学习分类方法。</p><h1><span id="解决问题">解决问题</span></h1><p>“当前样本属于正类吗？”</p><p>“这是好瓜吗？”</p><p>“它的根蒂是什么形态”</p><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day5/1.JPG" alt></p><p>决策过程的最终结论（叶子节点）对应了我们所希望的判定结果：好瓜 or 坏瓜</p><h1><span id="结构">结构</span></h1><p>1.一个根节点和若干个内部节点：分别对应一个属性测试</p><p>2.若干个叶节点：对应决策结果</p><p>j决策树学习的目的是为了产生一棵泛化能力强的决策树，基本流程遵循“分而治之”：</p><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day5/2.JPG" alt></p><p>递归返回条件：</p><ul><li>当前节点包含的样本全属于同一类别，无需划分</li><li>当前属性集为空，或是所有样本在所有属性上取值相同，无法划分</li><li>当前节点包含的样本集合为空，不能划分。</li></ul><h1><span id="id3">ID3</span></h1><p>信息熵：</p><p>熵是度量样本集合纯度最常用的一种指标，代表一个系统中蕴含多少信息量，信息量越大表明一个系统不确定性就越大，就存在越多的可能性，即信息熵越大。</p><p>假定当前样本集合D中第K类样本所占的比例为 $p_k(k=1,2,...,\mid y\mid)$, 则D的信息熵为：</p><p>$Ent(D)=-\sum_{k=1}^{\mid y \mid}p_{k}log_{2}p_{k}$</p><p>信息熵满足下列不等式：</p><p>$0 \leq Ent(D) \leq log_{2}\mid y \mid$ ,</p><p>$0 \leq p_k \leq 1$, $\sum_{k=1}^np_k=1$</p><p>其中$y$表示D中的样本类别数。</p><h2><span id="id3推导max-value">ID3推导(max-value)</span></h2><p>若令 $\mid y \mid=n,p_k=x_k$, 那么信息熵 $Ent(D)$ 可以看作一个n元实值函数，即</p><p>$Ent(D)=f(x_1,...,x_n)=-\sum_{k=1}^{n}x_{k}log_{2}x_{k}$, 其中：$0 \leq p_k \leq 1$, $\sum_{k=1}^np_k=1$.</p><p>引入拉格朗日乘子 $\lambda$求最值：</p><p>$L(x_1,...,x_n,\lambda)=-\sum_{k=1}^{n}x_{k}log_{2}x_{k}+\lambda(\sum_{k=1}^nx_k-1)$</p><p>$\frac{\partial L(x_1,...,x_n,\lambda)}{\partial x_1}=-log_2x_1-x_1 \cdot \frac{1}{x_{1}ln2}+\lambda=0$</p><p>$\lambda=log_2x_1+\frac{1}{ln2}$</p><p>同理：</p><p>$\lambda=log_2x_1+\frac{1}{ln2}=log_2x_2+\frac{1}{ln2}=...=log_2x_n+\frac{1}{ln2}$</p><p>so: $x_1=x_2=...=x_n=\frac{1}{n}$</p><p>最大值与最小值需要验证：</p><ul><li>$x_1=x_2=...=x_n=\frac{1}{n}$ 时：$f=-n \cdot \frac{1}{n}log_2\frac{1}{n}=log_2n$</li><li>$x_1=1,x_2=x_3=...=x_n=0$ 时： $f=0$</li></ul><p>所以为最大值</p><h2><span id="id3推导min-value">ID3推导(min-value)</span></h2><p>Assume:</p><p>$f(x_1,...x_n)=\sum_{k=1}^ng(x_k)$</p><p>$g(x_k)=-\sum_{k=1}^{n}x_{k}log_{2}x_{k}$, $0 \leq p_k \leq 1$</p><p>求 $g(x_1)$ 的最小值，首先求导：</p><p>$\frac{d(g(x_1))}{dx_1}=-log_2x_1-\frac{1}{ln2}$</p><p>$\frac{d^2(g(x_1))}{dx^2}=-\frac{1}{x_1ln2}$</p><p>在定义域$0 \leq p_k \leq 1$， 始终有 $\frac{d^2(g(x_1))}{dx^2}=-\frac{1}{x_1ln2} \leq 0$,所以最小值在边界处$x_1=0 或 x_1=1$取得：$min g(x_1)=0$</p><p>由推理可得$f(0,0,0,0,1,...,0)=0$</p><p>所以：</p><p>$0 \leq Ent(D) \leq log_{2}\mid y \mid$</p><h2><span id="信息增益">信息增益</span></h2><p>假定离散属性有V个可能的取值 {${a^1,a^2,...,a^V}$}, 如果使用特征a来对数据集D进行划分，则会产生V个分支结点，其中第 $v$ 个结点包含了数据集D中所有在特征a上取值为 $a^V$ 的样本总数，记为 $D^v$, 特征对样本集D进行划分的“样本增益”为：</p><p>$Gain(D,a)=Ent(D)-\sum_{v=1}^V \frac{\mid D^V \mid}{\mid D \mid}Ent(C^v)$</p><h2><span id="缺点">缺点</span></h2><p>1.ID3没有考虑连续特征</p><p>2.ID3采用信息增益大的特征优先建立决策树的节点，取值比较多的特征比取值少的特征信息增益大</p><p>3.ID3算法对于缺失值的情况没有做考虑</p><p>4.没有考虑过拟合的情况</p><h1><span id="c45算法">C4.5算法</span></h1><p>增益率：</p><p>弥补ID3偏向于取值较多属性,C4.5算法不直接使用信息增益，而是使用一种叫增益率的方法来选择最优属性进行划分：</p><p>$Gain-ration(D,a)=\frac{Gain(D,a)}{IV(a)}$</p><p>$IV(a)$ 是属性 $a$ 的固有值：</p><p>$IV(a)=-\sum_{v=1}^V \frac{\mid D^v \mid}{\mid D \mid}log_2 \frac{\mid D^v \mid}{D}$</p><p>属性越多，熵越大，对分支过多的情况进行惩罚。</p><h2><span id="缺点">缺点</span></h2><p>1.C4.5生成的是多叉树，生成决策树的效率比较慢</p><p>2.C4.5只能用于分类</p><p>3.C4.5由于使用了熵模型，对数运算耗时。</p><h1><span id="cart">CART</span></h1><p>Gini值：</p><p>度量数据集的纯度，Gini(D)反应了从数据集中随机抽取两个样本,类别标记不一致的概率，数据越小，纯度越高。</p><p>$Gini(D)=\sum_{k=1}^{\mid y \mid}\sum_{k' \neq k}p_kp_{k'}=1-\sum_{k=1}^{\mid y \mid}p_k^2$</p><p>$Gini-index(D,a)=\sum_{v=1}^V \frac{\mid D^v \mid}{\mid D \mid}Gini(D^v)$</p><h1><span id="剪枝">剪枝</span></h1><p>减指是决策树学习算法处理过拟合的重要手段。决策树剪枝的基本策略有“预剪枝”和“后剪枝”。预剪枝是对每个节点在划分前进行估计，若不能带来泛化能力的提升，则停止划分并将该节点标记为叶节点。后剪枝则是先从训练集生成一颗完整的决策树，然后自底向上计算泛化能力是否提升，否则标记为叶节点。<img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day5/3.JPG" alt></p><h2><span id="预剪枝">预剪枝</span></h2><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day5/4.JPG" alt><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day5/5.JPG" alt></p><h2><span id="后剪枝">后剪枝</span></h2><p>后剪枝先从训练集生成一棵完整的决策树如图4.5，该决策树的验证集精度为42.9%，后剪枝首先考察节点6，然后节点五，节点二，节点三，节点一，计算过程如图。<img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day5/6.JPG" alt></p><h2><span id="对比">对比</span></h2><ul><li>后剪枝比预剪枝保留了更多的分支。</li><li>后剪枝欠拟合风险小，泛化能力优于预剪枝决策树</li><li>后剪枝是在生成决策树后进行的，自底向上对非叶节点逐个考察，训练时间与开销都比预剪枝大得多</li></ul><h1><span id="连续与缺失值">连续与缺失值</span></h1><h1><span id="连续值处理在决策树学习中使用连续属性进行决策">连续值处理：在决策树学习中使用连续属性进行决策</span></h1><p>方法：连续属性离散化：（eg,二分法)</p><p>给定样本集$D$ 和连续属性，划分点$t$可以将D分为子集 $D_t^-$ 与 $D_t^+$, $D_t^-$包含在属性 $a$ 上不大于 $t$ 的样本，候选划分集合：</p><p>$T_a={\frac{a^i+a^{i+1}}{2} \mid 1 \leq i \leq n-1}$</p><p>然后我们可以像离散属性一样来选择划分点：</p><p>$Gain(D,a)=max_{t \in T_a}Gain(D,a,t)=max_{t \in T_a}Ent(D)-\sum_{\lambda \in {-,+}}\frac{\mid D_t^{\lambda} \mid}{\mid D \mid}Ent(D_t^{\lambda})$</p><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day5/7.JPG" alt><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day5/8.JPG" alt></p><h1><span id="缺失值处理">缺失值处理</span></h1><p>样本的某些属性值缺失如何进行划分属性的选择呢？</p><p>给定划分属性，若样本在该属性上的值缺失，如何对样本进行划分？</p><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day5/9.JPG" alt></p><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day5/10.JPG" alt></p><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day5/11.JPG" alt></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;&lt;span id=&quot;决策树定义&quot;&gt;决策树定义&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;决策树是基于输结构来进行决策的一类常见的机器学习分类方法。&lt;/p&gt;
&lt;h1&gt;&lt;span id=&quot;解决问题&quot;&gt;解决问题&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;“当前样本属于正类吗？”&lt;/p&gt;
&lt;p&gt;“这是好
      
    
    </summary>
    
      <category term="ML" scheme="http://dinry.github.io/categories/ML/"/>
    
    
      <category term="西瓜书" scheme="http://dinry.github.io/tags/%E8%A5%BF%E7%93%9C%E4%B9%A6/"/>
    
  </entry>
  
  <entry>
    <title>paper:CFGAN</title>
    <link href="http://dinry.github.io/paper-CFGAN/"/>
    <id>http://dinry.github.io/paper-CFGAN/</id>
    <published>2019-07-11T14:41:11.000Z</published>
    <updated>2019-07-11T14:46:22.352Z</updated>
    
    <content type="html"><![CDATA[<p>本片博客总结paper CFGAN。</p><p>《CFGAN: A Generic Collaborative Filtering Framework based on Generative Adversarial Networks》</p><p>from CIKM 2018</p><p>contribution:  GAN-based CF model</p><p>keyWords: Top-N recommendation, collaborative filtering, generative adversarial networks, implicit feedback</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本片博客总结paper CFGAN。&lt;/p&gt;
&lt;p&gt;《CFGAN: A Generic Collaborative Filtering Framework based on Generative Adversarial Networks》&lt;/p&gt;
&lt;p&gt;from CIKM 
      
    
    </summary>
    
      <category term="recommender systems" scheme="http://dinry.github.io/categories/recommender-systems/"/>
    
    
      <category term="Recommender systems" scheme="http://dinry.github.io/tags/Recommender-systems/"/>
    
  </entry>
  
  <entry>
    <title>tensorflow loss分析</title>
    <link href="http://dinry.github.io/train-loss/"/>
    <id>http://dinry.github.io/train-loss/</id>
    <published>2019-07-11T13:19:46.000Z</published>
    <updated>2019-07-11T14:47:38.930Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="train-loss与test-loss结果分析">train loss与test loss结果分析</span></h1><p>train loss 不断下降，test loss不断下降，说明网络仍在学习;</p><p>train loss 不断下降，test loss趋于不变，说明网络过拟合;</p><p>train loss 趋于不变，test loss不断下降，说明数据集100%有问题;</p><p>train loss 趋于不变，test loss趋于不变，说明学习遇到瓶颈，需要减小学习率或批量数目;</p><p>train loss 不断上升，test loss不断上升，说明网络结构设计不当，训练超参数设置不当，数据集经过清洗等问题。</p><h1><span id="loss和神经网络训练">Loss和神经网络训练</span></h1><h2><span id="训练前的检查工作">训练前的检查工作</span></h2><p>1.loss:在用很小的随机数初始化神经网络后，第一遍计算loss可以做一次检查(当然要记得把正则化系数设为0)。</p><p>2.接着把正则化系数设为正常的小值，加回正则化项，这时候再算损失/loss，应该比刚才要大一些。</p><p>3.试着去拟合一个小的数据集。最后一步，也是很重要的一步，在对大数据集做训练之前，先训练一个小的数据集，然后看看你的神经网络能够做到0损失/loss(当然，是指的正则化系数为0的情况下)，因为如果神经网络实现是正确的，在无正则化项的情况下，完全能够过拟合这一小部分的数据。</p><h2><span id="监控">监控</span></h2><p>开始训练之后，我们可以通过监控一些指标来了解训练的状态。我们还记得有一些参数是我们认为敲定的，比如学习率，比如正则化系数。</p><p>1.损失/loss随每轮完整迭代后的变化</p><p><img src="/train-loss/1.JPG" alt></p><p>合适的学习率可以保证每轮完整训练之后，loss都减小，且能在一段时间后降到一个较小的程度。太小的学习率下loss减小的速度很慢，如果太激进，设置太高的学习率，开始的loss减小速度非常可观，可是到了某个程度之后就不再下降了，在离最低点一段距离的地方反复，无法下降了。</p><p>2.训练集/验证集上的准确度:判断分类器所处的拟合状态。</p><p><img src="/train-loss/2.JPG" alt></p><p>随着时间推进，训练集和验证集上的准确度都会上升，如果训练集上的准确度到达一定程度后，两者之间的差值比较大，那就要注意一下，可能是过拟合现象，如果差值不大，那说明模型状况良好。</p><p>3.权重：权重更新幅度和当前权重幅度的比值权重更新部分是梯度和学习率的乘积，可以独立的检查这个比例，一个合适的比例大概是1e-3。如果得到的比例比这个值小很多，那么说明学习率设定太低了，反之则是设定太高了。</p><p>4.每一层的 激励/梯度值 分布：如果参数初始化不正确，那整个训练过程会越来越慢，甚至直接停掉。</p><h2><span id="关于参数更新部分的注意点">关于参数更新部分的注意点</span></h2><p>当确信解析梯度实现正确后，那就该在后向传播算法中使用它更新权重参数了。就单参数更新这个部分，也是有讲究的：</p><p>1.拿到梯度之后，乘以设定的学习率，用现有的权重减去这个部分，得到新的权重参数(因为梯度表示变化率最大的增大方向，减去这个值之后，损失函数值才会下降)。</p><p>2.在实际训练过程中，随着训练过程推进，逐渐衰减学习率是很有必要的。我们继续回到下山的场景中，刚下山的时候，可能离最低点很远，那我步子迈大一点也没什么关系，可是快到山脚了，我还激进地大步飞奔，一不小心可能就迈过去了。所以还不如随着下山过程推进，逐步减缓一点点步伐。不过这个『火候』确实要好好把握，衰减太慢的话，最低段震荡的情况依旧；衰减太快的话，整个系统下降的『动力』衰减太快，很快就下降不动了。下面提一些常见的学习率衰减方式：</p><ul><li>步伐衰减：这是很常见的一个衰减模式，每过一轮完整的训练周期(所有的图片都过了一遍)之后，学习率下降一些。比如比较常见的一个衰减率可能是每20轮完整训练周期，下降10%。不过最合适的值还真是依问题不同有变化。如果你在训练过程中，发现交叉验证集上呈现很高的错误率，还一直不下降，你可能就可以考虑考虑调整一下(衰减)学习率了。</li><li>指数级别衰减：需要自己敲定的超参数，是迭代轮数。</li><li>1/t衰减：有着数学形式为的衰减模式，其中是需要自己敲定的超参数，是迭代轮数。</li></ul><h2><span id="超参数的设定与优化">超参数的设定与优化</span></h2><p>神经网络的训练过程中，不可避免地要和很多超参数打交道，需要手动设定，大致包括：</p><p>1.初始学习率2.学习率衰减程度3.正则化系数/强度(包括l2正则化强度，dropout比例)</p><p>对于大的深层次神经网络而言，我们需要很多的时间去训练。因此在此之前我们花一些时间去做超参数搜索，以确定最佳设定是非常有必要的。最直接的方式就是在框架实现的过程中，设计一个会持续变换超参数实施优化，并记录每个超参数下每一轮完整训练迭代下的验证集状态和效果。实际工程中，神经网络里确定这些超参数，我们一般很少使用n折交叉验证，一般使用一份固定的交叉验证集就可以了。</p><p>一般对超参数的尝试和搜索都是在log域进行的。例如，一个典型的学习率搜索序列就是learning_rate = 10 ** uniform(-6, 1)。我们先生成均匀分布的序列，再以10为底做指数运算，其实我们在正则化系数中也做了一样的策略。比如常见的搜索序列为[0.5, 0.9, 0.95, 0.99]。另外还得注意一点，如果交叉验证取得的最佳超参数结果在分布边缘，要特别注意，也许取的均匀分布范围本身就是不合理的，也许扩充一下这个搜索范围会有更好的参数。</p><h2><span id="模型融合与优化">模型融合与优化：</span></h2><p>实际工程中，一个能有效提高最后神经网络效果的方式是，训练出多个独立的模型，在预测阶段选结果中的众数。模型融合能在一定程度上缓解过拟合的现象，对最后的结果有一定帮助，我们有一些方式可以得到同一个问题的不同独立模型：</p><ul><li>使用不同的初始化参数。先用交叉验证确定最佳的超参数，然后选取不同的初始值进行训练，结果模型能有一定程度的差别。</li><li>选取交叉验证排序靠前的模型。在用交叉验证确定超参数的时候，选取top的部分超参数，分别进行训练和建模。</li><li>选取训练过程中不同时间点的模型。神经网络训练确实是一件非常耗时的事情，因此有些人在模型训练到一定准确度之后，取不同的时间点的模型去做融合。不过比较明显的是，这样模型之间的差异性其实比较小，好处是一次训练也可以有模型融合的收益。</li></ul><p>检查你的初始权重是否合理，在关掉正则化项的系统里，是否可以取得100%的准确度。</p><p>在训练过程中，对损失函数结果做记录，以及训练集和交叉验证集上的准确度。</p><p>最常见的权重更新方式是SGD+Momentum，推荐试试RMSProp自适应学习率更新算法。</p><p>随着时间推进要用不同的方式去衰减学习率。</p><p>用交叉验证等去搜索和找到最合适的超参数。</p><p>记得也做做模型融合的工作，对结果有帮助。</p><h1><span id="loss保持常数的采坑记录">loss保持常数的采坑记录</span></h1><p>1.loss等于87.33这个问题是在对Inception-V3网络不管是fine-tuning还是train的时候遇到的，无论网络迭代多少次，网络的loss一直保持恒定。</p><p>原因（溢出）：</p><p>由于loss的最大值由FLT_MIN计算得到，FLT_MIN使其对应的自然对数正好是-87.3356，这也就对应上了loss保持87.3356了。这说明softmax在计算的过程中得到了概率值出现了零，由于softmax是用指数函数计算的，指数函数的值都是大于0的，所以应该是计算过程中出现了float溢出的异常，也就是出现了inf，nan等异常值导致softmax输出为0.当softmax之前的feature值过大时，由于softmax先求指数，会超出float的数据范围，成为inf。inf与其他任何数值的和都是inf，softmax在做除法时任何正常范围的数值除以inf都会变成0.然后求loss就出现了87.3356的情况。</p><p>solution:</p><p>由于softmax输入的feature由两部分计算得到：一部分是输入数据，另一部分是各层的权值等组成:</p><p>(1).减小初始化权重，以使得softmax的输入feature处于一个比较小的范围</p><p>(2).降低学习率，这样可以减小权重的波动范围</p><p>(3).如果有BN(batch normalization)层，finetune时最好不要冻结BN的参数，否则数据分布不一致时很容易使输出值变得很大(注意将batch_norm_param中的use_global_stats设置为false )。</p><p>(4).观察数据中是否有异常样本或异常label导致数据读取异常</p><h1><span id="loss不下降的常见原因">loss不下降的常见原因</span></h1><p>1）数据的输入是否正常，data和label是否一致。</p><p>2）网络架构的选择，一般是越深越好，也分数据集。 并且用不用在大数据集上pre-train的参数也很重要的。</p><p>3）loss 对不对。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;&lt;span id=&quot;train-loss与test-loss结果分析&quot;&gt;train loss与test loss结果分析&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;train loss 不断下降，test loss不断下降，说明网络仍在学习;&lt;/p&gt;
&lt;p&gt;train loss 不断
      
    
    </summary>
    
    
      <category term="tensorflow" scheme="http://dinry.github.io/tags/tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>西瓜书day2,day3,day4(线性模型)</title>
    <link href="http://dinry.github.io/%E8%A5%BF%E7%93%9C%E4%B9%A6day2/"/>
    <id>http://dinry.github.io/西瓜书day2/</id>
    <published>2019-07-09T08:20:52.000Z</published>
    <updated>2019-07-11T11:07:25.218Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="基本形式">基本形式</span></h1><p>example:</p><p>$\mathbb{x}=(x_1;x_2;...;x_d)$</p><p>$x_i$是 $\mathbb{x}$ 在第i个属性上的取值线性模型试图学得$f(\mathbb{x})=\mathbb{w}^T\mathbb{x}+b$ 来预测函数，$\mathbb{w}$ 和 $b$ 为参数</p><p>线性模型优点：可解释性强</p><p>分类：</p><ul><li>回归</li><li>分类</li></ul><h1><span id="回归">回归</span></h1><p>均方误差是回归任务中最常用的性能度量</p><h2><span id="一元线性回归">一元线性回归</span></h2><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day2/1.png" alt><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day2/2.png" alt><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day2/3.png" alt><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day2/4.png" alt><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day2/5.png" alt></p><h2><span id="多元线性回归">多元线性回归</span></h2><p>更一般的情形，样本由多个属性决定，此时$f(\mathbb{x}_i)=\mathbb{w}^T\mathbb{x}_i+b$, 称为多元线性回归</p><p>依旧用最小二乘法<img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day2/6.png" alt><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day2/7.png" alt><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day2/8.png" alt><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day2/9.png" alt></p><h2><span id="对数几率回归">对数几率回归</span></h2><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day2/10.jpg" alt><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day2/11.jpg" alt><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day2/12.jpg" alt></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;&lt;span id=&quot;基本形式&quot;&gt;基本形式&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;example:&lt;/p&gt;
&lt;p&gt;$\mathbb{x}=(x_1;x_2;...;x_d)$&lt;/p&gt;
&lt;p&gt;$x_i$是 $\mathbb{x}$ 在第i个属性上的取值线性模型试图学得$f(\math
      
    
    </summary>
    
      <category term="ML" scheme="http://dinry.github.io/categories/ML/"/>
    
    
      <category term="西瓜书" scheme="http://dinry.github.io/tags/%E8%A5%BF%E7%93%9C%E4%B9%A6/"/>
    
  </entry>
  
  <entry>
    <title>西瓜书day1（绪论）</title>
    <link href="http://dinry.github.io/%E8%A5%BF%E7%93%9C%E4%B9%A6day1/"/>
    <id>http://dinry.github.io/西瓜书day1/</id>
    <published>2019-07-08T07:30:32.000Z</published>
    <updated>2019-07-08T08:33:51.010Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="绪论">绪论</span></h1><p>机器学习致力于研究如何通过计算的手段，利用经验来改善系统自身的性能。经验即数据。</p><p>机器学习所研究的主要内容，是关于在计算机上从数据中产生“模型”的算法，learning algorithms.再用模型来预测未来数据。</p><h1><span id="术语">术语</span></h1><p>记录：</p><p>数据集：记录的集合</p><p>训练：从数据中学习模型的过程</p><p>训练集：训练过程中使用的数据样本的集合</p><p>分类任务：预测的结果为离散值（好瓜，坏瓜）</p><p>回归任务：预测值是连续值</p><p>根据训练数据是否有label，学习任务可划分为：“监督学习”，“无监督学习”</p><p>泛化能力：学得模型适用于新样本的能力</p><h1><span id="归纳演绎">归纳演绎</span></h1><p>归纳：从特殊到一般（机器学习）</p><p>演绎：从一般到特殊</p><h1><span id="发展历程">发展历程</span></h1><p>机器学习是人工智能研究发展到一定阶段的必然产物。</p><table><thead><tr><th>年代</th><th>事件</th><th>代表工作</th></tr></thead><tbody><tr><td>二十世纪而五十年代到七十年代</td><td>人工智能的推理期</td><td>感知机、Adaline</td></tr><tr><td>五十年代中后期</td><td>符号主义蓬勃发展，决策理论。增强学习</td><td>结构学习系统，概念学习系统</td></tr><tr><td>八十年代</td><td>决策树学习</td><td>由于复杂度过高而陷入低潮</td></tr><tr><td>九十年代</td><td>基于神将网络的连接学习</td><td>hopfield,BP,产生黑箱模型</td></tr><tr><td>九十年代中期</td><td>统计学习</td><td>SVM, 核方法</td></tr><tr><td>二十一世纪初</td><td>深度学习</td><td>对数据，硬件要求高</td></tr></tbody></table><h1><span id="应用现状">应用现状</span></h1><p>今天，在计算机学科的诸多分支学科中，无论是多媒体，图形学，还是网络通信，软件工程，体系结构，芯片设计都能找到机器学习的身影，尤其是CV与NLP。</p><p>交叉学科：生物信息学</p><p>大数据时代的三大技术：机器学习，云计算，众包</p><p>数据挖掘与机器学习的关系：</p><p>数据挖掘技术在二十世纪九十年代形成，受数据库，机器学习，统计学影响最大。数据挖掘是从海量知识中发掘知识，这就必然涉及对海量数据的管理分析。数据库领域的研究为数据挖掘提供数据管理技术，而机器学习和统计学研究为数据挖掘提供数据分析技术，统计学主要是通过机器学习对数据挖掘发挥影响，机器学习领域与数据库领域是数据挖掘的两大支撑。</p><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day1/1.jpg" alt></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;&lt;span id=&quot;绪论&quot;&gt;绪论&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;机器学习致力于研究如何通过计算的手段，利用经验来改善系统自身的性能。经验即数据。&lt;/p&gt;
&lt;p&gt;机器学习所研究的主要内容，是关于在计算机上从数据中产生“模型”的算法，learning algorithms.再
      
    
    </summary>
    
      <category term="ML" scheme="http://dinry.github.io/categories/ML/"/>
    
    
      <category term="西瓜书" scheme="http://dinry.github.io/tags/%E8%A5%BF%E7%93%9C%E4%B9%A6/"/>
    
  </entry>
  
  <entry>
    <title>tensorflow深度学习(2):tf.nn.top_k()</title>
    <link href="http://dinry.github.io/tensorflow%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-2-tf-nn-top-k/"/>
    <id>http://dinry.github.io/tensorflow深度学习-2-tf-nn-top-k/</id>
    <published>2019-07-05T03:42:07.000Z</published>
    <updated>2019-07-05T03:47:15.683Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="introduction">introduction</span></h1><p>def top_k(input, k=1, sorted=True, name=None)</p><p>Finds values and indices of the k largest entries for the last dimension.</p><p>If the input is a vector (rank=1), finds the k largest entries in the vector and outputs their values and indices as vectors.Thus values[j] is the j-th largest entry in input, and its index is indices[j].</p><p>For matrices (resp. higher rank input), computes the top k entries in each row (resp. vector along the last dimension).Thus, values.shape = indices.shape = input.shape[:-1] + [k]</p><p>If two elements are equal, the lower-index element appears first.</p><h1><span id="parameters">parameters</span></h1><p><img src="/tensorflow%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-2-tf-nn-top-k/1.JPG" alt></p><h1><span id="code">code</span></h1><p><img src="/tensorflow%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-2-tf-nn-top-k/2.JPG" alt></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;&lt;span id=&quot;introduction&quot;&gt;introduction&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;def top_k(input, k=1, sorted=True, name=None)&lt;/p&gt;
&lt;p&gt;Finds values and indices of the
      
    
    </summary>
    
    
      <category term="tensorflow" scheme="http://dinry.github.io/tags/tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>temsorflow常用集合(colection)</title>
    <link href="http://dinry.github.io/tensorflow%E5%B8%B8%E7%94%A8%E9%9B%86%E5%90%88/"/>
    <id>http://dinry.github.io/tensorflow常用集合/</id>
    <published>2019-07-05T02:55:07.000Z</published>
    <updated>2019-07-05T03:23:05.388Z</updated>
    
    <content type="html"><![CDATA[<p>tensorflow 用集合collection组织不同类别的对象，tf.GraphKeys中包含了所有默认集合的名称。</p><p>collection在对应的scope内提供了“零存整取”的思想：任意位置，任意层次的对象，统一提取。</p><p>tf.optimizer只优化tf.GraphKeys.TRAINABLE_VARIABLES中的变量</p><h2><span id="常用集合">常用集合</span></h2><ul><li>Variable集合：模型参数</li><li>summary 集合：监测</li><li>自定义集合</li></ul><h1><span id="variable">Variable</span></h1><p>Variable被收集在tf.GraphKeys.VARIABLES的collection中</p><h2><span id="定义">定义</span></h2><p>k=tf.Variable()<img src="/tensorflow%E5%B8%B8%E7%94%A8%E9%9B%86%E5%90%88/1.JPG" alt></p><h1><span id="summary">summary</span></h1><p>Summary被收集在名为tf.GraphKeys.SUMMARIES的collection中</p><h2><span id="define">define</span></h2><p>对网络中tensor取值进行监测</p><p>调用tf.scalar_summary系列函数，会向默认的collection中添加一个operation</p><p><img src="/tensorflow%E5%B8%B8%E7%94%A8%E9%9B%86%E5%90%88/2.JPG" alt></p><h1><span id="自定义">自定义</span></h1><p>tf.add_to_collection(&quot;losses&quot;,l1)losses=tf.get_collection('losses')</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;tensorflow 用集合collection组织不同类别的对象，tf.GraphKeys中包含了所有默认集合的名称。&lt;/p&gt;
&lt;p&gt;collection在对应的scope内提供了“零存整取”的思想：任意位置，任意层次的对象，统一提取。&lt;/p&gt;
&lt;p&gt;tf.optimiz
      
    
    </summary>
    
    
      <category term="tensorflow" scheme="http://dinry.github.io/tags/tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>机器学习之线性模型推导</title>
    <link href="http://dinry.github.io/machine-learning-2/"/>
    <id>http://dinry.github.io/machine-learning-2/</id>
    <published>2019-07-02T05:50:36.000Z</published>
    <updated>2019-07-02T06:24:26.420Z</updated>
    
    <content type="html"><![CDATA[<p>西瓜书，南瓜书</p><h1><span id="一元线性回归">一元线性回归</span></h1><p>最小二乘法推导</p><h2><span id="b的公式推导3638">b的公式推导（3.6，3.8）</span></h2><p>（二元函数求最值）</p><p>1.由最小二乘法导出损失函数E（w,b）</p><p>2.证明损失函数是关于w,b的凸函数</p><p>3.对损失函数关于B求偏导数</p><p>4.另一接偏导数为0求b</p><p>由最小二乘法导出损失函数：</p><p>$E_{w,b}=\sum_{i=1}^m$</p><h2><span id="w的公式推导3537">w的公式推导（3.5，3.7）</span></h2><h1><span id="多元线性回归">多元线性回归</span></h1>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;西瓜书，南瓜书&lt;/p&gt;
&lt;h1&gt;&lt;span id=&quot;一元线性回归&quot;&gt;一元线性回归&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;最小二乘法推导&lt;/p&gt;
&lt;h2&gt;&lt;span id=&quot;b的公式推导3638&quot;&gt;b的公式推导（3.6，3.8）&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;（二元函数求最值）&lt;/p
      
    
    </summary>
    
    
      <category term="machine learning" scheme="http://dinry.github.io/tags/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title>machine learning(1)</title>
    <link href="http://dinry.github.io/machine-learning-1/"/>
    <id>http://dinry.github.io/machine-learning-1/</id>
    <published>2019-07-02T01:36:05.000Z</published>
    <updated>2019-07-02T05:47:00.271Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="机器学习的四大应用领域及其应用">机器学习的四大应用领域及其应用</span></h1><h2><span id="数据挖掘发现数据之间的关系">数据挖掘：发现数据之间的关系</span></h2><p>1.回归问题</p><p>2.分类问题</p><p>根据已知数据，学习函数。</p><h2><span id="计算机视觉像人一样看懂世界">计算机视觉：像人一样看懂世界</span></h2><p>图像分类</p><p>目标检测（无人驾驶）</p><p>语义分割（无人驾驶）</p><p>场景理解（无人驾驶）</p><h2><span id="nlp像人一样看懂文字">NLP：像人一样看懂文字</span></h2><p>文本分类（新闻分类）</p><p>自动生成文本摘要</p><p>翻译</p><p>QA</p><p>人机对话（小冰）</p><p>image to text</p><p>end to end级自动驾驶</p><h2><span id="机器人决策像人一样具有决策能力">机器人决策：像人一样具有决策能力</span></h2><p>TORCS平台（玩赛车游戏）：增强学习（agent,action）</p><p>机器人开门（自动执行）：增强学习</p><h1><span id="机器学习理论分类">机器学习理论分类</span></h1><p>常用的三类：</p><p>1.传统的监督学习（分类，回归）</p><p>2.深度学习（视觉，NLP）</p><p>3.强化学习（机器人）</p><p>三种分类学习按标号顺序循序渐进</p><h1><span id="先重点再难点">先重点，再难点</span></h1><p><img src="/machine-learning-1/1.jpg" alt></p><p><img src="/machine-learning-1/2.jpg" alt></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;&lt;span id=&quot;机器学习的四大应用领域及其应用&quot;&gt;机器学习的四大应用领域及其应用&lt;/span&gt;&lt;/h1&gt;
&lt;h2&gt;&lt;span id=&quot;数据挖掘发现数据之间的关系&quot;&gt;数据挖掘：发现数据之间的关系&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;1.回归问题&lt;/p&gt;
&lt;p&gt;2.分类问题&lt;/
      
    
    </summary>
    
    
      <category term="machine learning" scheme="http://dinry.github.io/tags/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title>调参技巧汇总</title>
    <link href="http://dinry.github.io/%E8%B0%83%E5%8F%82%E6%8A%80%E5%B7%A7%E6%B1%87%E6%80%BB/"/>
    <id>http://dinry.github.io/调参技巧汇总/</id>
    <published>2019-06-28T02:33:02.000Z</published>
    <updated>2019-06-28T03:31:40.553Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>推荐系统评估指标(Rank)</title>
    <link href="http://dinry.github.io/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87/"/>
    <id>http://dinry.github.io/推荐系统评估指标/</id>
    <published>2019-06-24T11:09:54.000Z</published>
    <updated>2019-06-24T11:54:46.854Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="mean-average-precision-map">Mean Average Precision (MAP)</span></h1><p>$AP=\frac {\sum_{j=1}^{n_i}P(j)\cdot y_{i,j}}{\sum_{j=1}^{n_i}y_{i,j}}$</p><p>其中，$y_{i,j}$: 排序中第j个元素对于查询i是否是相关的；相关为1，不相关为0。</p><p>$P(j)=\frac {\sum_{k:\pi_{i}(k)\leq\pi_{i}(j)} y_{i,k}}{\pi_{i}(j)}$</p><p>其中，$\pi_{i}(j)$为J的排序位置。</p><p>例如：</p><table><thead><tr><th>rank_no</th><th>是否相关</th></tr></thead><tbody><tr><td>1</td><td>1</td></tr><tr><td>2</td><td>0</td></tr><tr><td>3</td><td>1</td></tr><tr><td>4</td><td>0</td></tr><tr><td>5</td><td>1</td></tr><tr><td>6</td><td>0</td></tr></tbody></table><p>则根据AP计算公式：$AP=(1*1 + (1/2) *0+ (2/3)*1 + (2/4)*0 + (3/5)*0 + (3/6)*0) /3$</p><p>AP的最大值是1，MAP就是对所有user求均值。</p><h1><span id="mean-reciprocal-rank-mrr">Mean Reciprocal Rank (MRR)</span></h1><p>$MRR=\frac{1}{\mid Q \mid} \sum_{i=1}^{\mid Q \mid} \frac{1}{rank_i}$</p><p>其中|Q|是查询个数，ranki是第i个查询，第一个相关的结果所在的排列位置。</p><p>例如：</p><table><thead><tr><th>Query</th><th>Result</th><th>Correct response</th><th>Rank</th><th>Reciprocal rank</th></tr></thead><tbody><tr><td>cat</td><td>catten,cati,cats</td><td>cats</td><td>3</td><td>1/3</td></tr><tr><td>tori</td><td>torii,tori,toruses</td><td>tori</td><td>2</td><td>1/2</td></tr><tr><td>virus</td><td>viruses,virii,viri</td><td>viruses</td><td>1</td><td>1</td></tr></tbody></table><p>对于三个查询，每个查询的ranki分别为3、2、1。所以，MRR=1/3∗(1/3+1/2+1/1)</p><h1><span id="ndcgprerec的计算较为简单已在csdn中介绍这里省略">NDCG，pre,rec的计算较为简单，已在CSDN中介绍，这里省略。</span></h1>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;&lt;span id=&quot;mean-average-precision-map&quot;&gt;Mean Average Precision (MAP)&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;$AP=\frac {\sum_{j=1}^{n_i}P(j)\cdot y_{i,j}}{\sum_{j=
      
    
    </summary>
    
      <category term="recommender systems" scheme="http://dinry.github.io/categories/recommender-systems/"/>
    
    
      <category term="评估指标（Rec）" scheme="http://dinry.github.io/tags/%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87%EF%BC%88Rec%EF%BC%89/"/>
    
  </entry>
  
  <entry>
    <title>cluster</title>
    <link href="http://dinry.github.io/cluster/"/>
    <id>http://dinry.github.io/cluster/</id>
    <published>2019-06-21T02:30:54.000Z</published>
    <updated>2019-06-24T00:47:17.731Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="概述">概述</span></h1><p>聚类（Clustering）的本质是对数据进行分类，将相异的数据尽可能地分开，而将相似的数据聚成一个类别（簇），使得同一类别的数据具有尽可能高的同质性（homogeneity），类别之间有尽可能高的异质性（heterogeneity），从而方便从数据中发现隐含的有用信息。聚类算法的应用包含如下几方面：</p><ul><li>其他数据挖掘任务的关键中间环节：用于构建数据概要，用于分类、模式识别、假设生成和测试；用于异常检测，检测远离群簇的点。</li><li>数据摘要、数据压缩、数据降维：例如图像处理中的矢量量化技术。创建一个包含所有簇原型的表，即每个原型赋予一个整数值，作为它在表中的索引。每个对象用与它所在簇相关联的原型的索引表示。</li><li>协同过滤：用于推荐系统和用户细分。</li><li>动态趋势检测：对流数据进行聚类，检测动态趋势和模式。</li><li>用于多媒体数据、生物数据、社交网络数据的应用。</li></ul><h1><span id="聚类算法的分类">聚类算法的分类</span></h1><p>1.hierarchical methods：主要讲给定的数据集进行逐层分解，直到满足某种条件为止。具体可分为“自底向上”和“自顶向下”两种方案。在“自底向上”方案中，初始时每个数据点组成一个单独的组，在接下来的迭代中，按一定的距离度量将相互邻近的组合并成一个组，直至所有的记录组成一个分组或者满足某个条件为止。代表算法有：<img src="https://www2.cs.sfu.ca/CourseCentral/459/han/papers/zhang96.pdf" alt="BIRCH">，<img src="https://www2.cs.sfu.ca/CourseCentral/459/han/papers/guha98.pdf" alt="CURE">，CHAMELEON等。自底向上的凝聚层次聚类如下图所示。</p><p><img src="/cluster/p1.jpg" alt></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;&lt;span id=&quot;概述&quot;&gt;概述&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;聚类（Clustering）的本质是对数据进行分类，将相异的数据尽可能地分开，而将相似的数据聚成一个类别（簇），使得同一类别的数据具有尽可能高的同质性（homogeneity），类别之间有尽可能高的异质性（h
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>gans problem</title>
    <link href="http://dinry.github.io/gans-problem/"/>
    <id>http://dinry.github.io/gans-problem/</id>
    <published>2019-06-18T13:31:22.000Z</published>
    <updated>2019-06-18T13:34:29.985Z</updated>
    
    <content type="html"><![CDATA[<p>自从2014年Ian Goodfellow提出以来，GAN就存在着训练困难、生成器和判别器的loss无法指示训练进程、生成样本缺乏多样性等问题。从那时起，很多论文都在尝试解决，但是效果不尽人意，比如最有名的一个改进DCGAN依靠的是对判别器和生成器的架构进行实验枚举，最终找到一组比较好的网络架构设置，但是实际上是治标不治本，没有彻底解决问题。而今天的主角Wasserstein GAN（下面简称WGAN）成功地做到了以下爆炸性的几点：</p><ul><li>彻底解决GAN训练不稳定的问题，不再需要小心平衡生成器和判别器的训练程度</li><li>基本解决了collapse mode的问题，确保了生成样本的多样性</li><li>训练过程中终于有一个像交叉熵、准确率这样的数值来指示训练的进程，这个数值越小代表GAN训练得越好，代表生成器产生的图像质量越高</li><li>以上一切好处不需要精心设计的网络架构，最简单的多层全连接网络就可以做到</li></ul><p>推荐阅读：《Towards Principled Methods for Training Generative Adversarial Networks》，《Wasserstein GAN》</p><p>而改进后相比原始GAN的算法实现流程却只改了四点：</p><ul><li>判别器最后一层去掉sigmoid</li><li>生成器和判别器的loss不取log</li><li>每次更新判别器的参数之后把它们的绝对值截断到不超过一个固定常数c</li><li>不要用基于动量的优化算法（包括momentum和Adam），推荐RMSProp，SGD也行</li></ul><h1><span id="1原始gan有什么问题">1.原始GAN有什么问题</span></h1><p>原始GAN中：</p><p>对于D，需要最小化如下损失函数，尽可能把真实样本分为正例，生成样本分为负例:<img src="/generate-model/p17.JPG" alt>  (1)</p><p>对于G，Goodfellow一开始提出来一个损失函数，后来又提出了一个改进的损失函数，分别是</p><p>$E_{x\sim P_g}[log(1-D(x))]$  (2)</p><p>$E_{x\sim P_g}[-log(D(x))]$  (3)</p><p>《Towards Principled Methods for Training Generative Adversarial Networks》分别分析了这两种形式的原始GAN各自的问题所在，下面分别说明。</p><h2><span id="第一种原始gan形式的问题">第一种原始GAN形式的问题</span></h2><p>一句话概括：判别器越好，生成器梯度消失越严重。WGAN前作从两个角度进行了论证，第一个角度是从生成器的等价损失函数切入的。</p><p>首先，从Eq.(1)可以知道，固定G，最优的D是 $D^*(x)=\frac{p_r(x)}{p_r(x)+p_g(x)}$       Eq.(4)这个结果就是公式1的最优值，求导而得，就是看一个样本x来自真实分布和生成分布的可能性的相对比例。如果 $p_r(x)=0$且$p_g(x) \neq 0$, 最优判别器就应该非常自信地给出概率0；如果$p_r(x)=p_g(x)$, 说明该样本是真是假的可能性刚好一半一半，此时最优判别器也应该给出概率0.5。</p><p>然而GAN训练有一个trick，就是别把判别器训练得太好，否则在实验中生成器会完全学不动（loss降不下去），为了探究背后的原因，我们就可以看看在极端情况——判别器最优时，生成器的损失函数变成什么。给公式2加上一个不依赖于生成器的项，使之变成:</p><p>$E_{x\sim P_r}[logD(x)]+E_{x\sim P_g}[log(1-D(x))]$</p><p>注意，最小化这个损失函数等价于最小化公式2，而且它刚好是判别器损失函数的反。代入最优判别器即公式4，再进行简单的变换可以得到:</p><p>$E_{x\sim P_r}[log\frac{p_r(x)}{\frac{1}{2}[p_r(x)+p_g(x)]}]+E_{x\sim P_g}[log\frac{p_g(x)}{\frac{1}{2}[p_r(x)+p_g(x)]}]-2log2$=$2JS(P_r||P_g)-2log2$.  Eq.(5)</p><p>变换成这个样子是为了引入Kullback–Leibler divergence（简称KL散度）和Jensen-Shannon divergence（简称JS散度）这两个重要的相似度衡量指标，后面的主角之一Wasserstein距离，就是要来吊打它们两个的。所以接下来介绍这两个重要的配角——KL散度和JS散度：</p><p>$KL(P_1\mid \mid P_2)=E_{x\sim P_1}log\frac{P_1}{P_2}$.  Eq.(6)</p><p>$JS(P1\mid \mid P2)=\frac{1}{2}KL(P_1\mid \mid \frac{P_1+P_2}{2})+\frac{1}{2}KL(P_2\mid \mid \frac{P_1+P_2}{2})$. Eq.(7)</p><p>根据原始GAN定义的判别器loss，我们可以得到最优判别器的形式；而在最优判别器的下，我们可以把原始GAN定义的生成器loss等价变换为最小化真实分布P_r与生成分布P_g之间的JS散度。我们越训练判别器，它就越接近最优，最小化生成器的loss也就会越近似于最小化$P_r$和$P_g$之间的JS散度。</p><p>问题就出在这个JS散度上。我们会希望如果两个分布之间越接近,它们的JS散度越小，我们通过优化JS散度就能将$P_g$“拉向”$P_r$，最终以假乱真。这个希望在两个分布有所重叠的时候是成立的，但是如果两个分布完全没有重叠的部分，或者它们重叠的部分可忽略（下面解释什么叫可忽略），它们的JS散度是多少呢？</p><p>答案是$log2$,因为对于任意$x$, 只有如下四种可能性：</p><p>$P_1(x)=0$且$P_2(x)=0$</p><p>$P_1(x)\neq0$且$P_2(x)\neq0$</p><p>$P_1(x)=0$且$P_2(x)\neq0$</p><p>$P_1(x)\neq0$且$P_2(x)=0$</p><p>第一种对计算JS散度无贡献，第二种情况由于重叠部分可忽略所以贡献也为0，第三种情况对公式7右边第一个项的贡献是$log\frac{P_2}{\frac{1}{2}(P_2+0)}=log2$,第四种情况与之类似，所以最终$JS(P_1\mid \mid P_2)=log2$</p><p>换句话说，无论$P_r$跟$P_g$是远在天边，还是近在眼前，只要它们俩没有一点重叠或者重叠部分可忽略，JS散度就固定是常数$log 2$，而这对于梯度下降方法意味着——梯度为0！此时对于最优判别器来说，生成器肯定是得不到一丁点梯度信息的；即使对于接近最优的判别器来说，生成器也有很大机会面临梯度消失的问题。</p><p>那么$P_r$与$P_g$不重叠或重叠部分可忽略的可能性有多大？不严谨的答案是：非常大。比较严谨的答案是：当$P_r$与$P_g$的支撑集（support）是高维空间中的低维流形（manifold）时，$P_r$与$P_g$重叠部分测度（measure）为0的概率为1。</p><ul><li>支撑集（support）其实就是函数的非零部分子集，比如ReLU函数的支撑集就是(0, +\infty)，一个概率分布的支撑集就是所有概率密度非零部分的集合。</li><li>流形（manifold）是高维空间中曲线、曲面概念的拓广，我们可以在低维上直观理解这个概念，比如我们说三维空间中的一个曲面是一个二维流形，因为它的本质维度（intrinsic dimension）只有2，一个点在这个二维流形上移动只有两个方向的自由度。同理，三维空间或者二维空间中的一条曲线都是一个一维流形。</li><li>测度（measure）是高维空间中长度、面积、体积概念的拓广，可以理解为“超体积”。</li></ul><p>回过头来看第一句话，“当$P_r$与$P_g$的支撑集是高维空间中的低维流形时”，基本上是成立的。原因是GAN中的生成器一般是从某个低维（比如100维）的随机分布中采样出一个编码向量，再经过一个神经网络生成出一个高维样本（比如64x64的图片就有4096维）。当生成器的参数固定时，生成样本的概率分布虽然是定义在4096维的空间上，但它本身所有可能产生的变化已经被那个100维的随机分布限定了，其本质维度就是100，再考虑到神经网络带来的映射降维，最终可能比100还小，所以生成样本分布的支撑集就在4096维空间中构成一个最多100维的低维流形，“撑不满”整个高维空间。</p><p>“撑不满”就会导致真实分布与生成分布难以“碰到面”，这很容易在二维空间中理解：一方面，二维平面中随机取两条曲线，它们之间刚好存在重叠线段的概率为0；另一方面，虽然它们很大可能会存在交叉点，但是相比于两条曲线而言，交叉点比曲线低一个维度，长度（测度）为0，可忽略。三维空间中也是类似的，随机取两个曲面，它们之间最多就是比较有可能存在交叉线，但是交叉线比曲面低一个维度，面积（测度）是0，可忽略。从低维空间拓展到高维空间，就有了如下逻辑：因为一开始生成器随机初始化，所以$P_g$几乎不可能与$P_r$有什么关联，所以它们的支撑集之间的重叠部分要么不存在，要么就比$P_r$和$P_g$的最小维度还要低至少一个维度，故而测度为0。所谓“重叠部分测度为0”，就是上文所言“不重叠或者重叠部分可忽略”的意思。</p><p>我们就得到了WGAN前作中关于生成器梯度消失的第一个论证：在（近似）最优判别器下，最小化生成器的loss等价于最小化$P_r$与$P_g$之间的JS散度，而由于$P_r$与$P_g$几乎不可能有不可忽略的重叠，所以无论它们相距多远JS散度都是常数$log 2$，最终导致生成器的梯度（近似）为0，梯度消失。</p><h3><span id="从第二个角度论证梯度消失">从第二个角度论证梯度消失</span></h3><ul><li>首先，P_r与P_g之间几乎不可能有不可忽略的重叠，所以无论它们之间的“缝隙”多狭小，都肯定存在一个最优分割曲面把它们隔开，最多就是在那些可忽略的重叠处隔不开而已。</li><li>由于判别器作为一个神经网络可以无限拟合这个分隔曲面，所以存在一个最优判别器，对几乎所有真实样本给出概率1，对几乎所有生成样本给出概率0，而那些隔不开的部分就是难以被最优判别器分类的样本，但是它们的测度为0，可忽略。</li><li>最优判别器在真实分布和生成分布的支撑集上给出的概率都是常数（1和0），导致生成器的loss梯度为0，梯度消失。</li></ul><p>有了这些理论分析，原始GAN不稳定的原因就彻底清楚了：判别器训练得太好，生成器梯度消失，生成器loss降不下去；判别器训练得不好，生成器梯度不准，四处乱跑。只有判别器训练得不好不坏才行，但是这个火候又很难把握，甚至在同一轮训练的前后不同阶段这个火候都可能不一样，所以GAN才那么难训练。</p><p><img src="/gans-problem/1.JPG" alt></p><h2><span id="第二种原始gan形式的问题">第二种原始GAN形式的问题</span></h2><p>一句话概括：最小化第二种生成器loss函数，会等价于最小化一个不合理的距离衡量，导致两个问题，一是梯度不稳定，二是collapse mode即多样性不足。《Towards Principled Methods for Training Generative Adversarial Networks》又是从两个角度进行了论证，下面只说第一个角度.</p><p>上文提到固定G，最优的D是$D^<em>(x)=\frac{p_r(x)}{p_r(x)+p_g(x)}$， 这里，我们可以把KL散度变化成含$D^</em>$的模式：</p><p><img src="/gans-problem/9.JPG" alt></p><p>由以上公式可知：</p><p><img src="/gans-problem/10.JPG" alt></p><p>注意上式最后两项不依赖于生成器G，最终得到最小化公式3等价于最小化</p><p>$KL(P_g\mid \mid P_r)-2JS(P_r\mid \mid P_g)$ Eq.(11)</p><p>这个等价最小化目标存在两个严重的问题。</p><p>第一是它同时要最小化生成分布与真实分布的KL散度，却又要最大化两者的JS散度，一个要拉近，一个却要推远！这在直观上非常荒谬，在数值上则会导致梯度不稳定，这是后面那个JS散度项的毛病。</p><p>第二，即便是前面那个正常的KL散度项也有毛病。因为KL散度不是一个对称的衡量，$KL(P_g\mid \mid P_r)$ 与 $KL(P_r\mid \mid P_g)$ 是有差别的。以前者为例：</p><ul><li>当$P_g(x)\rightarrow0$而$P_r(x)\rightarrow1$时，$P_g(x)log\frac{P_g(x)}{P_r(x)}\rightarrow0$, 对$KL(P_g \mid \mid P_r)$的贡献趋于0.</li><li>当$P_g(x)\rightarrow1$而$P_r(x)\rightarrow0$时，$P_g(x)log\frac{P_g(x)}{P_r(x)}\rightarrow+\infty$, 对$KL(P_g \mid \mid P_r)$的贡献趋于无穷大.</li></ul><p>换言之，$KL(P_g \mid \mid  P_r)$ 对于上面两种错误的惩罚是不一样的，第一种错误对应的是“生成器没能生成真实的样本”，惩罚微小；第二种错误对应的是“生成器生成了不真实的样本” ，惩罚巨大。第一种错误对应的是缺乏多样性，第二种错误对应的是缺乏准确性。这一放一打之下，生成器宁可多生成一些重复但是很“安全”的样本，也不愿意去生成多样性的样本，因为那样一不小心就会产生第二种错误，得不偿失。这种现象就是大家常说的collapse mode。</p><p>第一部分小结：在原始GAN的（近似）最优判别器下，第一种生成器loss面临梯度消失问题，第二种生成器loss面临优化目标荒谬、梯度不稳定、对多样性与准确性惩罚不平衡导致mode collapse这几个问题。</p><p>关于实验证明，可以参考paper原文</p><h1><span id="2wgan之前的一个过渡解决方案">2.WGAN之前的一个过渡解决方案</span></h1><p>原始GAN问题的根源可以归结为两点，一是等价优化的距离衡量（KL散度、JS散度）不合理，二是生成器随机初始化后的生成分布很难与真实分布有不可忽略的重叠。</p><p>WGAN前作其实已经针对第二点提出了一个解决方案，就是对生成样本和真实样本加噪声，直观上说，使得原本的两个低维流形“弥散”到整个高维空间，强行让它们产生不可忽略的重叠。而一旦存在重叠，JS散度就能真正发挥作用，此时如果两个分布越靠近，它们“弥散”出来的部分重叠得越多，JS散度也会越小而不会一直是一个常数，于是（在第一种原始GAN形式下）梯度消失的问题就解决了。在训练过程中，我们可以对所加的噪声进行退火（annealing），慢慢减小其方差，到后面两个低维流形“本体”都已经有重叠时，就算把噪声完全拿掉，JS散度也能照样发挥作用，继续产生有意义的梯度把两个低维流形拉近，直到它们接近完全重合。以上是对原文的直观解释。</p><p>在这个解决方案下我们可以放心地把判别器训练到接近最优，不必担心梯度消失的问题。而当判别器最优时，对公式9取反可得判别器的最小loss为：</p><p><img src="/gans-problem/11.JPG" alt></p><p>其中$P_{r+\epsilon},P_{g+\epsilon}$ 分别是加噪声后的真实分布与生成分布。反过来说，从最优判别器的loss可以反推出当前两个加噪分布的JS散度。两个加噪分布的JS散度可以在某种程度上代表两个原本分布的距离，也就是说可以通过最优判别器的loss反映训练进程！</p><p>但是，因为加噪JS散度的具体数值受到噪声的方差影响，随着噪声的退火，前后的数值就没法比较了，所以它不能成为$P_r$和$P_g$距离的本质性衡量。加噪方案是针对原始GAN问题的第二点根源提出的，解决了训练不稳定的问题，不需要小心平衡判别器训练的火候，可以放心地把判别器训练到接近最优，但是仍然没能够提供一个衡量训练进程的数值指标。但是WGAN本作就从第一点根源出发，用Wasserstein距离代替JS散度，同时完成了稳定训练和进程指标的问题！</p><h1><span id="3wasserstein距离的优越性质">3.Wasserstein距离的优越性质</span></h1><p>Wasserstein距离又叫Earth-Mover（EM）距离，定义如下：</p><p>$W(P_r,P_g)=\mathop{inf}\limits_{r\sim \prod(P_r,P_g)}E_{(x,y)\sim\gamma}[\mid \mid x-y\mid \mid ]$ Eq.(12)</p><p>解释说明：$\prod(P_r,P_g)$ 是$P_r$,$P_g$组合起来的所有可能的联合分布的集合，反过来讲，$\prod(P_r,P_g)$ 中每一个分布的边缘分布都是 $P_r$ 和$P_g$. 对于每一个可能的联合分布 $\gamma$ 而言，可以从中采样 $(x,y)\sim \gamma$  得到一个真实样本 $x$ 和一个生成样本 $y$ , 并算出这对样本的距离 $\mid \mid x-y\mid \mid$, 所以可以计算该联合分布 $\gamma$ 下样本对距离的期望值 $\mathbb{E}_{(x, y) \sim \gamma} [\mid \mid x - y\mid \mid]$ 。在所有可能的联合分布中能够对这个期望值取到的下界 $W(P_r,P_g)$ ，就定义为Wasserstein距离。</p><p>直观上可以把 $\mathbb{E}_{(x, y) \sim \gamma} [\mid \mid x - y\mid \mid]$ 理解为在 $\gamma$ 这个“路径规划”下把 $P_r$ 这堆“沙土”挪到 $P_g$ “位置”所需的“消耗”，而 $W(P_r, P_g)$ 就是“最优路径规划”下的“最小消耗”，所以才叫Earth-Mover（推土机）距离。</p><p>Wasserstein距离相比KL散度、JS散度的优越性在于，即便两个分布没有重叠，Wasserstein距离仍然能够反映它们的远近。WGAN本作通过简单的例子展示了这一点。考虑如下二维空间中的两个分布 $P_1$ 和 $P_2$，$P_1$在线段AB上均匀分布， $P_2$ 在线段CD上均匀分布，通过控制参数 $\theta$ 可以控制着两个分布的距离远近。</p><p><img src="/gans-problem/2.JPG" alt></p><p>此时容易得到</p><p><img src="/gans-problem/3.JPG" alt></p><p>KL散度和JS散度是突变的，要么最大要么最小，Wasserstein距离却是平滑的，如果我们要用梯度下降法优化 $\theta$ 这个参数，前两者根本提供不了梯度，Wasserstein距离却可以。类似地，在高维空间中如果两个分布不重叠或者重叠部分可忽略，则KL和JS既反映不了远近，也提供不了梯度，但是Wasserstein却可以提供有意义的梯度。</p><h1><span id="4从wasserstein距离到wgan">4.从Wasserstein距离到WGAN</span></h1><p>既然Wasserstein距离有如此优越的性质，如果我们能够把它定义为生成器的loss，不就可以产生有意义的梯度来更新生成器，使得生成分布被拉向真实分布吗？</p><p>没那么简单，因为Wasserstein距离定义（公式12）中的 $\inf_{\gamma \sim \Pi (P_r, P_g)}$ 没法直接求解，不过没关系，作者用了一个已有的定理把它变换为如下形式:</p><p>$W(P_r, P_g) = \frac{1}{K} \sup_{\mid \mid f\mid\mid_L \leq K} \mathbb{E}<em>{x \sim P_r} [f(x)] - \mathbb{E}</em>{x \sim P_g} [f(x)]$（公式13）</p><p>证明过程见paper附录。</p><p>首先需要介绍一个概念——Lipschitz连续。它其实就是在一个连续函数 $f$ 上面额外施加了一个限制，要求存在一个常数 $K\geq 0$ 使得定义域内的任意两个元素 $x_1$ 和 $x_2$ 都满足</p><p>$\mid f(x_1) - f(x_2)\mid \leq K \mid x_1 - x_2\mid$</p><p>此时称函数 $f$ 的Lipschitz常数为K。</p><p>简单理解，比如说 $f$ 的定义域是实数集合，那上面的要求就等价于 $f$ 的导函数绝对值不超过K。再比如说 $\log (x)$ 就不是Lipschitz连续，因为它的导函数没有上界。Lipschitz连续条件限制了一个连续函数的最大局部变动幅度。</p><p>公式13的意思就是在要求函数f的Lipschitz常数 $\mid \mid f\mid \mid_L$ 不超过K的条件下，对所有可能满足条件的 $f$ 取到 $\mathbb{E}<em>{x \sim P_r} [f(x)] - \mathbb{E}</em>{x \sim P_g} [f(x)]$ 的上界，然后再除以 $K$。特别地，我们可以用一组参数w来定义一系列可能的函数 $f_w$，此时求解公式13可以近似变成求解如下形式</p><p>$K \cdot W(P_r, P_g) \approx \max_{w: \mid f_w\mid_L \leq K} \mathbb{E}<em>{x \sim P_r} [f_w(x)] - \mathbb{E}</em>{x \sim P_g} [f_w(x)]$（公式14）</p><p>由于神经网络的拟合能力足够强大，我们有理由相信，这样定义出来的一系列 $f_w$ 虽然无法囊括所有可能，但是也足以高度近似公式13要求的那个 $sup_{\mid \mid f\mid \mid_L \leq K}$ 了。</p><p>最后，还不能忘了满足公式14中 $\mid \mid f_w\mid \mid_L \leq K$ 这个限制。我们其实不关心具体的K是多少，只要它不是正无穷就行，因为它只是会使得梯度变大K倍，并不会影响梯度的方向。所以作者采取了一个非常简单的做法，就是限制神经网络 $f_\theta$ 的所有参数 $w_i$ 的不超过某个范围 $[-c, c]$，比如 $w_i \in [- 0.01, 0.01]$，此时关于输入样本x的导数 $\frac{\partial f_w}{\partial x}$ 也不会超过某个范围，所以一定存在某个不知道的常数K使得 $f_w$ 的局部变动幅度不会超过它，Lipschitz连续条件得以满足。具体在算法实现中，只需要每次更新完w后把它clip回这个范围就可以了。</p><p>到此为止，我们可以构造一个含参数w、最后一层不是非线性激活层的判别器网络 $f_w$ ，在限制w不超过某个范围的条件下，使得</p><p>$L = \mathbb{E}<em>{x \sim P_r} [f_w(x)] - \mathbb{E}</em>{x \sim P_g} [f_w(x)]$ （公式15）</p><p>尽可能取到最大，此时L就会近似真实分布与生成分布之间的Wasserstein距离（忽略常数倍数K）。注意原始GAN的判别器做的是真假二分类任务，所以最后一层是sigmoid，但是现在WGAN中的判别器 $f_w$ 做的是近似拟合Wasserstein距离，属于回归任务，所以要把最后一层的sigmoid拿掉。</p><p>接下来生成器要近似地最小化Wasserstein距离，可以最小化L，由于Wasserstein距离的优良性质，我们不需要担心生成器梯度消失的问题。再考虑到L的第一项与生成器无关，就得到了WGAN的两个loss。</p><p>$- \mathbb{E}_{x \sim P_g} [f_w(x)]$（公式16，WGAN生成器loss函数）</p><p>$\mathbb{E}<em>{x \sim P_g} [f_w(x)]- \mathbb{E}</em>{x \sim P_r} [f_w(x)]$（公式17，WGAN判别器loss函数）</p><p>公式15是公式17的反，可以指示训练进程，其数值越小，表示真实分布与生成分布的Wasserstein距离越小，GAN训练得越好。</p><p><img src="/gans-problem/4.JPG" alt></p><p>上文说过，WGAN与原始GAN第一种形式相比，只改了四点：</p><ul><li>判别器最后一层去掉sigmoid</li><li>生成器和判别器的loss不取log</li><li>每次更新判别器的参数之后把它们的绝对值截断到不超过一个固定常数c</li><li>不要用基于动量的优化算法（包括momentum和Adam），推荐RMSProp，SGD也行</li></ul><p>前三点都是从理论分析中得到的，已经介绍完毕；第四点却是作者从实验中发现的，属于trick，相对比较“玄”。作者发现如果使用Adam，判别器的loss有时候会崩掉，当它崩掉时，Adam给出的更新方向与梯度方向夹角的cos值就变成负数，更新方向与梯度方向南辕北辙，这意味着判别器的loss梯度是不稳定的，所以不适合用Adam这类基于动量的优化算法。作者改用RMSProp之后，问题就解决了，因为RMSProp适合梯度不稳定的情况。</p><p>实验验证：</p><p>1.判别器所近似的Wasserstein距离与生成器的生成图片质量高度相关，如下所示（此即题图）：</p><p><img src="/gans-problem/5.JPG" alt></p><p>2.WGAN如果用类似DCGAN架构，生成图片的效果与DCGAN差不多：</p><p><img src="/gans-problem/6.JPG" alt></p><p>但是厉害的地方在于WGAN不用DCGAN各种特殊的架构设计也能做到不错的效果，比如如果大家一起拿掉Batch Normalization的话，DCGAN就崩了：</p><p><img src="/gans-problem/7.JPG" alt></p><p>如果WGAN和原始GAN都使用多层全连接网络（MLP），不用CNN，WGAN质量会变差些，但是原始GAN不仅质量变得更差，而且还出现了collapse mode，即多样性不足：</p><p><img src="/gans-problem/8.JPG" alt></p><p>3.在所有WGAN的实验中未观察到collapse mode。</p><p>相比于判别器迭代次数的改变，对判别器架构超参的改变会直接影响到对应的Lipschitz常数K，进而改变近似Wasserstein距离的倍数，前后两轮训练的指标就肯定不能比较了，这是需要在实际应用中注意的。对此我想到了一个工程化的解决方式，不是很优雅：取同样一对生成分布和真实分布，让前后两个不同架构的判别器各自拟合到收敛，看收敛到的指标差多少倍，可以近似认为是后面的K_2相对前面K_1的变化倍数，于是就可以用这个变化倍数校正前后两轮训练的指标。</p><h1><span id="总结">总结</span></h1><p>《Towards Principled Methods for Training Generative Adversarial Networks》分析了Ian Goodfellow提出的原始GAN两种形式各自的问题，第一种形式等价在最优判别器下等价于最小化生成分布与真实分布之间的JS散度，由于随机生成分布很难与真实分布有不可忽略的重叠以及JS散度的突变特性，使得生成器面临梯度消失的问题；第二种形式在最优判别器下等价于既要最小化生成分布与真实分布直接的KL散度，又要最大化其JS散度，相互矛盾，导致梯度不稳定，而且KL散度的不对称性使得生成器宁可丧失多样性也不愿丧失准确性，导致collapse mode现象。</p><p>《Towards Principled Methods for Training Generative Adversarial Networks》针对分布重叠问题提出了一个过渡解决方案，通过对生成样本和真实样本加噪声使得两个分布产生重叠，理论上可以解决训练不稳定的问题，可以放心训练判别器到接近最优，但是未能提供一个指示训练进程的可靠指标，也未做实验验证。</p><p>WGAN引入了Wasserstein距离，由于它相对KL散度与JS散度具有优越的平滑特性，理论上可以解决梯度消失问题。接着通过数学变换将Wasserstein距离写成可求解的形式，利用一个参数数值范围受限的判别器神经网络来最大化这个形式，就可以近似Wasserstein距离。在此近似最优判别器下优化生成器使得Wasserstein距离缩小，就能有效拉近生成分布与真实分布。WGAN既解决了训练不稳定的问题，也提供了一个可靠的训练进程指标，而且该指标确实与生成样本的质量高度相关。作者对WGAN进行了实验验证。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;自从2014年Ian Goodfellow提出以来，GAN就存在着训练困难、生成器和判别器的loss无法指示训练进程、生成样本缺乏多样性等问题。从那时起，很多论文都在尝试解决，但是效果不尽人意，比如最有名的一个改进DCGAN依靠的是对判别器和生成器的架构进行实验枚举，最终找
      
    
    </summary>
    
      <category term="Deep learning" scheme="http://dinry.github.io/categories/Deep-learning/"/>
    
    
      <category term="GAN" scheme="http://dinry.github.io/tags/GAN/"/>
    
  </entry>
  
</feed>
