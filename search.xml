<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Word Embedding</title>
      <link href="/embedding/"/>
      <url>/embedding/</url>
      
        <content type="html"><![CDATA[<h1><span id="dimension-reduction">dimension reduction</span></h1><p><img src="/embedding/1.JPG" alt></p><h1><span id="word-embedding">word Embedding</span></h1><ul><li>Machine learn the meaning of words from reading a lot of documents without supervision.</li><li>Generating Word Vector is Unsupervised</li><li>A word can be understood by its context.<img src="/embedding/2.JPG" alt></li></ul><h1><span id="how-to-exploit-the-context">How to exploit the context?</span></h1><ul><li>count based: If two words $w_i$ and $w_j$ frequently co-occur, $V(w_i)$ and $V(w_j)$ would be close to each other.(Glove Vector)</li></ul><p>$V(w_i) \cdot V(w_j) \to N_{i,j}$, where number of times $w_i$ and $w_j$ in the same document.</p><ul><li>prediction based: predict next word based on previous words.</li></ul><p><img src="/embedding/3.JPG" alt></p><ul><li>take out he input of the neurons in the first layer.</li><li>use it to represent a word w</li><li>word vector. word embedding feature: V(w)具有相同上下文的单词具有相近的分布<img src="/embedding/4.JPG" alt><img src="/embedding/5.JPG" alt><img src="/embedding/6.JPG" alt>如何让两个weight一样？一样有什么好处？</li><li>Given the same initialization</li><li><img src="/embedding/7.JPG" alt></li><li>cross entropy: <img src="/embedding/8.JPG" alt></li></ul><h2><span id="two-class">two class:</span></h2><ul><li>Cbow</li><li>skip-gram<img src="/embedding/9.JPG" alt>结构信息：结构，包含关系等<img src="/embedding/10.JPG" alt><img src="/embedding/11.JPG" alt></li></ul><h1><span id="document-embedding">document Embedding</span></h1><p><img src="/embedding/12.JPG" alt></p>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>自然语言处理NLP中的N-gram模型</title>
      <link href="/n-gram/"/>
      <url>/n-gram/</url>
      
        <content type="html"><![CDATA[<h1><span id="naive-bayes">Naive Bayes</span></h1><p>见 https://dinry.github.io/%E8%A5%BF%E7%93%9C%E4%B9%A6day13/， 这里再复习一下。</p><p>朴素贝叶斯的关键组成是贝叶斯公式与条件独立性假设。为了方便说明，我们举一个垃圾短信分类的例子。</p><p><strong>&quot;在家日赚百万，惊人秘密...&quot;</strong></p><p>$p(垃圾短信 \mid &quot;在家日赚百万&quot;)∝p(垃圾邮件)p(&quot;在家日赚百万&quot;\mid 垃圾短信)$</p><p>由条件独立性假设：</p><p>$p(&quot;在家日赚百万&quot; \mid J)=p(&quot;在&quot;,&quot;家&quot;,&quot;日&quot;,&quot;赚&quot;,&quot;百&quot;,&quot;万&quot;∣J)=p(&quot;在&quot; \mid J)p(&quot;家&quot;\mid J)p(&quot;日&quot;\mid J)p(&quot;赚&quot;\mid J)p(&quot;百&quot;\mid J)p(&quot;万&quot;\mid J)$</p><p>上面每一项条件概率都可以通过在训练数据的垃圾短信中统计每个字出现的次数得到，然而这里有一个问题，朴素贝叶斯将句子处理为一个 <strong>词袋模型（Bag-of-Words, BoW）</strong> ，以至于不考虑每个单词的顺序。这一点在中文里可能没有问题，因为有时候即使把顺序捣乱，我们还是能看懂这句话在说什么，但有时候不行，例如：</p><p><strong>我烤面筋 = 面筋烤我 ？</strong></p><p>那么有没有模型是考虑句子中单词之间的顺序的呢？有，N-gram就是。</p><h1><span id="n-gram">N-gram</span></h1><h2><span id="n-gram简介">N-gram简介</span></h2><p>在介绍N-gram之前，让我们回想一下**“联想”**的过程是怎样发生的。如果你是一个玩LOL的人，那么当我说“正方形打野”、“你是真的皮”，“你皮任你皮”这些词或词组时，你应该能想到的下一个词可能是“大司马”，而不是“五五开”。如果你不是LOL玩家，没关系，当我说“上火”、“金罐”这两个词，你能想到的下一个词应该更可能“加多宝”，而不是“可口可乐”。</p><p>N-gram正是基于这样的想法，它的第一个特点是某个词的出现依赖于其他若干个词，第二个特点是我们获得的信息越多，预测越准确。我想说，我们每个人的大脑中都有一个N-gram模型，而且是在不断完善和训练的。我们的见识与经历，都在丰富着我们的阅历，增强着我们的联想能力。</p><p>N-gram模型是一种语言模型（Language Model，LM），语言模型是一个基于概率的判别模型，它的输入是一句话（单词的顺序序列），输出是这句话的概率，即这些单词的联合概率（joint probability）。</p><p><img src="/n-gram/1.JPG" alt></p><p>N-gram本身也指一个由N个单词组成的集合，各单词具有先后顺序，且不要求单词之间互不相同。常用的有 $Bi-gram(N=2)$ 和 $Tri-gram(N=3)$，一般已经够用了。例如在上面这句话里，我可以分解的 Bi-gram 和 Tri-gram ：</p><p>Bi-gram :  {I, love}, {love, deep}, {love, deep}, {deep, learning}</p><p>Tri-gram :  {I, love, deep}, {love, deep, learning}</p><h2><span id="n-gram中的概率计算">N-gram中的概率计算</span></h2><p>假设我们有一个由n个词组成的句子 $S=(w_1​,w_2​,⋯,w_n​)$，如何衡量它的概率呢？让我们假设，每一个单词 $w_i$ ​都要依赖于从第一个单词 $w_1$ ​到它之前一个单词 $w_{i−1}$​的影响：</p><p>$p(S)=p(w_1w_2⋯w_n)=p(w_1)p(w_2 \mid w_1)⋯p(w_n \mid w_{n−1}⋯w_2w_1)$</p><p>是不是很简单？是的，不过这个衡量方法有两个缺陷：</p><ul><li>参数空间过大，概率 $p(w_n \mid w_{n−1}⋯w_2w_1)$ 的参数有 $O(n)$ 个。</li><li>数据稀疏严重，词同时出现的情况可能没有，组合阶数高时尤其明显。</li></ul><p>为了解决第一个问题，我们引入马尔科夫假设（Markov Assumption）：一个词的出现仅与它之前的若干个词有关。</p><p>$p(w_1⋯w_n)=\prod p(w_i \mid w_{i-1}⋯w_1)=\prod p(w_i \mid w_{i-1}⋯w_{i-N+1})$</p><ul><li>如果一个词的出现仅依赖于它前面出现的一个词，那么我们就称之为 Bi-gram：$p(S)=p(w_1w_2⋯w_n)=p(w_1)p(w_2 \mid w_1)⋯p(w_n \mid w_{n-1})$</li><li>如果一个词的出现仅依赖于它前面出现的两个词，那么我们就称之为 Tri-gram</li></ul><p>N-gram的N可以取很高，然而现实中一般 bi-gram 和 tri-gram 就够用了。</p><p>那么，如何计算其中的每一项条件概率 $p(w_n \mid w_{n−1}⋯w_2w_1)$ 呢？答案是 <strong>极大似然估计（Maximum Likelihood Estimation，MLE）</strong>，说人话就是数频数：</p><p><img src="/n-gram/2.JPG" alt></p><h1><span id="n-gram-的用途">N-gram 的用途</span></h1><h2><span id="用途一词性标注">用途一：词性标注</span></h2><p><img src="/n-gram/3.JPG" alt></p><h2><span id="用途二垃圾短信分类">用途二：垃圾短信分类</span></h2><p><img src="/n-gram/4.JPG" alt></p><h2><span id="用途三分词器">用途三：分词器</span></h2><p><img src="/n-gram/5.JPG" alt></p><h2><span id="用途四机器翻译和语音识别">用途四：机器翻译和语音识别</span></h2><p><img src="/n-gram/6.JPG" alt></p><h1><span id="n-gram中n的确定">N-gram中N的确定</span></h1><p>为了确定N的取值，《Language Modeling with Ngrams》使用了 Perplexity 这一指标，该指标越小表示一个语言模型的效果越好。文章使用了华尔街日报的数据库，该数据库的字典大小为19,979，训练集包含 38 million 个词，测试集包含 1.5 million 个词。针对不同的N-gram，计算各自的 Perplexity。<img src="/n-gram/7.JPG" alt>结果显示，Tri-gram的Perplexity最小，因此它的效果是最好的。</p><h1><span id="n-gram中的数据平滑方法">N-gram中的数据平滑方法</span></h1><p>上面提到，N-gram的N越大，模型 Perplexity 越小，表示模型效果越好。这在直观意义上是说得通的，毕竟依赖的词越多，我们获得的信息量越多，对未来的预测就越准确。然而，语言是有极强的创造性的（Creative），当N变大时，更容易出现这样的状况：某些n-gram从未出现过，这就是稀疏问题。</p><p>n-gram最大的问题就是稀疏问题（Sparsity）。例如，在bi-gram中，若词库中有20k个词，那么两两组合其中的很多组合在语料库中都没有出现，根据极大似然估计得到的组合概率将会是0，从而整个句子的概率就会为0。最后的结果是，我们的模型只能计算零星的几个句子的概率，而大部分的句子算得的概率是0，这显然是不合理的。</p><p>因此，我们要进行数据平滑（data Smoothing），数据平滑的目的有两个：一个是使所有的N-gram概率之和为1，使所有的n-gram概率都不为0。它的本质，是重新分配整个概率空间，使已经出现过的n-gram的概率降低，补充给未曾出现过的n-gram。<img src="/n-gram/8.JPG" alt>关于N-gram的训练数据，如果你以为 <strong>“只要是英语就可以了”</strong>，那就大错特错了。文献《Language Modeling with Ngrams》**的作者做了个实验，分别用莎士比亚文学作品，以及华尔街日报作为训练集训练两个N-gram，他认为，两个数据集都是英语，那么用他们生成的文本应该也会有所重合。然而结果是，用两个语料库生成的文本没有任何重合性，即使在语法结构上也没有。  这告诉我们，N-gram的训练是很挑数据集的，你要训练一个问答系统，那就要用问答的语料库来训练，要训练一个金融分析系统，就要用类似于华尔街日报这样的语料库来训练。</p><h1><span id="n-gram的进化版nnlm">N-gram的进化版：NNLM</span></h1><p>NNLM 即 Neural Network based Language Model，由Bengio在2003年提出，它是一个很简单的模型，由四层组成，输入层、嵌入层、隐层和输出层。模型接收的输入是长度为nn的词序列，输出是下一个词的类别。首先，输入是单词序列的index序列，例如单词 I 在字典（大小为 $\mid V \mid$）中的index是10，单词 am 的 index 是23， Bengio 的 index 是65，则句子“I am Bengio”的index序列就是 10, 23, 65。嵌入层（Embedding）是一个大小为 $\mid V \mid \times K$ 的矩阵，从中取出第10、23、65行向量拼成 $3\times K$ 的矩阵就是Embedding层的输出了。隐层接受拼接后的Embedding层输出作为输入，以tanh为激活函数，最后送入带softmax的输出层，输出概率。</p><p>NNLM最大的缺点就是参数多，训练慢。另外，NNLM要求输入是定长n，定长输入这一点本身就很不灵活，同时不能利用完整的历史信息。</p><p><img src="/n-gram/9.JPG" alt></p><h1><span id="nnlm的进化版rnnlm">NNLM的进化版：RNNLM</span></h1><p>针对NNLM存在的问题，Mikolov在2010年提出了RNNLM，其结构实际上是用RNN代替NNLM里的隐层，这样做的好处包括减少模型参数、提高训练速度、接受任意长度输入、利用完整的历史信息。同时，RNN的引入意味着可以使用RNN的其他变体，像LSTM、BLSTM、GRU等等，从而在时间序列建模上进行更多更丰富的优化。</p><p>http://www.fit.vutbr.cz/~imikolov/rnnlm/thesis.pdf</p><h1><span id="word2vec">Word2Vec</span></h1><p>https://www.jianshu.com/p/e91f061d6d91</p>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>www2019_recommender system</title>
      <link href="/www2019/"/>
      <url>/www2019/</url>
      
        <content type="html"><![CDATA[<h1><span id="1cross-domain-recommendation-without-sharing-user-relevant-data">1.Cross-domain Recommendation Without Sharing User-relevant Data</span></h1><p>研究方向：cross-domain recommendation Task</p><p>Goal: combine data from different websites to improve recommendation task</p><p>Challenge:Despite many research efforts on this task, the main drawback is that they largely assume the data of different systems can be fully shared.</p><p>methods: NATR(short for Neural Attentive Transfer Recommendation)To avoid the leak of user privacy during the data sharing process, it consider sharing only the information of the item side, rather than user behavior data. Specifically, we transfer the item embeddings across domains, making it easier for two companies to reach a consensus (e.g., legal policy) on data sharing since the data to be shared is user-irrelevant and has no explicit semantics.</p><p>step:</p><p><img src="/www2019/1.JPG" alt>Our proposed solution, which has three steps, is illustrated in Figure 1.</p><ul><li>In the first step, an embedding-based recommender model, MF for example, is trained on the user-item interaction matrix of the auxiliary domain to obtain item embeddings.</li><li>In the second step, item embeddings of the auxiliary domain are sent to the target domain; note that only the embeddings of overlapped items are necessary to be sent, which are subjected to the data-sharing policy between two companies.</li><li>Finally, the target domain trains a recommender model with the consideration of the transferred item embeddings.</li></ul><h2><span id="contribution">contribution</span></h2><ul><li>We present a new paradigm for cross-domain recommendation without sharing user-relevant data, in which only item-side data can be shared across domains. To allow the transferring of CF signal, we propose to share the item embeddings which are learned from user-item interactions of the auxiliary domain.</li><li>We propose a new solution NATR to resolve the key challenges in leveraging transferred item embeddings. The twolevel attention design allows NATR to distill useful signal from transferred item embeddings, and appropriately combine them with the data of the target domain.</li><li>We conduct extensive experiments on two real-world datasets to demonstrate our proposed method. More ablation studies verify the efficacy of our designed components, and the utility of transferred item embeddings in addressing the data sparsity issue.</li></ul><h2><span id="framework">framework</span></h2><p><img src="/www2019/2.JPG" alt></p><h1><span id="2dual-graph-attention-networks-for-deep-latent-representation-of-multifaceted-social-effects-in-recommender-systems">2.Dual Graph Attention Networks for Deep Latent Representation of Multifaceted Social Effects in Recommender Systems</span></h1><h2><span id="abstract">Abstract</span></h2><p><img src="/www2019/4.JPG" alt></p><h2><span id="contribution">contribution</span></h2><p><img src="/www2019/5.JPG" alt></p><h2><span id="framework">framework</span></h2><p><img src="/www2019/3.JPG" alt></p><h1><span id="3exploiting-ratings-reviews-and-relationships-for-item-recommendations-in-topic-based-social-networks">3.Exploiting Ratings, Reviews and Relationships for Item Recommendations in Topic Based Social Networks</span></h1><h2><span id="abstract">Abstract</span></h2><p>Many e-commerce platforms today allow users to give their rating scores and reviews on items as well as to establish social relationships with other users. As a result, such platforms accumulate heterogeneous data including numeric scores, short textual reviews, and social relationships. HHowever, many recommender systems only consider historical user feedbacks in modeling user preferences. More specifically, most existing recommendation approaches only use rating scores but ignore reviews and social relationships in the user-generated data. In this paper, we propose TSNPF—a latent factor model to effectively capture user preferences and item features. Employing Poisson factorization, TSNPF fully exploits the wealth of information in rating scores, review text and social relationships altogether. It extracts topics of items and users from the review text and makes use of similarities between user pairs with social relationships, which results in a comprehensive understanding of user preferences. Experimental results on real-world datasets demonstrate that our TSNPF approach is highly effective at recommending items to users.</p><h2><span id="contribution">contribution</span></h2><ul><li>We propose a method based on Gamma-Poisson distribution to extract the topic intensities of items and users from usergenerated textual reviews. Compared to previous techniques, our method is able to address the usual problem of data scarcity.</li><li>We propose TSNPF, a conjugate graphical model based on Poisson factorization which only models non-zero observations in ratings, reviews and social relations simultaneously via interpretable user preferences and item attributes. In addition, we propose a closed form mean-field variational inference method to train TSNPF.</li><li>We evaluate the performance of TSNPF using three publicly available real datasets. The results show that TSNPF outperforms state-of-the-art alternatives.</li></ul><h2><span id="framework">framework</span></h2><p><img src="/www2019/6.JPG" alt></p><p>主题提取与推荐系统的结合</p><h1><span id="4ghostlink-latent-network-inference-for-influence-aware-recommendationintroduction-写的不错">4.GhostLink: Latent Network Inference for Influence-aware Recommendation.(introduction 写的不错)</span></h1><h2><span id="abstract-probabilistic-graphical-model">Abstract (probabilistic graphical model)</span></h2><p>Social influence plays a vital role in shaping a user’s behavior in online communities dealing with items of fine taste like movies, food, and beer. For online recommendation, this implies that users’ preferences and ratings are influenced due to other individuals. Given only time-stamped reviews of users, can we find out whoinfluences- whom, and characteristics of the underlying influence network? Can we use this network to improve recommendation?</p><p>While prior works in social-aware recommendation have leveraged social interaction by considering the observed social network of users, many communities like Amazon, Beeradvocate, and Ratebeer do not have explicit user-user links.Therefore,we propose GhostLink, an unsupervised probabilistic graphical model, to automatically learn the latent influence network underlying a review community – given only the temporal traces (timestamps) of users’ posts and their content. Based on extensive experiments with four real-world datasets with 13 million reviews, we show that GhostLink improves item recommendation by around 23% over state-of-the-art methods that do not consider this influence. As additional use-cases, we show that GhostLink can be used to differentiate between users’ latent preferences and influenced ones, as well as to detect influential users based on the learned influence graph.</p><h2><span id="contribution">contribution</span></h2><ul><li>We propose an unsupervised probabilistic generative model GhostLink based on Latent Dirichlet Allocation to learn a latent influence graph in online communities without requiring explicit user-user links or a social network. This is the first work that solely relies on timestamped review data.</li><li>We propose an efficient algorithm based on Gibbs sampling to estimate the hidden parameters in GhostLink that empirically demonstrates fast convergence.</li><li>We perform large-scale experiments in four communities with 13 million reviews, 0.5 mil. items, and 1 mil. users where we show improved recommendation for item rating prediction by around 23% over state-of-the-art methods. Moreover, we analyze the properties of the influence graph and use it for use-cases like finding influential members in the community.</li></ul><h2><span id="framework">framework</span></h2><p><img src="/www2019/7.JPG" alt></p><h1><span id="5graph-neural-networks-for-social-recommendation">5.Graph Neural Networks for Social Recommendation</span></h1><h2><span id="abstract">Abstract</span></h2><p>In recent years, Graph Neural Networks (GNNs), which can naturally integrate node information and topological structure, have been demonstrated to be powerful in learning on graph data. These advantages of GNNs provide great potential to advance social recommendation since data in social recommender systems can be represented as user-user social graph and user-item graph; and learning latent factors of users and items is the key.</p><p>However, building social recommender systems based on GNNs faces challenges. For example, the user-item graph encodes both interactions and their associated opinions; social relations have heterogeneous strengths; users involve in two graphs (e.g., the useruser social graph and the user-item graph).</p><p>To address the three aforementioned challenges simultaneously, in this paper,we present a novel graph neural network framework (GraphRec) for social recommendations. In particular, we provide a principled approach to jointly capture interactions and opinions in the user-item graph and propose the framework GraphRec, which coherently models two graphs and heterogeneous strengths. Extensive experiments on two real-world datasets demonstrate the effectiveness of the proposed framework GraphRec.</p><h2><span id="contribution">contribution</span></h2><ul><li>We propose a novel graph neural network GraphRec, which can model graph data in social recommendations coherently;</li><li>We provide a principled approach to jointly capture interactions and opinions in the user-item graph;</li><li>We introduce a method to consider heterogeneous strengths of social relations mathematically;</li><li>We demonstrate the effectiveness of the proposed framework on various real-world datasets.</li></ul><h2><span id="framework">framework</span></h2><p><img src="/www2019/8.JPG" alt></p><h2><span id="performance">performance</span></h2><p><img src="/www2019/9.JPG" alt></p><h1><span id="6hierarchical-temporal-convolutional-networks-for-dynamic-recommender-systems工程应用">6.Hierarchical Temporal Convolutional Networks for Dynamic Recommender Systems(工程应用)</span></h1><h2><span id="abstract">Abstract</span></h2><p>Recommender systems that can learn from cross-session data to dynamically predict the next item a user will choose are crucial for online platforms. However, existing approaches often use out-ofthe-box sequence models which are limited by speed and memory consumption, are often infeasible for production environments, and usually do not incorporate cross-session information, which is crucial for effective recommendations.</p><p>Here we propose Hierarchical Temporal Convolutional Networks (HierTCN), a hierarchical deep learning architecture that makes dynamic recommendations based on users’ sequential multi-session interactions with items. HierTCN is designed for web-scale systems with billions of items and hundreds of millions of users. It consists of two levels of models: The high-level model uses Recurrent Neural Networks (RNN) to aggregate users’ evolving long-term interests across different sessions, while the low-level model is implemented with Temporal Convolutional Networks (TCN), utilizing both the long-term interests and the short-term interactions within sessions to predic  the next interaction.</p><h2><span id="contribution">contribution</span></h2><ul><li>HierTCN has a significant performance improvement over existing deep learning models by about 30% on a public XING dataset and 18% on a private large-scale Pinterest dataset.</li><li>Compared with RNN-based approaches, HierTCN is 2.5 times faster in terms of training time and allows for much easier gradient backpropagation.</li><li>Compared with CNN-based approaches, HierTCN requires roughly 10% data memory usage and allows for easy latent feature extraction.</li></ul><h2><span id="framework">framework</span></h2><p><img src="/www2019/10.JPG" alt></p><h1><span id="7how-intention-informed-recommendations-modulate-choices-a-field-study-of-spokenword-content">7.How Intention Informed Recommendations Modulate Choices: A Field Study of SpokenWord Content</span></h1><h2><span id="abstract">Abstract</span></h2><p>People’s content choices are ideally driven by their intentions, aspirations, and plans.</p><p>However, in reality, choices may be modulated by recommendation systems which are typically trained to promote popular items and to reinforce users’ historical behavior. As a result, the utility and user experience of content consumption can be affected implicitly and undesirably.</p><p>To study this problem, we conducteda 2 × 2 randomized controlled field experiment (105 urbancollege students) to compare the effects of intention informed recommendationswith classical intention agnostic systems. The studywas conducted in the context of spokenwordweb content (podcasts)which is often consumed through subscription sites or apps. Wemodified a commercial podcast app to include (1) a recommenderthat takes into account users’ stated intentions at onboarding, and(2) a Collaborative Filtering (CF) recommender during daily use.Our study suggests that: (1) intention-aware recommendations cansignificantly raise users’ interactions (subscriptions and listening)with channels and episodes related to intended topics by over 24%,even if such a recommender is only used during onboarding, and (2)the CF-based recommender doubles users’ explorations on episodesfrom not-subscribed channels and improves satisfaction for usersonboarded with the intention-aware recommender.</p><h2><span id="contribution">contribution</span></h2><p><img src="/www2019/11.JPG" alt></p><h2><span id="framework">framework</span></h2><p><img src="/www2019/12.JPG" alt></p><h1><span id="8how-serendipity-improves-user-satisfaction-with-recommendations-a-large-scale-user-evaluation">8.How Serendipity Improves User Satisfaction with Recommendations? A Large-Scale User Evaluation</span></h1><h2><span id="abstract">Abstract</span></h2><p>Recommendation serendipity is being increasingly recognized asbeing equally important as the other beyond-accuracy objectives(such as novelty and diversity), in eliminating the “filter bubble”phenomenon of the traditional recommender systems.</p><p>However,little work has empirically verified the effects of serendipity onincreasing user satisfaction and behavioral intention.</p><p>In this paper,we report the results of a large-scale user survey (involving over3,000 users) conducted in an industrial mobile e-commerce setting.The study has identified the significant causal relationships fromnovelty, unexpectedness, relevance, and timeliness to serendipity,and from serendipity to user satisfaction and purchase intention.Moreover, our findings reveal that user curiosity plays a moderatingrole in strengthening the relationships from novelty to serendipityand from serendipity to satisfaction. Our third contribution lies inthe comparison of several recommender algorithms, which demonstratesthe significant improvements of the serendipity-orientedalgorithm over the relevance- and novelty-oriented approaches interms of user perceptions. We finally discuss the implications ofthis experiment, which include the feasibility of developing a moreprecise metric for measuring recommendation serendipity, andthe potential benefit of a curiosity-based personalized serendipitystrategy for recommender systems.<img src="/www2019/13.JPG" alt></p><h1><span id="9improving-outfit-recommendation-with-co-supervision-of-fashion-generation-图像衣服类">9.Improving Outfit Recommendation with Co-supervision of Fashion Generation (图像：衣服类)</span></h1><h2><span id="abstract">Abstract</span></h2><p>The task of fashion recommendation includes twomain challenges:visual understanding and visual matching. Visual understandingaims to extract effective visual features. Visual matching aims tomodel a human notion of compatibility to compute a match betweenfashion items. Most previous studies rely on recommendationloss alone to guide visual understanding and matching. Althoughthe features captured by thesemethods describe basic characteristics(e.g., color, texture, shape) of the input items, they arenot directly related to the visual signals of the output items (to berecommended). This is problematic because the aesthetic characteristics(e.g., style, design), based on which we can directly inferthe output items, are lacking. Features are learned under the recommendationloss alone, where the supervision signal is simplywhether the given two items are matched or not.</p><p>To address this problem, we propose a neural co-supervisionlearning framework, called the FAshion RecommendationMachine(FARM). FARM improves visual understanding by incorporatingthe supervision of generation loss, which we hypothesize to beable to better encode aesthetic information. FARMenhances visualmatching by introducing a novel layer-to-layer matching mechanismto fuse aesthetic information more effectively, and meanwhileavoiding paying too much attention to the generation qualityand ignoring the recommendation performance.</p><p>Extensive experiments on two publicly available datasets showthat FARM outperforms state-of-the-art models on outfit recommendation,in terms of AUC and MRR. Detailed analyses of generatedand recommended items demonstrate that FARM can encodebetter features and generate high quality images as references toimprove recommendation performance.</p><h2><span id="contribution">contribution</span></h2><ul><li>We propose a neural co-supervision learning framework, FARM, for outfit recommendation that simultaneously yields recommendation and generation.</li><li>We propose a layer-to-layer matching mechanism that acts as a bridge between generation and recommendation, and improves recommendation by leveraging generation features.</li><li>Our proposed approach is shown to be effective in experiments on two large-scale datasets.</li></ul><h2><span id="framework">framework</span></h2><p><img src="/www2019/14.JPG" alt><img src="/www2019/15.JPG" alt></p><h1><span id="10jointly-learning-explainable-rules-for-recommendation-with-knowledge-graph">10.Jointly Learning Explainable Rules for Recommendation with Knowledge Graph</span></h1><h2><span id="abstract">Abstract</span></h2><p>Explainability and effectiveness are two key aspects for building recommendersystems. Prior efforts mostly focus on incorporating sideinformation to achieve better recommendation performance.</p><p>However,these methods have some weaknesses: (1) prediction of neuralnetwork-based embedding methods are hard to explain and debug;(2) symbolic, graph-based approaches (e.g., meta path-based models)require manual efforts and domain knowledge to define patternsand rules, and ignore the item association types (e.g. substitutableand complementary).</p><p>In this paper, we propose a novel joint learningframework to integrate induction of explainable rules from knowledgegraph with construction of a rule-guided neural recommendationmodel. The framework encourages two modules to complementeach other in generating effective and explainable recommendation:</p><ol><li>inductive rules, mined from item-centric knowledge graphs,summarize common multi-hop relational patterns for inferring differentitem associations and provide human-readable explanationfor model prediction; 2) recommendation module can be augmentedby induced rules and thus have better generalization ability dealingwith the cold-start issue.</li></ol><p>Extensive experiments1 show that ourproposed method has achieved significant improvements in itemrecommendation over baselines on real-world datasets. Our modeldemonstrates robust performance over “noisy&quot; item knowledgegraphs, generated by linking item names to related entities.</p><h2><span id="contribution">contribution</span></h2><ul><li>We utilize a large-scale knowledge graph to derive rules between items from item associations.</li><li>We propose a joint optimization framework that induces rules from knowledge graphs and recommends items based on the rules at the same time.</li><li>We conduct extensive experiments on real-world datasets. Experimental results prove the effectiveness of our framework in accurate and explainable recommendation.</li></ul><h2><span id="framework">framework</span></h2><p><img src="/www2019/16.JPG" alt></p><h1><span id="11jointly-leveraging-intent-and-interaction-signals-to-predict-user-satisfaction-with-slate-recommendations">11.Jointly Leveraging Intent and Interaction Signals to Predict User Satisfaction with Slate Recommendations.</span></h1><h2><span id="abstract">Abstract</span></h2><p>Detecting and understanding implicit measures of user satisfactionare essential for enhancing recommendation quality. When usersinteract with a recommendation system, they leave behind finegrained traces of interaction signals, which contain valuable informationthat could help gauging user satisfaction. User interactionwith such systems is often motivated by a specific need or intent, oftennot explicitly specified by the user, but can nevertheless informon how the user interacts with, and the extent to which the user issatisfied by the recommendations served. In this work, we considera complex recommendation scenario, called Slate Recommendation,wherein a user is presented with an ordered set of collections, calledslates, in a specific page layout. We focus on the context of musicstreaming and leverage fine-grained user interaction signals totackle the problem of predicting user satisfaction.</p><p>We hypothesize that user interactions are conditional on thespecific intent users have when interacting with a recommendationsystem, and highlight the need for explicitly considering userintent when interpreting interaction signals. We present diverseapproaches to identify user intents (interviews, surveys and a quantitativeapproach) and identify a set of common intents users have ina music streaming recommendation setting. Additionally, we identifythe importance of shared learning across intents and propose amulti-level hierarchical model for user satisfaction prediction thatleverages user intent information alongside interaction signals. Ourfindings from extensive experiments on a large scale real world datademonstrate (i) the utility of considering different interaction signals,(ii) the role of intents in interpreting user interactions and (iii)the interplay between interaction signals and intents in predictinguser satisfaction.</p><h1><span id="12modeling-heart-rate-and-activity-data-for-personalized-fitness-recommendation健康推荐">12.Modeling Heart Rate and Activity Data for Personalized Fitness Recommendation(健康推荐)</span></h1><h2><span id="abstract">Abstract</span></h2><p>Activity logs collected from wearable devices (e.g. Apple Watch,Fitbit, etc.) are a promising source of data to facilitate a wide rangeof applications such as personalized exercise scheduling, workoutrecommendation, and heart rate anomaly detection.</p><p>However,such data are heterogeneous, noisy, diverse in scale and resolution,and have complex interdependencies, making them challenging tomodel.</p><p>In this paper, we develop context-aware sequential modelsto capture the personalized and temporal patterns of fitness data.</p><p>Specifically, we propose FitRec – an LSTM-based model that capturestwo levels of context information: context within a specificactivity, and context across a user’s activity history.</p><h2><span id="contribution">contribution</span></h2><p><img src="/www2019/17.JPG" alt></p><h2><span id="framework">framework</span></h2><p><img src="/www2019/18.JPG" alt></p><h1><span id="13modeling-item-specific-temporal-dynamics-of-repeat-consumption-for-recommender-systems">13.Modeling Item-Specific Temporal Dynamics of Repeat Consumption for Recommender Systems</span></h1><h2><span id="abstract">Abstract</span></h2><p>Repeat consumption is a common scenario in daily life, such asrepurchasing items and revisiting websites, and is a critical factorto be taken into consideration for recommender systems. Temporaldynamics play important roles in modeling repeat consumption.It is noteworthy that for items with distinct lifetimes, consumingtendency for the next one fluctuates differently with time. Forexample, users may repurchase milk weekly, but it is possible torepurchase mobile phone after a long period of time. Therefore,how to adaptively incorporate various temporal patterns of repeatconsumption into a holistic recommendation model has been a newand important problem.</p><p>In this paper, we propose a novel unified model with introducingHawkes Process into Collaborative Filtering (CF). Differentfrom most previous work which ignores various time-varying patternsof repeat consumption, the model explicitly addresses twoitem-specific temporal dynamics: (1) short-term effect and (2) lifetimeeffect, which is named as Short-Term and Life-Time RepeatConsumption (SLRC) model. SLRC learns importance of the twofactors for each item dynamically by interpretable parameters.</p><h2><span id="contribution">contribution</span></h2><p><img src="/www2019/19.JPG" alt></p><h1><span id="14multi-task-feature-learning-for-knowledge-graph-enhanced-recommendationcross-domain-recommendation">14.Multi-Task Feature Learning for Knowledge Graph Enhanced Recommendation(cross-domain recommendation)</span></h1><h2><span id="abstract">Abstract</span></h2><p>Collaborative filtering often suffers from sparsity and cold startproblems in real recommendation scenarios, therefore, researchersand engineers usually use side information to address the issuesand improve the performance of recommender systems.</p><p>In thispaper, we consider knowledge graphs as the source of side information.</p><p>We propose MKR, a Multi-task feature learning approachfor Knowledge graph enhanced Recommendation. MKR is a deepend-to-end framework that utilizes knowledge graph embeddingtask to assist recommendation task.</p><h2><span id="contribution">contribution</span></h2><p>We propose MKR, a Multi-task feature learning approachfor Knowledge graph enhanced Recommendation. MKR is a deepend-to-end framework that utilizes knowledge graph embeddingtask to assist recommendation task. knowledge graph embedding, as shown in theoretical analysis and experiment results.</p><h2><span id="framework">framework</span></h2><p><img src="/www2019/20.JPG" alt></p><h1><span id="15multimodal-review-generation-for-recommender-systems">15.Multimodal Review Generation for Recommender Systems</span></h1><h2><span id="abstract">Abstract</span></h2><p>Key to recommender systems is learning user preferences, whichare expressed through various modalities. In online reviews, forinstance, this manifests in numerical rating, textual content, as wellas visual images. In this work, we hypothesize that modelling thesemodalities jointly would result in a more holistic representation ofa review towards more accurate recommendations. Therefore, wepropose Multimodal Review Generation (MRG), a neural approachthat simultaneously models a rating prediction component and areview text generation component. We hypothesize that the shareduser and item representations would augment the rating predictionwith richer information from review text, while sensitizingthe generated review text to sentiment features based on user anditem of interest. Moreover, when review photos are available, visualfeatures could inform the review text generation further. Comprehensiveexperiments on real-life datasets from several major UScities show that the proposed model outperforms comparable multimodalbaselines, while an ablation analysis establishes the relativecontributions of the respective components of the joint model.</p><h2><span id="contribution">contribution</span></h2><p>We design the MRG model (see Section 3), whichjointly models rating prediction and text generation at the reviewlevel by incorporating LSTM cells with a novel fusion gate as akind of soft attention to weigh the relative contributions of sentimentfeatures and visual features that provide context to the textgeneration. We also describe the learning and inference algorithmsrespectively.</p><h2><span id="framework">framework</span></h2><p><img src="/www2019/21.JPG" alt></p><h1><span id="16personalized-bundle-list-recommendation">16.Personalized Bundle List Recommendation</span></h1><h2><span id="abstract">Abstract</span></h2><p>Product bundling, offering a combination of items to customers,is one of the marketing strategies commonly used in online ecommerceand offline retailers. A high-quality bundle generalizesfrequent items of interest, and diversity across bundles boosts theuser-experience and eventually increases transaction volume.</p><p>Inthis paper, we formalize the personalized bundle list recommendationas a structured prediction problem and propose a bundlegeneration network (BGN), which decomposes the problem intoquality/diversity parts by the determinantal point processes (DPPs).BGN uses a typical encoder-decoder framework with a proposedfeature-aware softmax to alleviate the inadequate representationof traditional softmax, and integrates the masked beam search andDPP selection to produce high-quality and diversified bundle listwith an appropriate bundle size.<img src="/www2019/22.JPG" alt></p>]]></content>
      
      
      <categories>
          
          <category> recommender systems </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>tensorflow学习率衰减</title>
      <link href="/tensorflow%E5%AD%A6%E4%B9%A0%E7%8E%87%E8%A1%B0%E5%87%8F/"/>
      <url>/tensorflow%E5%AD%A6%E4%B9%A0%E7%8E%87%E8%A1%B0%E5%87%8F/</url>
      
        <content type="html"><![CDATA[<p>在神经网络的训练过程中，学习率(learning rate)控制着参数的更新速度，tf.train类下面的五种不同的学习速率的衰减方法。</p><ul><li>tf.train.exponential_decay</li><li>tf.train.inverse_time_decay</li><li>tf.train.natural_exp_decay</li><li>tf.train.piecewise_constant</li><li>tf.train.polynomial_decay</li></ul><ol><li>首先使用较大学习率(目的：为快速得到一个比较优的解);</li><li>然后通过迭代逐步减小学习率(目的：为使模型在训练后期更加稳定);</li></ol><p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">tf.train.exponential_decay(</span><br><span class="line">    learning_rate,初始学习率</span><br><span class="line">    global_step,当前迭代次数</span><br><span class="line">    decay_steps,衰减速度（在迭代到该次数时学习率衰减为earning_rate * decay_rate）</span><br><span class="line">    decay_rate,学习率衰减系数，通常介于<span class="number">0</span><span class="number">-1</span>之间。</span><br><span class="line">    staircase=False,(默认值为False,当为True时，（global_step/decay_steps）则被转化为整数) ,选择不同的衰减方式。</span><br><span class="line">    name=None</span><br><span class="line">)</span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      
        <tags>
            
            <tag> tensorflow </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>西瓜书day24</title>
      <link href="/%E8%A5%BF%E7%93%9C%E4%B9%A6day24/"/>
      <url>/%E8%A5%BF%E7%93%9C%E4%B9%A6day24/</url>
      
        <content type="html"><![CDATA[<h1><span id="主成分分析pca">主成分分析（PCA）</span></h1><p>PCA是一种最常用的降维方法</p><ul><li>最近重构性：样本点到这个超平面的距离都足够近</li><li>最大可分性：样本点在这个超平面上的投影能尽可能分开</li></ul><h4><span id="最近重构性">最近重构性</span></h4><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day24/1.JPG" alt></p><h4><span id="最大可分性">最大可分性</span></h4><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day24/2.JPG" alt></p><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day24/3.JPG" alt></p><p>应用拉格朗日乘子法</p><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day24/4.JPG" alt></p><h4><span id="结果">结果</span></h4><p>降维导致 d-d'个特征值的特征向量被舍弃了，舍弃这部分信息能使样本的采样密度增大，另外，当数据受到噪声影响时，最小的特征值所对应的特征向量往往与噪声有关，将他们舍弃能在一定程度上起到去噪的作用。</p>]]></content>
      
      
      <categories>
          
          <category> ML </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 西瓜书 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>西瓜书day21</title>
      <link href="/%E8%A5%BF%E7%93%9C%E4%B9%A6day21/"/>
      <url>/%E8%A5%BF%E7%93%9C%E4%B9%A6day21/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>tf.multinomial</title>
      <link href="/tf-multinomial/"/>
      <url>/tf-multinomial/</url>
      
        <content type="html"><![CDATA[<p>明明按概率，亲测却非常随机</p><p>tf.multinomial(logits, num_samples, seed=None, name=None)</p><p>从multinomial分布中采样，样本个数是num_samples，每个样本被采样的概率由logits给出</p><h4><span id="parametrs">parametrs:</span></h4><ul><li><p>logits: 2-D Tensor with shape [batch_size, num_classes]. Each slice [i, :] represents the unnormalized log probabilities for all classes.2维量，shape是 [batch_size, num_classes]，每一行都是关于种类的未归一化的对数概率</p></li><li><p>num_samples: 0-D. Number of independent samples to draw for each row slice.标量，表示采样的个数，更重要的是，它限制了返回张量中元素的范围{：0，1，2，…，num_samples-1 }</p></li></ul><p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">samples = tf.multinomial(tf.log([[<span class="number">10.</span>, <span class="number">10.</span>, <span class="number">10.</span>]]), <span class="number">5</span>)</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">sess.run(samples)</span><br><span class="line"></span><br><span class="line"># 运行结果：array([[2, 1, 2, 2, 0]])</span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      <categories>
          
          <category> deep learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tensorflow </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>tensorflow实现梯度下降各种方法</title>
      <link href="/tensorflow%E5%AE%9E%E7%8E%B0%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E5%90%84%E7%A7%8D%E6%96%B9%E6%B3%95/"/>
      <url>/tensorflow%E5%AE%9E%E7%8E%B0%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E5%90%84%E7%A7%8D%E6%96%B9%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h1><span id="不使用tensorflow任何梯度下降方法">不使用tensorflow任何梯度下降方法</span></h1><p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"># -*- coding: utf8 -*-</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"># Import MNIST data</span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">"./MNIST_data"</span>, one_hot=True)</span><br><span class="line"></span><br><span class="line"># Parameters</span><br><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line">training_epochs = <span class="number">10</span></span><br><span class="line">batch_size = <span class="number">100</span></span><br><span class="line">display_step = <span class="number">1</span></span><br><span class="line"></span><br><span class="line"># Parameters</span><br><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line">training_epochs = <span class="number">10</span></span><br><span class="line">batch_size = <span class="number">100</span></span><br><span class="line">display_step = <span class="number">1</span></span><br><span class="line"></span><br><span class="line"># tf Graph Input</span><br><span class="line">x = tf.placeholder(tf.float32, [None, 784]) # mnist data image of shape 28*28=784</span><br><span class="line">y = tf.placeholder(tf.float32, [None, 10]) # 0-9 digits recognition =&gt; 10 classes</span><br><span class="line"></span><br><span class="line"># Set model weights</span><br><span class="line">W = tf.Variable(tf.zeros([<span class="number">784</span>, <span class="number">10</span>]))</span><br><span class="line">b = tf.Variable(tf.zeros([<span class="number">10</span>]))</span><br><span class="line"></span><br><span class="line"># Construct model</span><br><span class="line">pred = tf.nn.softmax(tf.matmul(x, W)+b) # Softmax</span><br><span class="line"></span><br><span class="line"># Minimize error using cross entropy</span><br><span class="line">cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred), reduction_indices=<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">W_grad =  - tf.matmul ( tf.transpose(x) , y - pred)</span><br><span class="line">b_grad = - tf.reduce_mean( tf.matmul(tf.transpose(x), y - pred), reduction_indices=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">new_W = W.assign(W - learning_rate * W_grad)</span><br><span class="line">new_b = b.assign(b - learning_rate * b_grad)</span><br><span class="line"></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line"></span><br><span class="line">    # Training cycle</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(training_epochs):</span><br><span class="line">        avg_cost = <span class="number">0.</span></span><br><span class="line">        total_batch = int(mnist.train.num_examples / batch_size)</span><br><span class="line">        # Loop over all batches</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(total_batch):</span><br><span class="line">            batch_xs, batch_ys = mnist.train.next_batch(batch_size)</span><br><span class="line">            # Fit training using batch data</span><br><span class="line">            _, _, c = sess.run([new_W, new_b, cost], feed_dict=&#123;<span class="attr">x</span>: batch_xs, <span class="attr">y</span>: batch_ys&#125;)</span><br><span class="line"></span><br><span class="line">            # Compute average loss</span><br><span class="line">            avg_cost += c / total_batch</span><br><span class="line">        # Display logs per epoch step</span><br><span class="line">        <span class="keyword">if</span> (epoch + <span class="number">1</span>) % display_step == <span class="number">0</span>:</span><br><span class="line">            print(<span class="string">"Epoch:"</span>, <span class="string">'%04d'</span> % (epoch + <span class="number">1</span>), <span class="string">"cost="</span>, <span class="string">"&#123;:.9f&#125;"</span>.format(avg_cost))</span><br><span class="line"></span><br><span class="line">    # test</span><br><span class="line">    acc=tf.reduce_mean(tf.cast(tf.equal(tf.argmax(pred,<span class="number">1</span>),tf.argmax(y,<span class="number">1</span>)),tf.float32))</span><br><span class="line">    print(<span class="string">'test acc'</span>,acc.eval(&#123;<span class="attr">x</span>: mnist.test.images, <span class="attr">y</span>: mnist.test.labels&#125;))</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"Optimization Finished!"</span>)</span><br></pre></td></tr></table></figure></p><h1><span id="使用tfgradients实现梯度下降">使用tf.gradients实现梯度下降</span></h1><p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 使用随机梯度下降</span><br><span class="line">vars=tf.trainable_variables()</span><br><span class="line">vars_grad=tf.gradients(loss_op,vars)</span><br><span class="line">vars_new=[]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(vars)):</span><br><span class="line">    vars_new.append(vars[i].assign(vars[i]-learning_rate*vars_grad[i])) # 权重更新</span><br><span class="line">sess.run(vars_new, feed_dict=&#123;<span class="attr">X</span>: batch_x, <span class="attr">Y</span>: batch_y, <span class="attr">keep_prob</span>: <span class="number">0.8</span>&#125;)</span><br></pre></td></tr></table></figure></p><p>minist:<figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">"./MNIST_data"</span>, one_hot=True)</span><br><span class="line"># Parameters</span><br><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line">training_epochs = <span class="number">10</span></span><br><span class="line">batch_size = <span class="number">100</span></span><br><span class="line">display_step = <span class="number">1</span></span><br><span class="line"></span><br><span class="line"># Parameters</span><br><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line">training_epochs = <span class="number">10</span></span><br><span class="line">batch_size = <span class="number">100</span></span><br><span class="line">display_step = <span class="number">1</span></span><br><span class="line"></span><br><span class="line"># tf Graph Input</span><br><span class="line">x = tf.placeholder(tf.float32, [None, 784]) # mnist data image of shape 28*28=784</span><br><span class="line">y = tf.placeholder(tf.float32, [None, 10]) # 0-9 digits recognition =&gt; 10 classes</span><br><span class="line"></span><br><span class="line"># Set model weights</span><br><span class="line">W = tf.Variable(tf.zeros([<span class="number">784</span>, <span class="number">10</span>]))</span><br><span class="line">b = tf.Variable(tf.zeros([<span class="number">10</span>]))</span><br><span class="line"></span><br><span class="line"># Construct model</span><br><span class="line">pred = tf.nn.softmax(tf.matmul(x, W)+b) # Softmax</span><br><span class="line"></span><br><span class="line"># Minimize error using cross entropy</span><br><span class="line">cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred), reduction_indices=<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"># W_grad =  - tf.matmul ( tf.transpose(x) , y - pred)</span><br><span class="line"># b_grad = - tf.reduce_mean( tf.matmul(tf.transpose(x), y - pred), reduction_indices=0)</span><br><span class="line">W_grad, b_grad=tf.gradients(cost,[W,b])</span><br><span class="line"></span><br><span class="line">new_W = W.assign(W - learning_rate * W_grad)</span><br><span class="line">new_b = b.assign(b - learning_rate * b_grad)</span><br><span class="line"></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line"></span><br><span class="line">    # Training cycle</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(training_epochs):</span><br><span class="line">        avg_cost = <span class="number">0.</span></span><br><span class="line">        total_batch = int(mnist.train.num_examples / batch_size)</span><br><span class="line">        # Loop over all batches</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(total_batch):</span><br><span class="line">            batch_xs, batch_ys = mnist.train.next_batch(batch_size)</span><br><span class="line">            # Fit training using batch data</span><br><span class="line">            _, _, c = sess.run([new_W, new_b, cost], feed_dict=&#123;<span class="attr">x</span>: batch_xs, <span class="attr">y</span>: batch_ys&#125;)</span><br><span class="line"></span><br><span class="line">            # Compute average loss</span><br><span class="line">            avg_cost += c / total_batch</span><br><span class="line">        # Display logs per epoch step</span><br><span class="line">        <span class="keyword">if</span> (epoch + <span class="number">1</span>) % display_step == <span class="number">0</span>:</span><br><span class="line">            print(<span class="string">"Epoch:"</span>, <span class="string">'%04d'</span> % (epoch + <span class="number">1</span>), <span class="string">"cost="</span>, <span class="string">"&#123;:.9f&#125;"</span>.format(avg_cost))</span><br><span class="line"></span><br><span class="line">    # test</span><br><span class="line">    acc=tf.reduce_mean(tf.cast(tf.equal(tf.argmax(pred,<span class="number">1</span>),tf.argmax(y,<span class="number">1</span>)),tf.float32))</span><br><span class="line">    print(<span class="string">'test acc'</span>,acc.eval(&#123;<span class="attr">x</span>: mnist.test.images, <span class="attr">y</span>: mnist.test.labels&#125;))</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"Optimization Finished!"</span>)</span><br></pre></td></tr></table></figure></p><h1><span id="使用tensorflow内置优化器">使用tensorflow内置优化器</span></h1><h4><span id="minimize">minimize</span></h4><p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">"./MNIST_data"</span>, one_hot=True)</span><br><span class="line"></span><br><span class="line"># Parameters</span><br><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line">training_epochs = <span class="number">10</span></span><br><span class="line">batch_size = <span class="number">100</span></span><br><span class="line">display_step = <span class="number">1</span></span><br><span class="line"></span><br><span class="line"># Parameters</span><br><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line">training_epochs = <span class="number">10</span></span><br><span class="line">batch_size = <span class="number">100</span></span><br><span class="line">display_step = <span class="number">1</span></span><br><span class="line"></span><br><span class="line"># tf Graph Input</span><br><span class="line">x = tf.placeholder(tf.float32, [None, 784]) # mnist data image of shape 28*28=784</span><br><span class="line">y = tf.placeholder(tf.float32, [None, 10]) # 0-9 digits recognition =&gt; 10 classes</span><br><span class="line"></span><br><span class="line"># Set model weights</span><br><span class="line">W = tf.Variable(tf.zeros([<span class="number">784</span>, <span class="number">10</span>]))</span><br><span class="line">b = tf.Variable(tf.zeros([<span class="number">10</span>]))</span><br><span class="line"></span><br><span class="line"># Construct model</span><br><span class="line">pred = tf.nn.softmax(tf.matmul(x, W)+b) # Softmax</span><br><span class="line"></span><br><span class="line"># Minimize error using cross entropy</span><br><span class="line">cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred), reduction_indices=<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"># W_grad =  - tf.matmul ( tf.transpose(x) , y - pred)</span><br><span class="line"># b_grad = - tf.reduce_mean( tf.matmul(tf.transpose(x), y - pred), reduction_indices=0)</span><br><span class="line"># W_grad, b_grad=tf.gradients(cost,[W,b])</span><br><span class="line">#</span><br><span class="line"># new_W = W.assign(W - learning_rate * W_grad)</span><br><span class="line"># new_b = b.assign(b - learning_rate * b_grad)</span><br><span class="line">train_op=tf.train.AdamOptimizer().minimize(cost)</span><br><span class="line"></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line"></span><br><span class="line">    # Training cycle</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(training_epochs):</span><br><span class="line">        avg_cost = <span class="number">0.</span></span><br><span class="line">        total_batch = int(mnist.train.num_examples / batch_size)</span><br><span class="line">        # Loop over all batches</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(total_batch):</span><br><span class="line">            batch_xs, batch_ys = mnist.train.next_batch(batch_size)</span><br><span class="line">            # Fit training using batch data</span><br><span class="line">            # _, _, c = sess.run([new_W, new_b, cost], feed_dict=&#123;x: batch_xs, y: batch_ys&#125;)</span><br><span class="line"></span><br><span class="line">            _,c=sess.run([train_op,cost],feed_dict=&#123;<span class="attr">x</span>: batch_xs, <span class="attr">y</span>: batch_ys&#125;)</span><br><span class="line"></span><br><span class="line">            # Compute average loss</span><br><span class="line">            avg_cost += c / total_batch</span><br><span class="line">        # Display logs per epoch step</span><br><span class="line">        <span class="keyword">if</span> (epoch + <span class="number">1</span>) % display_step == <span class="number">0</span>:</span><br><span class="line">            print(<span class="string">"Epoch:"</span>, <span class="string">'%04d'</span> % (epoch + <span class="number">1</span>), <span class="string">"cost="</span>, <span class="string">"&#123;:.9f&#125;"</span>.format(avg_cost))</span><br><span class="line"></span><br><span class="line">    # test</span><br><span class="line">    acc=tf.reduce_mean(tf.cast(tf.equal(tf.argmax(pred,<span class="number">1</span>),tf.argmax(y,<span class="number">1</span>)),tf.float32))</span><br><span class="line">    print(<span class="string">'test acc'</span>,acc.eval(&#123;<span class="attr">x</span>: mnist.test.images, <span class="attr">y</span>: mnist.test.labels&#125;))</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"Optimization Finished!"</span>)</span><br></pre></td></tr></table></figure></p><h4><span id="compute_gradients与apply_gradients">compute_gradients与apply_gradients</span></h4><p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">"./MNIST_data"</span>, one_hot=True)</span><br><span class="line"></span><br><span class="line"># Parameters</span><br><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line">training_epochs = <span class="number">10</span></span><br><span class="line">batch_size = <span class="number">100</span></span><br><span class="line">display_step = <span class="number">1</span></span><br><span class="line"></span><br><span class="line"># Parameters</span><br><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line">training_epochs = <span class="number">10</span></span><br><span class="line">batch_size = <span class="number">100</span></span><br><span class="line">display_step = <span class="number">1</span></span><br><span class="line"></span><br><span class="line"># tf Graph Input</span><br><span class="line">x = tf.placeholder(tf.float32, [None, 784]) # mnist data image of shape 28*28=784</span><br><span class="line">y = tf.placeholder(tf.float32, [None, 10]) # 0-9 digits recognition =&gt; 10 classes</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">'D'</span>):</span><br><span class="line">    # Set model weights</span><br><span class="line">    W = tf.Variable(tf.zeros([<span class="number">784</span>, <span class="number">10</span>]))</span><br><span class="line">    b = tf.Variable(tf.zeros([<span class="number">10</span>]))</span><br><span class="line"></span><br><span class="line">    # Construct model</span><br><span class="line">    pred = tf.nn.softmax(tf.matmul(x, W)+b) # Softmax</span><br><span class="line"></span><br><span class="line"># Minimize error using cross entropy</span><br><span class="line">cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred), reduction_indices=<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"># W_grad =  - tf.matmul ( tf.transpose(x) , y - pred)</span><br><span class="line"># b_grad = - tf.reduce_mean( tf.matmul(tf.transpose(x), y - pred), reduction_indices=0)</span><br><span class="line"># W_grad, b_grad=tf.gradients(cost,[W,b])</span><br><span class="line">#</span><br><span class="line"># new_W = W.assign(W - learning_rate * W_grad)</span><br><span class="line"># new_b = b.assign(b - learning_rate * b_grad)</span><br><span class="line"># train_op=tf.train.AdamOptimizer().minimize(cost)</span><br><span class="line"># optimizer=tf.train.AdamOptimizer()</span><br><span class="line"># gradients=optimizer.compute_gradients(cost)</span><br><span class="line"># clipped_gradients = [(tf.clip_by_value(_[0], -1, 1), _[1]) for _ in gradients] # _[0] 对应dw ,_[1]对应db</span><br><span class="line"># train_op = optimizer.apply_gradients(clipped_gradients)</span><br><span class="line"># 或</span><br><span class="line"># train_op = optimizer.apply_gradients(gradients)</span><br><span class="line"></span><br><span class="line">tvars = tf.trainable_variables()</span><br><span class="line">d_params = [v <span class="keyword">for</span> v <span class="keyword">in</span> tvars <span class="keyword">if</span> v.name.startswith(<span class="string">'D/'</span>)]</span><br><span class="line">trainerD = tf.train.AdamOptimizer(learning_rate=<span class="number">0.0002</span>, beta1=<span class="number">0.5</span>)</span><br><span class="line">d_grads = trainerD.compute_gradients(cost, d_params)#Only update the weights for the discriminator network.</span><br><span class="line">train_op = trainerD.apply_gradients(d_grads)</span><br><span class="line"></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line"></span><br><span class="line">    # Training cycle</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(training_epochs):</span><br><span class="line">        avg_cost = <span class="number">0.</span></span><br><span class="line">        total_batch = int(mnist.train.num_examples / batch_size)</span><br><span class="line">        # Loop over all batches</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(total_batch):</span><br><span class="line">            batch_xs, batch_ys = mnist.train.next_batch(batch_size)</span><br><span class="line">            # Fit training using batch data</span><br><span class="line">            # _, _, c = sess.run([new_W, new_b, cost], feed_dict=&#123;x: batch_xs, y: batch_ys&#125;)</span><br><span class="line"></span><br><span class="line">            _,c=sess.run([train_op,cost],feed_dict=&#123;<span class="attr">x</span>: batch_xs, <span class="attr">y</span>: batch_ys&#125;)</span><br><span class="line"></span><br><span class="line">            # Compute average loss</span><br><span class="line">            avg_cost += c / total_batch</span><br><span class="line">        # Display logs per epoch step</span><br><span class="line">        <span class="keyword">if</span> (epoch + <span class="number">1</span>) % display_step == <span class="number">0</span>:</span><br><span class="line">            print(<span class="string">"Epoch:"</span>, <span class="string">'%04d'</span> % (epoch + <span class="number">1</span>), <span class="string">"cost="</span>, <span class="string">"&#123;:.9f&#125;"</span>.format(avg_cost))</span><br><span class="line"></span><br><span class="line">    # test</span><br><span class="line">    acc=tf.reduce_mean(tf.cast(tf.equal(tf.argmax(pred,<span class="number">1</span>),tf.argmax(y,<span class="number">1</span>)),tf.float32))</span><br><span class="line">    print(<span class="string">'test acc'</span>,acc.eval(&#123;<span class="attr">x</span>: mnist.test.images, <span class="attr">y</span>: mnist.test.labels&#125;))</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"Optimization Finished!"</span>)</span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      <categories>
          
          <category> Deep learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tensorflow </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>tensorflow中的参数初始化方法</title>
      <link href="/tensorflow%E4%B8%AD%E7%9A%84%E5%8F%82%E6%95%B0%E5%88%9D%E5%A7%8B%E5%8C%96%E6%96%B9%E6%B3%95/"/>
      <url>/tensorflow%E4%B8%AD%E7%9A%84%E5%8F%82%E6%95%B0%E5%88%9D%E5%A7%8B%E5%8C%96%E6%96%B9%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h1><span id="常量初始化">常量初始化</span></h1><p>tf中使用tf.constant_initializer(value)类生成一个初始值为常量value的tensor对象。constant_initializer类的构造函数定义：<figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">def __init__(self, value=<span class="number">0</span>, dtype=dtypes.float32, verify_shape=False):</span><br><span class="line">    self.value = value</span><br><span class="line">    self.dtype = dtypes.as_dtype(dtype)</span><br><span class="line">    self._verify_shape = verify_shape</span><br></pre></td></tr></table></figure></p><ul><li>value：指定的常量</li><li>dtype： 数据类型</li><li>verify_shape： 是否可以调整tensor的形状，默认可以调整</li></ul><p>example:<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">value = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>]</span><br><span class="line">init = tf.constant_initializer(value)</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">  x = tf.get_variable(<span class="string">'x'</span>, shape=[<span class="number">8</span>], initializer=init)</span><br><span class="line">  x.initializer.run()</span><br><span class="line">  print(x.eval())</span><br><span class="line">#output:</span><br><span class="line">#[ 0.  1.  2.  3.  4.  5.  6.  7.]</span><br></pre></td></tr></table></figure></p><p>神经网络中经常使用常量初始化方法来初始化偏置值</p><p>当初始化一个维数很多的常量时，一个一个指定每个维数上的值很不方便，tf提供了 tf.zeros_initializer() 和 tf.ones_initializer() 类，分别用来初始化全0和全1的tensor对象。</p><p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">init_zeros=tf.zeros_initializer()</span><br><span class="line">init_ones = tf.ones_initializer</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">  x = tf.get_variable(<span class="string">'x'</span>, shape=[<span class="number">8</span>], initializer=init_zeros)</span><br><span class="line">  y = tf.get_variable(<span class="string">'y'</span>, shape=[<span class="number">8</span>], initializer=init_ones)</span><br><span class="line">  x.initializer.run()</span><br><span class="line">  y.initializer.run()</span><br><span class="line">  print(x.eval())</span><br><span class="line">  print(y.eval())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#output:</span><br><span class="line"># [ 0.  0.  0.  0.  0.  0.  0.  0.]</span><br><span class="line"># [ 1.  1.  1.  1.  1.  1.  1.  1.]</span><br></pre></td></tr></table></figure></p><h1><span id="初始化为正态分布">初始化为正态分布</span></h1><p>初始化参数为正太分布在神经网络中应用的最多，可以初始化为标准正太分布和截断正太分布。</p><p>tf中使用 tf.random_normal_initializer() 类来生成一组符合标准正太分布的tensor。</p><p>tf中使用 tf.truncated_normal_initializer() 类来生成一组符合截断正太分布的tensor。</p><p>tf.random_normal_initializer 类和 tf.truncated_normal_initializer 的构造函数定义：</p><p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">def __init__(self, mean=<span class="number">0.0</span>, stddev=<span class="number">1.0</span>, seed=None, dtype=dtypes.float32):</span><br><span class="line">    self.mean = mean</span><br><span class="line">    self.stddev = stddev</span><br><span class="line">    self.seed = seed</span><br><span class="line">    self.dtype = _assert_float_dtype(dtypes.as_dtype(dtype))</span><br></pre></td></tr></table></figure></p><ul><li>mean： 正太分布的均值，默认值0</li><li>stddev： 正太分布的标准差，默认值1</li><li>seed： 随机数种子，指定seed的值可以每次都生成同样的数据</li><li>dtype： 数据类型</li></ul><p>example:<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">init_random = tf.random_normal_initializer(mean=<span class="number">0.0</span>, stddev=<span class="number">1.0</span>, seed=None, dtype=tf.float32)</span><br><span class="line">init_truncated = tf.truncated_normal_initializer(mean=<span class="number">0.0</span>, stddev=<span class="number">1.0</span>, seed=None, dtype=tf.float32)</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">  x = tf.get_variable(<span class="string">'x'</span>, shape=[<span class="number">10</span>], initializer=init_random)</span><br><span class="line">  y = tf.get_variable(<span class="string">'y'</span>, shape=[<span class="number">10</span>], initializer=init_truncated)</span><br><span class="line">  x.initializer.run()</span><br><span class="line">  y.initializer.run()</span><br><span class="line">  print(x.eval())</span><br><span class="line">  print(y.eval())</span><br><span class="line"></span><br><span class="line">#output:</span><br><span class="line"># [-0.40236568 -0.35864913 -0.94253045 -0.40153521  0.1552504   1.16989613</span><br><span class="line">#   0.43091929 -0.31410623  0.70080078 -0.9620409 ]</span><br><span class="line"># [ 0.18356581 -0.06860946 -0.55245203  1.08850253 -1.13627422 -0.1006074</span><br><span class="line">#   0.65564936  0.03948414  0.86558545 -0.4964745 ]</span><br></pre></td></tr></table></figure></p><h1><span id="初始化为均匀分布">初始化为均匀分布</span></h1><p>tf中使用 tf.random_uniform_initializer 类来生成一组符合均匀分布的tensor。</p><p>tf.random_uniform_initializer类构造函数定义：<figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">def __init__(self, minval=<span class="number">0</span>, maxval=None, seed=None, dtype=dtypes.float32):</span><br><span class="line">    self.minval = minval</span><br><span class="line">    self.maxval = maxval</span><br><span class="line">    self.seed = seed</span><br><span class="line">    self.dtype = dtypes.as_dtype(dtype)</span><br></pre></td></tr></table></figure></p><ul><li>minval: 最小值</li><li>maxval： 最大值</li><li>seed：随机数种子</li><li>dtype： 数据类型</li></ul><p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">init_uniform = tf.random_uniform_initializer(minval=<span class="number">0</span>, maxval=<span class="number">10</span>, seed=None, dtype=tf.float32)</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">  x = tf.get_variable(<span class="string">'x'</span>, shape=[<span class="number">10</span>], initializer=init_uniform)</span><br><span class="line">  x.initializer.run()</span><br><span class="line">  print(x.eval())</span><br><span class="line"></span><br><span class="line"># output:</span><br><span class="line"># [ 6.93343639  9.41196823  5.54009819  1.38017178  1.78720832  5.38881063</span><br><span class="line">#   3.39674473  8.12443542  0.62157512  8.36026382]</span><br></pre></td></tr></table></figure></p><p>从输出可以看到，均匀分布生成的随机数并不是从小到大或者从大到小均匀分布的，这里均匀分布的意义是每次从一组服从均匀分布的数里边随机抽取一个数。</p><p>tf中另一个生成均匀分布的类是 tf.uniform_unit_scaling_initializer()，构造函数是：</p><p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">def __init__(self, factor=<span class="number">1.0</span>, seed=None, dtype=dtypes.float32):</span><br><span class="line">    self.factor = factor</span><br><span class="line">    self.seed = seed</span><br><span class="line">    self.dtype = _assert_float_dtype(dtypes.as_dtype(dtype))</span><br></pre></td></tr></table></figure></p><p>同样都是生成均匀分布，tf.uniform_unit_scaling_initializer 跟 tf.random_uniform_initializer 不同的地方是前者不需要指定最大最小值，是通过公式计算出来的：</p><p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">max_val = math.sqrt(<span class="number">3</span> / input_size) * factor</span><br><span class="line">min_val = -max_val</span><br></pre></td></tr></table></figure></p><p>input_size是生成数据的维度，factor是系数。<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">init_uniform_unit = tf.uniform_unit_scaling_initializer(factor=<span class="number">1.0</span>, seed=None, dtype=tf.float32)</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">  x = tf.get_variable(<span class="string">'x'</span>, shape=[<span class="number">10</span>], initializer=init_uniform_unit)</span><br><span class="line">  x.initializer.run()</span><br><span class="line">  print(x.eval())</span><br><span class="line"></span><br><span class="line"># output:</span><br><span class="line"># [-1.65964031  0.59797513 -0.97036457 -0.68957627  1.69274557  1.2614969</span><br><span class="line">#   1.55491126  0.12639415  0.54466736 -1.56159735]</span><br></pre></td></tr></table></figure></p><h1><span id="初始化为变尺度正太-均匀分布">初始化为变尺度正太、均匀分布</span></h1><p>tf中tf.variance_scaling_initializer()类可以生成截断正太分布和均匀分布的tensor，增加了更多的控制参数。构造函数：</p><p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">def __init__(self, scale=<span class="number">1.0</span>,</span><br><span class="line">               mode=<span class="string">"fan_in"</span>,</span><br><span class="line">               distribution=<span class="string">"normal"</span>,</span><br><span class="line">               seed=None,</span><br><span class="line">               dtype=dtypes.float32):</span><br><span class="line">    <span class="keyword">if</span> scale &lt;= <span class="number">0.</span>:</span><br><span class="line">      raise ValueError(<span class="string">"`scale` must be positive float."</span>)</span><br><span class="line">    <span class="keyword">if</span> mode not <span class="keyword">in</span> &#123;<span class="string">"fan_in"</span>, <span class="string">"fan_out"</span>, <span class="string">"fan_avg"</span>&#125;:</span><br><span class="line">      raise ValueError(<span class="string">"Invalid `mode` argument:"</span>, mode)</span><br><span class="line">    distribution = distribution.lower()</span><br><span class="line">    <span class="keyword">if</span> distribution not <span class="keyword">in</span> &#123;<span class="string">"normal"</span>, <span class="string">"uniform"</span>&#125;:</span><br><span class="line">      raise ValueError(<span class="string">"Invalid `distribution` argument:"</span>, distribution)</span><br><span class="line">    self.scale = scale</span><br><span class="line">    self.mode = mode</span><br><span class="line">    self.distribution = distribution</span><br><span class="line">    self.seed = seed</span><br><span class="line">    self.dtype = _assert_float_dtype(dtypes.as_dtype(dtype))</span><br></pre></td></tr></table></figure></p><ul><li>scale: 缩放尺度</li><li>mode： 有3个值可选，分别是 “fan_in”, “fan_out” 和 “fan_avg”，用于控制计算标准差 stddev的值</li><li>distribution： 2个值可选，”normal”或“uniform”，定义生成的tensor的分布是截断正太分布还是均匀分布</li></ul><p>distribution选‘normal’的时候，生成的是截断正太分布，标准差 stddev = sqrt(scale / n), n的取值根据mode的不同设置而不同：</p><ul><li>mode = &quot;fan_in&quot;， n为输入单元的结点数；</li><li>mode = &quot;fan_out&quot;，n为输出单元的结点数；</li><li>mode = &quot;fan_avg&quot;,n为输入和输出单元结点数的平均值;</li></ul><p>distribution选 ‘uniform’，生成均匀分布的随机数tensor，最大值 max_value和 最小值 min_value 的计算公式：</p><p>max_value = sqrt(3 * scale / n)</p><p>min_value = -max_value</p><p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">init_variance_scaling_normal = tf.variance_scaling_initializer(scale=<span class="number">1.0</span>,mode=<span class="string">"fan_in"</span>,</span><br><span class="line">                                                        distribution=<span class="string">"normal"</span>,seed=None,dtype=tf.float32)</span><br><span class="line">init_variance_scaling_uniform = tf.variance_scaling_initializer(scale=<span class="number">1.0</span>,mode=<span class="string">"fan_in"</span>,</span><br><span class="line">                                                        distribution=<span class="string">"uniform"</span>,seed=None,dtype=tf.float32)</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">  x = tf.get_variable(<span class="string">'x'</span>, shape=[<span class="number">10</span>], initializer=init_variance_scaling_normal)</span><br><span class="line">  y = tf.get_variable(<span class="string">'y'</span>, shape=[<span class="number">10</span>], initializer=init_variance_scaling_uniform)</span><br><span class="line">  x.initializer.run()</span><br><span class="line">  y.initializer.run()</span><br><span class="line">  print(x.eval())</span><br><span class="line">  print(y.eval())</span><br><span class="line"></span><br><span class="line"># output:</span><br><span class="line"># [ 0.55602223  0.36556259  0.39404872 -0.11241052  0.42891756 -0.22287074</span><br><span class="line">#   0.15629818  0.56271428 -0.15364751 -0.03651841]</span><br><span class="line"># [ 0.22965753 -0.1339919  -0.21013224  0.112804   -0.49030468  0.21375734</span><br><span class="line">#   0.24524075 -0.48397955  0.02254289 -0.07996771]</span><br></pre></td></tr></table></figure></p><h1><span id="其他初始化方式">其他初始化方式</span></h1><ul><li>tf.orthogonal_initializer() 初始化为正交矩阵的随机数，形状最少需要是二维的</li><li>tf.glorot_uniform_initializer() 初始化为与输入输出节点数相关的均匀分布随机数</li><li>tf.glorot_normal_initializer（） 初始化为与输入输出节点数相关的截断正太分布随机数</li></ul><p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">init_orthogonal = tf.orthogonal_initializer(gain=<span class="number">1.0</span>, seed=None, dtype=tf.float32)</span><br><span class="line">init_glorot_uniform = tf.glorot_uniform_initializer()</span><br><span class="line">init_glorot_normal = tf.glorot_normal_initializer()</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">  x = tf.get_variable(<span class="string">'x'</span>, shape=[<span class="number">4</span>,<span class="number">4</span>], initializer=init_orthogonal)</span><br><span class="line">  y = tf.get_variable(<span class="string">'y'</span>, shape=[<span class="number">10</span>], initializer=init_glorot_uniform)</span><br><span class="line">  z = tf.get_variable(<span class="string">'z'</span>, shape=[<span class="number">10</span>], initializer=init_glorot_normal)</span><br><span class="line">  x.initializer.run()</span><br><span class="line">  y.initializer.run()</span><br><span class="line">  z.initializer.run()</span><br><span class="line">  print(x.eval())</span><br><span class="line">  print(y.eval())</span><br><span class="line">  print(z.eval())</span><br><span class="line"></span><br><span class="line"># output:</span><br><span class="line"># [[ 0.41819954  0.38149482  0.82090431  0.07541249]</span><br><span class="line">#  [ 0.41401231  0.21400851 -0.38360971  0.79726893]</span><br><span class="line">#  [ 0.73776144 -0.62585676 -0.06246936 -0.24517137]</span><br><span class="line">#  [ 0.33077344  0.64572859 -0.41839844 -0.54641217]]</span><br><span class="line"># [-0.11182356  0.01995623 -0.0083192  -0.09200105  0.49967837  0.17083591</span><br><span class="line">#   0.37086374  0.09727859  0.51015782 -0.43838671]</span><br><span class="line"># [-0.50223351  0.18181904  0.43594137  0.3390047   0.61405027  0.02597036</span><br><span class="line">#   0.31719241  0.04096413  0.10962497 -0.13165198]</span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      <categories>
          
          <category> deep learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tensorflow </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>神经网络训练问题排查</title>
      <link href="/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%AE%AD%E7%BB%83%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/"/>
      <url>/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%AE%AD%E7%BB%83%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/</url>
      
        <content type="html"><![CDATA[<h1><span id="数据标准化">数据标准化</span></h1><p>数据的分布情况如何？数据是否经过适当的缩放？总体上的规则是：</p><ul><li>如果数据是连续值：范围应当在-1到1、0到1，或者呈平均值为0、标准差为1的正态分布。实际的范围不用如此精确，但确保输入数据大致处于上述区间内会有助于训练。缩小过大的输入，放大过小的输入。</li><li>如果数据是离散的类别（以及对于分类问题的输出而言），则通常使用one-hot表示。也就是说，如果有三种类别，那么这三种不同类别的数据将分别以[1,0,0]、[0,1,0]、[0,0,1]的方式表示。</li></ul><p>请注意：训练数据和测试数据的标准化方法必须完全相同，这非常重要。</p><h1><span id="权重初始化">权重初始化</span></h1><p>您需要确保权重不会过大，也不会过小。Xavier权重初始化方法通常是比较好的选择。对于使用修正线性（relu）或带泄露的修正线性（leaky relu）激活函数的网络而言，RELU权重初始化方法比较合适。</p><h1><span id="epoch数量和迭代次数">Epoch数量和迭代次数</span></h1><p>一个epoch周期的定义是完整地遍历数据集一次。DL4J将迭代次数定义为每个微批次中的参数更新次数。</p><p>在训练中，一般应让训练持续多个epoch，而将迭代次数设为一次（.iterations(1)选项）；一般仅在对非常小的数据集进行完整批次的训练时才会采用大于1的迭代次数。</p><p>如果epoch数量太少，网络就没有足够的时间学会合适的参数；epoch数量太多则有可能导致网络对训练数据过拟合。选择epoch数量的方式之一是早停法。早停法还可以避免神经网络发生过拟合（即可以帮助网络更好地适应未曾见过的数据）。</p><h1><span id="学习速率">学习速率</span></h1><p>学习速率是最重要的超参数之一。如果学习速率过高或过低，网络可能学习效果非常差、学习速度非常慢，甚至完全没有进展。学习速率的取值范围一般在0.1到1e-6之间，最理想的速率通常取决于具体的数据（以及网络架构）。一种简单的建议是，一开始可以尝试三种不同的学习速率：1e-1、1e-3、1e-6，先大致了解一下应该设为怎样的值，然后再进一步微调。理想状态下，可以同时以不同的学习速率运行模型，以便节省时间。</p><p>选择合适的学习速率的常用方法是借助DL4J的可视化界面来将训练进程可视化。您需要关注损失随时间变化的情况以及更新值与参数的绝对值之比（通常可以先考虑1:1000左右的比例）。</p><h1><span id="策略与学习速率计划">策略与学习速率计划</span></h1><p>您可以选择为神经网络设定学习速率策略，让学习速率随着时间推移逐渐“放缓”，帮助网络收敛至更接近局部极小值的位置，进而取得更好的学习效果。一种常用的策略是学习速率计划（learning rate schedule）。</p><h1><span id="损失函数">损失函数</span></h1><p>神经网络不同层中的损失函数的作用包括预训练、学习改善权重，以及在分类问题中得出结果（位于输出层上）。（在上述例子中，分类发生在重写段中。）</p><p>网络目的决定了所用的损失函数类型。预训练可选择重构熵函数。分类可选择多类叉熵函数。</p>]]></content>
      
      
      <categories>
          
          <category> Deep learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习调参技巧</title>
      <link href="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%B0%83%E5%8F%82%E6%8A%80%E5%B7%A7/"/>
      <url>/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%B0%83%E5%8F%82%E6%8A%80%E5%B7%A7/</url>
      
        <content type="html"><![CDATA[<h1><span id="初始化">初始化</span></h1><p>一次惨痛的教训是用normal初始化cnn的参数，最后acc只能到70%多，仅仅改成xavier，acc可以到98%。还有一次给word embedding初始化，最开始使用了TensorFlow中默认的initializer（即glorot_uniform_initializer，也就是大家经常说的无脑使用xavier），训练速度慢不说，结果也不好。改为uniform，训练速度飙升，结果也飙升。所以，初始化就跟黑科技一样，用对了超参都不用调；没用对，跑出来的结果就跟模型有bug一样不忍直视。</p><p>记得刚开始研究深度学习时，做过两个小例子。一个是用tensorflow构建了一个十分简单的只有一个输入层和一个softmax输出层的Mnist手写识别网络，第一次我对权重矩阵W和偏置b采用的是正态分布初始化，一共迭代了20个epoch，当迭代完第一个epoch时，预测的准确度只有10%左右（和随机猜一样，Mnist是一个十分类问题），当迭代完二十个epoch，精度也仅仅达到了60%的样子。然后我仅仅是将权重矩阵W初始化方法改成了全为0的初始化，其他的参数均保持不变，结果在训练完第一个epoch后预测精度就达到了85%以上，最终20个epoch后精度达到92%。另一个例子是回归问题的预测，当时采用的SGD优化器，一开始学习率设定的0.1，模型可以正常训练，只是训练速度有些慢，我试着将学习率调整到0.3，希望可以加速训练速度，结果没迭代几轮loss就变成Nan了。于是从那时起我就深刻的感受到参数调节在深度学习模型训练中的重要意义。</p><p>其实上述问题产生的原因也很好理解，对于参数初始化，因为我们学习的本来就是权重W与偏置b，如果初始化足够好，直接就初始化到最优解，那都不用进行训练了。良好的初始化，可以让参数更接近最优解，这可以大大提高收敛速度，也可以防止落入局部极小。</p><h4><span id="tensorflow常用的初始化方法">tensorflow常用的初始化方法</span></h4><h1><span id="激活函数选择">激活函数选择：</span></h1><p>常用的激活函数有relu、leaky-relu、sigmoid、tanh等。对于输出层，多分类任务选用softmax输出，二分类任务选用sigmoid输出，回归任务选用线性输出。而对于中间隐层，则优先选择relu激活函数（relu激活函数可以有效的解决sigmoid和tanh出现的梯度弥散问题，多次实验表明它会比其他激活函数以更快的速度收敛）。另外，构建序列神经网络（RNN）时要优先选用tanh激活函数。</p><h1><span id="学习率设定">学习率设定：</span></h1><p>一般学习率从0.1或0.01开始尝试。学习率设置太大会导致训练十分不稳定，甚至出现Nan，设置太小会导致损失下降太慢。学习率一般要随着训练进行衰减。衰减系数设0.1，0.3，0.5均可，衰减时机，可以是验证集准确率不再上升时，或固定训练多少个周期以后自动进行衰减。</p><h1><span id="防止过拟合">防止过拟合：</span></h1><p>一般常用的防止过拟合方法有使用L1正则项、L2正则项、dropout、提前终止、数据集扩充等。如果模型在训练集上表现比较好但在测试集上表现欠佳可以选择增大L1或L2正则的惩罚力度（L2正则经验上首选1.0，超过10很少见），或增大dropout的随机失活概率（经验首选0.5）；或者当随着训练的持续在测试集上不增反降时，使用提前终止训练的方法。当然最有效的还是增大训练集的规模，实在难以获得新数据也可以使用数据集增强的方法，比如CV任务可以对数据集进行裁剪、翻转、平移等方法进行数据集增强，这种方法往往都会提高最后模型的测试精度。</p><h1><span id="优化器选择">优化器选择：</span></h1><p>如果数据是稀疏的，就用自适应方法，即 Adagrad, Adadelta, RMSprop, Adam。整体来讲，Adam 是最好的选择。SGD 虽然能达到极小值，但是比其它算法用的时间长，而且可能会被困在鞍点。如果需要更快的收敛，或者是训练更深更复杂的神经网络，需要用一种自适应的算法。</p><h1><span id="残差块与bn层">残差块与BN层</span></h1><p>如果你希望训练一个更深更复杂的网络，那么残差块绝对是一个重要的组件，它可以让你的网络训练的更深。</p><p>BN层具有加速训练速度，有效防止梯度消失与梯度爆炸，具有防止过拟合的效果，所以构建网络时最好要加上这个组件。</p><h1><span id="自动调参方法">自动调参方法：</span></h1><ul><li>Grid Search：网格搜索，在所有候选的参数选择中，通过循环遍历，尝试每一种可能性，表现最好的参数就是最终的结果。其原理就像是在数组里找最大值。缺点是太费时间了，特别像神经网络，一般尝试不了太多的参数组合。</li><li>Random Search：经验上，Random Search比Gird Search更有效。实际操作的时候，一般也是先用Gird Search的方法，得到所有候选参数，然后每次从中随机选择进行训练。另外Random Search往往会和由粗到细的调参策略结合使用，即在效果比较好的参数附近进行更加精细的搜索。</li><li>Bayesian Optimization：贝叶斯优化，考虑到了不同参数对应的 实验结果值，因此更节省时间，贝叶斯调参比Grid Search迭代次数少， 速度快；而且其针对非凸问题依然稳健。</li></ul><h1><span id="深度学习debug的流程策略">深度学习debug的流程策略</span></h1><p>既然消除模型中的错误很难，我们不如先从简单模型入手，然后逐渐增加模型的复杂度。</p><ul><li>从最简单模型入手；</li><li>成功搭建模型，重现结果；</li><li>分解偏差各项，逐步拟合数据；</li><li>用由粗到细随机搜索优化超参数；</li><li>如果欠拟合，就增大模型；如果过拟合，就添加数据或调整。</li></ul><p><img src="https://pcc.cs.byu.edu/2017/10/02/practical-advice-for-building-deep-neural-networks/" alt></p>]]></content>
      
      
      <categories>
          
          <category> Deep learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python-excel</title>
      <link href="/python-excel/"/>
      <url>/python-excel/</url>
      
        <content type="html"><![CDATA[<p>python存excel数据</p><pre><code class="language-js">import xlwtimport pdbworkbook=xlwt.Workbook(encoding='utf-8')booksheet=workbook.add_sheet('data', cell_overwrite_ok=True)DATA=(('学号','姓名','年龄','性别','成绩'),      ('1001','A','11','男','12'),      ('1002','B','12','女','22'),      ('1003','C','13','女','32'),      ('1004','D','14','男','52'),      )pdb.set_trace()for i,row in enumerate(DATA):    for j,col in enumerate(row):        booksheet.write(i,j,col)workbook.save('grade.xls')</code></pre>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python语法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>西瓜书day16，day17,day18,day19,day20(神经网络)</title>
      <link href="/%E8%A5%BF%E7%93%9C%E4%B9%A6day16/"/>
      <url>/%E8%A5%BF%E7%93%9C%E4%B9%A6day16/</url>
      
        <content type="html"><![CDATA[<h1><span id="神经元模型">神经元模型</span></h1><p>神经网络中最基本的成分是神经元模型。</p><h2><span id="m-p神经元模型">M-P神经元模型</span></h2><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day16/1.JPG" alt></p><h2><span id="激活函数">激活函数</span></h2><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day16/2.JPG" alt></p><h1><span id="感知机与多层网络">感知机与多层网络</span></h1><h2><span id="感知机">感知机</span></h2><p>感知机由两层神经元组成，如图，<img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day16/3.JPG" alt></p><p>感知机能够容易的实现逻辑与、或、非运算， $f(\sum_iw_ix_i-\theta)$, 假定f是阶跃函数，有</p><ul><li>与：令 $w_1=w_2=1,\theta=2$, 则 $y=f(1 \cdot x_1+1 \cdot x_2-2)$,仅在$x_1=x_2=1$ 时，y=1;</li><li>或：令 $w_1=w_2=1,\theta=0.5$, 则 $y=f(1 \cdot x_1+1 \cdot x_2-0.5)$,仅在$x_1=1 or x_2=1$ 时，y=1;</li><li>非：令令 $w_1=-06，w_2=0,\theta=-0.5$, 则 $y=f(-0.6 \cdot x_1+0 \cdot x_2+0.5)$,当$x_1=1$ 时，$y=0$,当 $x_1=0$ 时， $y=1$.</li></ul><p>给定训练数据集，权重与阈值可以通过学习得到。</p><p>感知机学习规则：对训练样例(x,y)，若当前感知机的输出为 $\hat{y}$, 则感知机权重将这样调整：</p><p>$w_i \leftarrow w_i +\Delta w_i$</p><p>$\Delta w_i=\eta(y-\hat{y})x_i$</p><p>其中 $\eta \in (0,1)$ 代表learning rate,.</p><h2><span id="感知机的局限性">感知机的局限性</span></h2><p>感知机只拥有一层功能神经元，学习能力非常有限，只能处理线性可分问题，不能解决抑或问题。<img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day16/4.JPG" alt>要解决非线性可分问题，需要考虑多层神经元，例如添加一个隐藏层的两层神经元可以解决“异或”问题。<img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day16/5.JPG" alt>神经网络的学习过程，就是根据训练数据来调整神经元之间的权重以及每个功能神经元的阈值。</p><h1><span id="误差逆传播算法bp">误差逆传播算法（BP）</span></h1><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day16/6.JPG" alt><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day16/7.JPG" alt><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day16/8.JPG" alt><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day16/9.JPG" alt></p><h1><span id="全局最小与局部最小">全局最小与局部最小</span></h1><p>神经网络的训练过程可以看作参数寻优过程，在参数空间中寻找一组最优参数使神经网络在训练集上的误差达到最小。</p><p>局部最优解：参数空间中的某个点，其邻域点的误差函数值均不小于该点的函数值</p><p>全局最小解：参数空间中所有点的误差函数值均不小于该点的函数值</p><p>基于梯度的搜索是使用最为广泛的参数寻优方法</p><h4><span id="局部最小跳出策略">局部最小跳出策略</span></h4><ul><li>以多组不同参数值初始化多个神经网络，取误差最小的参数</li><li>“模拟退火”：以一定概率接受比当前解更差的结果</li><li>随机梯度下降 在计算梯度时加入了随机因素，即使陷入局部极小，也有可能跳出。</li></ul><h1><span id="其他常见的神经网络">其他常见的神经网络</span></h1><h4><span id="rbf">RBF</span></h4><h4><span id="art">ART</span></h4><h4><span id="smo">SMO</span></h4><h4><span id="级联相关网络">级联相关网络</span></h4><h4><span id="elman网络">Elman网络</span></h4><h4><span id="boltzmann">Boltzmann</span></h4><h1><span id="神经网络">神经网络</span></h1>]]></content>
      
      
      <categories>
          
          <category> ML </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 西瓜书 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>西瓜书day13,day14,day15（贝叶斯分类器）</title>
      <link href="/%E8%A5%BF%E7%93%9C%E4%B9%A6day13/"/>
      <url>/%E8%A5%BF%E7%93%9C%E4%B9%A6day13/</url>
      
        <content type="html"><![CDATA[<h1><span id="以多分类为例">以多分类为例</span></h1><h1><span id="贝叶斯判定准则">贝叶斯判定准则</span></h1><p>为最小化总体风险，只需在每个样本上选择能使条件风险 $R(c \mid x)$ 最小的类别标记，即为： $h^*(x)=argmin_{c \in y}R(c \mid x)=argmax_{c \in y}P(c \mid x)$,</p><p>此时，$h^*$ 为贝叶斯最优分类器。条件风险：</p><p>$R(c_i \mid x)=\sum_{j=1}^N \lambda_{ij}P(c_j \mid x)=1-P(c_i \mid x)$,</p><p>$\lambda_{ij}$ 是将一个真实标记为 $c_j$ 的样本误分类为 $c_i$ 所产生的损失。</p><h1><span id="多元正态分布的mle">多元正态分布的MLE</span></h1><p>概率模型的训练过程就是参数估计过程。</p><ul><li><p>频率主义学派：参数虽然未知，但却是客观存在的固定值，因此，可通过优化似然函数等准则来确定参数值</p></li><li><p>贝叶斯学派：参数是为观察到的随机变量，其本身也可以有分布，因此，可假定参数服从一个先验分布，然后基于观测到的数据来计算参数的后验分布。</p></li></ul><p>MLE源自频率主义学派。</p><p>$P(D_c \mid \theta_c)=\prod_{x \in D_c}P(x \mid \theta_c)$</p><p>其中 $D_c$ 表示训练集D中第c类样本组成的集合。</p><p>推导：</p><p>$LL(\theta_c)$</p><p>$=logP(D_c \mid \theta_c)$</p><p>$=\sum_{x \in D_c}logP(x \mid \theta_c)$</p><h2><span id="多元正态分布的概率密度函数">多元正态分布的概率密度函数：</span></h2><p>由于 $P(x \mid \theta_c)=P(x \mid c) -N(\mu_c,\sigma_c^2)$, 那么</p><p>$P(x \mid \theta_c)=\frac{1}{\sqrt{(2\pi)^d\mid\sum_c\mid}}exp(-\frac{1}{2}(x-\mu_c)^T\sum_c^{-1}(x-\mu_c))$</p><p>其中d表示xde维数，$\sum_c=\sigma_c^2$ 为对称正定协方差矩阵，$\mid\sum_c\mid$ 表示行列式，将上式代入对数似然函数可得</p><p>$LL(\theta_c)=\sum_{x \in D_c}ln[\frac{1}{\sqrt{(2\pi)^d\mid\sum_c\mid}}exp(-\frac{1}{2}(x-\mu_c)^T\sum_c^{-1}(x-\mu_c))]$</p><p>$=\sum_{i=1}^Nln[\frac{1}{\sqrt{(2\pi)^d\mid\sum_c\mid}}exp(-\frac{1}{2}(x_i-\mu_c)^T\sum_c^{-1}(x_i-\mu_c))]$</p><p>$=\sum_{i=1}^N{ln\frac{1}{\sqrt{(2\pi)^d}}+ln\frac{1}{\sqrt{\mid \sum_c \mid}}+ln[exp(-\frac{1}{2}(x_i-\mu_c)^T\sum_c^{-1}(x_i-\mu_c))]}$</p><p>$=-\frac{Nd}{2}ln(2\pi)-\frac{N}{2}ln\mid \sum_c\mid-\frac{1}{2}\sum_{i=1}^N(x_i-\mu_c)^T\sum_c^{-1}(x_i-\mu_c))$</p><p>由于参数 $\theta_c$ 的极大似然估计 $\hat{\theta_c}$ 为 $\hat{\theta_c}=argmax_{\theta_c}LL(\theta_c)$，</p><p>对 $LL(\theta_c)$ 关于 $\mu_c$ 求偏导：</p><p>$\frac{\partial LL(\theta_c)}{\partial \mu_c}=-\frac{1}{2}\sum_{i=1}^{N}\frac{\partial (x_i^T-\mu_c^T)\sum_c^{-1}(x_i-\mu_c)}{\partial \mu_c}$</p><p>$=-\frac{1}{2}\sum_{i=1}^{N}\frac{\partial [x_i^T\sum_c^{-1}x_i-x_i^T\sum_c^{-1}\mu_c-\mu_c^T\sum_c^{-1}x_i+\mu_c^T\sum_c^{-1}\mu_c]}{\partial \mu_c}$</p><p>由于 $x_i^T\sum_c^{-1}\mu_c=(x_i^T\sum_c^{-1}\mu_c)^T=\mu_c^T(\sum_c^T)^{-1}x_i=\mu_c^T\sum_c^{-1}x_i$</p><p>$=-\frac{1}{2}\sum_{i=1}^{N}\frac{\partial [x_i^T\sum_c^{-1}x_i-2x_i^T\sum_c^{-1}\mu_c+\mu_c^T\sum_c^{-1}\mu_c]}{\partial \mu_c}$</p><p>$=-\frac{1}{2}\sum_{i=1}^{N}[0-(2x_i^T\sum_c^{-1})^T+(\sum_c^{-1}+(\sum_c^{-1})^T)\mu_c]$</p><p>$=-\frac{1}{2}\sum_{i=1}^{N}[-(2\sum_c^{-1}x_i)+2\sum_c^{-1}\mu_c]$</p><p>$=\sum_{i=1}^{N}\Sigma_c^{-1}x_i-N\Sigma_c^{-1}\mu_c$</p><p>$=0$</p><p>$\hat{\mu_c}=\frac{\sum_{i=1}^Nx_i}{N}$</p><p>对 $LL(\theta_c)$ 关于 $\Sigma_c$ 求偏导：</p><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day13/4.JPG" alt><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day13/5.JPG" alt><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day13/6.JPG" alt></p><h2><span id="评估">评估</span></h2><p>这种参数化的方法虽然能使类条件概率估计变得相对简单，但估计结果的准确性严重依赖于所假设的概率分布形式是否符合潜在的真实数据分布。</p><h1><span id="朴素贝叶斯分类器">朴素贝叶斯分类器</span></h1><p>$h^*(x)=argmax P(c \mid x)=argmax \frac{P(c)P(x \mid c)}{P(x)}=argmaxP(c)P(x \mid c)$ ++++++属性条件独立性假设</p><p>属性条件独立性假设定义：$P(x \mid c)=P(x_1,x_2,...,x_d \mid c)=\prod_{i=1}^{d}P(x_i \mid c)$ -----(牺牲准确度换取计算效率)</p><h2><span id="naive-bayes">naive bayes</span></h2><p>$h^*(x)=argmaxP(c)\prod_{i=1}^dP(x_i \mid c)$</p><h2><span id="先验概率-pc">先验概率 $P(c)$</span></h2><p>$P(c)=\frac{\mid D_c \mid}{\mid D \mid}$</p><h2><span id="似然概率-px_i-mid-c">似然概率 $P(x_i \mid c)$</span></h2><h4><span id="连续值">连续值</span></h4><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day13/2.JPG" alt></p><h4><span id="离散值">离散值</span></h4><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day13/1.JPG" alt></p><h2><span id="laplacian-correction">Laplacian correction</span></h2><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day13/3.JPG" alt>拉普拉斯修正避免了因训练集样本不充足而导致概率估值为0的问题，当训练集样本增大，这个误差会被忽略。</p><h1><span id="em算法">EM算法</span></h1><h2><span id="em算法的引入">EM算法的引入</span></h2><h4><span id="为什么需要em">为什么需要EM？</span></h4><p>训练样本含有隐变量Z</p><h2><span id="em算法的例子">EM算法的例子</span></h2><p>《统计学习方法》-三硬币模型  9.1</p><p>迭代求解参数,近似极大化</p><h2><span id="em算法的导出">EM算法的导出</span></h2><h4><span id="jensen-不等式">Jensen 不等式</span></h4><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day13/7.JPG" alt></p><p>可以将a看作概率，则f表示为期望</p><p>Jensen不等式在概率论中的应用：$\varphi(E[X]) \leq E[\varphi(X)]$</p><h4><span id="推导">推导</span></h4><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day13/8.JPG" alt><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day13/9.JPG" alt><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day13/10.JPG" alt><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day13/11.JPG" alt><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day13/12.JPG" alt><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day13/13.JPG" alt></p><h2><span id="em算法求解例子">EM算法求解例子</span></h2><p>用EM求解三硬币</p><ul><li>E:求Q</li><li>M：寻找参数最大化期望</li></ul>]]></content>
      
      
      <categories>
          
          <category> ML </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 西瓜书 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>西瓜书day9,day10,day11,day12(支持向量机)</title>
      <link href="/%E8%A5%BF%E7%93%9C%E4%B9%A6day9/"/>
      <url>/%E8%A5%BF%E7%93%9C%E4%B9%A6day9/</url>
      
        <content type="html"><![CDATA[<h1><span id="预备知识">预备知识</span></h1><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day9/3.JPG" alt><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day9/4.JPG" alt></p><h1><span id="间隔与支持向量">间隔与支持向量</span></h1><p>分类学习最基本的想法就是基于训练集D在样本空间中找到一个划分超平面，将不同类别的样本分开。<img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day9/1.JPG" alt></p><p>直观来说，应该找位于两类训练样本“正中间”的划分超平面，因为其对训练样本局部扰动的“容忍”性最好。</p><p>在训练样本中，划分超平面可以通过线性方程 $\mathbb{w}^T\mathbb{x}+b=0$ 来描述。其中 $\mathbb{w}=(w_1;w_2;...;d_d)$ 为法向量，决定了超平面的方向；b为位移，决定了超平面与原点之间的距离。样本空间中任意点 $x$ 到超平面$(\mathbb{w},b)$ 的距离可写为：</p><p>$r=\frac{\mid \mathbb{w}^T\mathbb{x}+b \mid}{\mid \mid \mathbb{w} \mid \mid}$.</p><p>证明：</p><p>任意取超平面上一个点 $x'$，则点 $x$ 到超平面的距离等于向量 $(x-x')$ 在法向量 $w$（参考预备2）的投影长度（参考预备1）:</p><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day9/5.JPG" alt>注意：上式推导过程中，分子之所有取绝对值是由于向量内积可能小于零；另外，由于 $x'$ 是超平上面的点，因此 $\mathbb{w}^T\mathbb{x'}+b=0$，即 $b=-\mathbb{w}^T\mathbb{x'}$。</p><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day9/6.JPG" alt></p><p>注意到，距离超平面最近的训练样本可以使上式的等号成立，由6.2知这些训练样本到超平面的距离为：</p><p>$dist=\frac{\mid \mathbb{w}^T\mathbb{x}+b \mid}{\mid \mid \mathbb{w} \mid \mid}=\frac{1}{\mid \mid w \mid \mid}$.</p><p>那么很容易知道，两个异类支持向量到超平面的距离之和是 $\frac{2}{\mid \mid w \mid \mid}$<img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day9/2.JPG" alt></p><h1><span id="支持向量基本型">支持向量基本型</span></h1><p>最大间隔超平面条件等同于最小化如下公式：</p><p>$min_{w,b} \frac{1}{2} \mid \mid \mathbb{w} \mid \mid^2$</p><p>s.t. $y_i(\mathbb{w}^T\mathbb{x}_i+b) \ge 1$, i=1,2,...,m.</p><p>式(6.6)的约束条件意思是训练样本线性可分，也就是说不存在被分类错误的样本，因此也就不存在欠拟合问题；已知优化式(6.6)目标函数是在寻找“最大间隔”的划分超平面，而“最大间隔”划分超平面所产生的分类结果是最鲁棒的，对未见示例的泛化能力最强，因此可将式(6.6)优化目标进一步解释为寻找最不可能过拟合的分类超平面，这一点与正则化不谋而合。</p><h1><span id="对偶问题">对偶问题</span></h1><h2><span id="拉格朗日乘子法">拉格朗日乘子法</span></h2><p>此出假设优化问题一定有解<img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day9/7.JPG" alt></p><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day9/8.JPG" alt></p><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day9/9.JPG" alt></p><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day9/10.JPG" alt></p><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day9/11.JPG" alt></p><h1><span id="核函数">核函数</span></h1><p>使训练样本在高维空间可分的映射函数。<img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day9/12.JPG" alt>$f(x)=\mathbb{w}^T \phi(x)+b$, 此时w的维度与 $\phi(x)$ 同。</p><p>核函数可以分解成两个向量的内积。要想了解某个核函数是如何将原始特征空间映射到更高维的特征空间的，只需要将核函数分解为两个表达形式完全一样的向量 $\phi(x_i)$ 和 $\phi(x_j)$ 即可（有时很难分解）。以下是LIBSVM中的几个核函数：<img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day9/13.JPG" alt><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day9/14.JPG" alt>遗留问题：核函数的几何意义是什么？核矩阵正定核函数就存在？</p><h1><span id="软间隔与正则化">软间隔与正则化</span></h1><p>软间隔的引入：</p><p>在前面的学习中，一直假设训练样本在样本空间或特征空间是线性可分的，要求所有样本都必须正确划分，称为“硬间隔”，然而现实中很难确定核函数使训练样本线性可分，缓解这一问题的方法是允许SVM在一些样本上出错，因此，引入软间隔：允许某些样本不满足约束 $y_i(w^Tx_i+b) \geq 1$<img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day9/15.JPG" alt></p><h2><span id="预备知识替代损失函数">预备知识：替代损失函数</span></h2><ul><li>凸函数</li><li>连续函数<img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day9/16.JPG" alt><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day9/19.JPG" alt></li></ul><h2><span id="软间隔优化目标函数">软间隔优化目标函数</span></h2><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day9/17.JPG" alt></p><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day9/18.JPG" alt></p><p>引入松弛变量后的目标函数</p><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day9/20.JPG" alt></p><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day9/21.JPG" alt></p>]]></content>
      
      
      <categories>
          
          <category> ML </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 西瓜书 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>paper:AdamOptimizer</title>
      <link href="/paper-AdamOptimizer/"/>
      <url>/paper-AdamOptimizer/</url>
      
        <content type="html"><![CDATA[<h1><span id="paperadam-a-method-for-stochastic-optimization">paper：Adam: A Method for Stochastic Optimization</span></h1><p>论文链接：<img src="https://arxiv.org/abs/1412.6980" alt></p><p><img src="/paper-AdamOptimizer/1.JPG" alt></p><p>如上算法所述，在确定了参数 $\alpha$,$\beta_1$,$\beta_2$和随机目标函数 $f(\theta)$ 之后，我们需要初始化参数向量、一阶矩向量、二阶矩向量和时间步。然后当参数 $\theta$ 没有收敛时，循环迭代地更新各个部分。即时间步 t 加 1、更新目标函数在该时间步上对参数 $\theta$ 所求的梯度、更新偏差的一阶矩估计和二阶原始矩估计，再计算偏差修正的一阶矩估计和偏差修正的二阶矩估计，然后再用以上计算出来的值更新模型的参数 $\theta$。</p><h1><span id="算法">算法</span></h1>]]></content>
      
      
      <categories>
          
          <category> deep learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tensorflow </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>西瓜书day5,day6,day7,day8(决策树)</title>
      <link href="/%E8%A5%BF%E7%93%9C%E4%B9%A6day5/"/>
      <url>/%E8%A5%BF%E7%93%9C%E4%B9%A6day5/</url>
      
        <content type="html"><![CDATA[<h1><span id="决策树定义">决策树定义</span></h1><p>决策树是基于输结构来进行决策的一类常见的机器学习分类方法。</p><h1><span id="解决问题">解决问题</span></h1><p>“当前样本属于正类吗？”</p><p>“这是好瓜吗？”</p><p>“它的根蒂是什么形态”</p><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day5/1.JPG" alt></p><p>决策过程的最终结论（叶子节点）对应了我们所希望的判定结果：好瓜 or 坏瓜</p><h1><span id="结构">结构</span></h1><p>1.一个根节点和若干个内部节点：分别对应一个属性测试</p><p>2.若干个叶节点：对应决策结果</p><p>j决策树学习的目的是为了产生一棵泛化能力强的决策树，基本流程遵循“分而治之”：</p><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day5/2.JPG" alt></p><p>递归返回条件：</p><ul><li>当前节点包含的样本全属于同一类别，无需划分</li><li>当前属性集为空，或是所有样本在所有属性上取值相同，无法划分</li><li>当前节点包含的样本集合为空，不能划分。</li></ul><h1><span id="id3">ID3</span></h1><p>信息熵：</p><p>熵是度量样本集合纯度最常用的一种指标，代表一个系统中蕴含多少信息量，信息量越大表明一个系统不确定性就越大，就存在越多的可能性，即信息熵越大。</p><p>假定当前样本集合D中第K类样本所占的比例为 $p_k(k=1,2,...,\mid y\mid)$, 则D的信息熵为：</p><p>$Ent(D)=-\sum_{k=1}^{\mid y \mid}p_{k}log_{2}p_{k}$</p><p>信息熵满足下列不等式：</p><p>$0 \leq Ent(D) \leq log_{2}\mid y \mid$ ,</p><p>$0 \leq p_k \leq 1$, $\sum_{k=1}^np_k=1$</p><p>其中$y$表示D中的样本类别数。</p><h2><span id="id3推导max-value">ID3推导(max-value)</span></h2><p>若令 $\mid y \mid=n,p_k=x_k$, 那么信息熵 $Ent(D)$ 可以看作一个n元实值函数，即</p><p>$Ent(D)=f(x_1,...,x_n)=-\sum_{k=1}^{n}x_{k}log_{2}x_{k}$, 其中：$0 \leq p_k \leq 1$, $\sum_{k=1}^np_k=1$.</p><p>引入拉格朗日乘子 $\lambda$求最值：</p><p>$L(x_1,...,x_n,\lambda)=-\sum_{k=1}^{n}x_{k}log_{2}x_{k}+\lambda(\sum_{k=1}^nx_k-1)$</p><p>$\frac{\partial L(x_1,...,x_n,\lambda)}{\partial x_1}=-log_2x_1-x_1 \cdot \frac{1}{x_{1}ln2}+\lambda=0$</p><p>$\lambda=log_2x_1+\frac{1}{ln2}$</p><p>同理：</p><p>$\lambda=log_2x_1+\frac{1}{ln2}=log_2x_2+\frac{1}{ln2}=...=log_2x_n+\frac{1}{ln2}$</p><p>so: $x_1=x_2=...=x_n=\frac{1}{n}$</p><p>最大值与最小值需要验证：</p><ul><li>$x_1=x_2=...=x_n=\frac{1}{n}$ 时：$f=-n \cdot \frac{1}{n}log_2\frac{1}{n}=log_2n$</li><li>$x_1=1,x_2=x_3=...=x_n=0$ 时： $f=0$</li></ul><p>所以为最大值</p><h2><span id="id3推导min-value">ID3推导(min-value)</span></h2><p>Assume:</p><p>$f(x_1,...x_n)=\sum_{k=1}^ng(x_k)$</p><p>$g(x_k)=-\sum_{k=1}^{n}x_{k}log_{2}x_{k}$, $0 \leq p_k \leq 1$</p><p>求 $g(x_1)$ 的最小值，首先求导：</p><p>$\frac{d(g(x_1))}{dx_1}=-log_2x_1-\frac{1}{ln2}$</p><p>$\frac{d^2(g(x_1))}{dx^2}=-\frac{1}{x_1ln2}$</p><p>在定义域$0 \leq p_k \leq 1$， 始终有 $\frac{d^2(g(x_1))}{dx^2}=-\frac{1}{x_1ln2} \leq 0$,所以最小值在边界处$x_1=0 或 x_1=1$取得：$min g(x_1)=0$</p><p>由推理可得$f(0,0,0,0,1,...,0)=0$</p><p>所以：</p><p>$0 \leq Ent(D) \leq log_{2}\mid y \mid$</p><h2><span id="信息增益">信息增益</span></h2><p>假定离散属性有V个可能的取值 {${a^1,a^2,...,a^V}$}, 如果使用特征a来对数据集D进行划分，则会产生V个分支结点，其中第 $v$ 个结点包含了数据集D中所有在特征a上取值为 $a^V$ 的样本总数，记为 $D^v$, 特征对样本集D进行划分的“样本增益”为：</p><p>$Gain(D,a)=Ent(D)-\sum_{v=1}^V \frac{\mid D^V \mid}{\mid D \mid}Ent(C^v)$</p><h2><span id="缺点">缺点</span></h2><p>1.ID3没有考虑连续特征</p><p>2.ID3采用信息增益大的特征优先建立决策树的节点，取值比较多的特征比取值少的特征信息增益大</p><p>3.ID3算法对于缺失值的情况没有做考虑</p><p>4.没有考虑过拟合的情况</p><h1><span id="c45算法">C4.5算法</span></h1><p>增益率：</p><p>弥补ID3偏向于取值较多属性,C4.5算法不直接使用信息增益，而是使用一种叫增益率的方法来选择最优属性进行划分：</p><p>$Gain-ration(D,a)=\frac{Gain(D,a)}{IV(a)}$</p><p>$IV(a)$ 是属性 $a$ 的固有值：</p><p>$IV(a)=-\sum_{v=1}^V \frac{\mid D^v \mid}{\mid D \mid}log_2 \frac{\mid D^v \mid}{D}$</p><p>属性越多，熵越大，对分支过多的情况进行惩罚。</p><h2><span id="缺点">缺点</span></h2><p>1.C4.5生成的是多叉树，生成决策树的效率比较慢</p><p>2.C4.5只能用于分类</p><p>3.C4.5由于使用了熵模型，对数运算耗时。</p><h1><span id="cart">CART</span></h1><p>Gini值：</p><p>度量数据集的纯度，Gini(D)反应了从数据集中随机抽取两个样本,类别标记不一致的概率，数据越小，纯度越高。</p><p>$Gini(D)=\sum_{k=1}^{\mid y \mid}\sum_{k' \neq k}p_kp_{k'}=1-\sum_{k=1}^{\mid y \mid}p_k^2$</p><p>$Gini-index(D,a)=\sum_{v=1}^V \frac{\mid D^v \mid}{\mid D \mid}Gini(D^v)$</p><h1><span id="剪枝">剪枝</span></h1><p>减指是决策树学习算法处理过拟合的重要手段。决策树剪枝的基本策略有“预剪枝”和“后剪枝”。预剪枝是对每个节点在划分前进行估计，若不能带来泛化能力的提升，则停止划分并将该节点标记为叶节点。后剪枝则是先从训练集生成一颗完整的决策树，然后自底向上计算泛化能力是否提升，否则标记为叶节点。<img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day5/3.JPG" alt></p><h2><span id="预剪枝">预剪枝</span></h2><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day5/4.JPG" alt><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day5/5.JPG" alt></p><h2><span id="后剪枝">后剪枝</span></h2><p>后剪枝先从训练集生成一棵完整的决策树如图4.5，该决策树的验证集精度为42.9%，后剪枝首先考察节点6，然后节点五，节点二，节点三，节点一，计算过程如图。<img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day5/6.JPG" alt></p><h2><span id="对比">对比</span></h2><ul><li>后剪枝比预剪枝保留了更多的分支。</li><li>后剪枝欠拟合风险小，泛化能力优于预剪枝决策树</li><li>后剪枝是在生成决策树后进行的，自底向上对非叶节点逐个考察，训练时间与开销都比预剪枝大得多</li></ul><h1><span id="连续与缺失值">连续与缺失值</span></h1><h1><span id="连续值处理在决策树学习中使用连续属性进行决策">连续值处理：在决策树学习中使用连续属性进行决策</span></h1><p>方法：连续属性离散化：（eg,二分法)</p><p>给定样本集$D$ 和连续属性，划分点$t$可以将D分为子集 $D_t^-$ 与 $D_t^+$, $D_t^-$包含在属性 $a$ 上不大于 $t$ 的样本，候选划分集合：</p><p>$T_a={\frac{a^i+a^{i+1}}{2} \mid 1 \leq i \leq n-1}$</p><p>然后我们可以像离散属性一样来选择划分点：</p><p>$Gain(D,a)=max_{t \in T_a}Gain(D,a,t)=max_{t \in T_a}Ent(D)-\sum_{\lambda \in {-,+}}\frac{\mid D_t^{\lambda} \mid}{\mid D \mid}Ent(D_t^{\lambda})$</p><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day5/7.JPG" alt><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day5/8.JPG" alt></p><h1><span id="缺失值处理">缺失值处理</span></h1><p>样本的某些属性值缺失如何进行划分属性的选择呢？</p><p>给定划分属性，若样本在该属性上的值缺失，如何对样本进行划分？</p><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day5/9.JPG" alt></p><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day5/10.JPG" alt></p><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day5/11.JPG" alt></p>]]></content>
      
      
      <categories>
          
          <category> ML </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 西瓜书 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>paper:CFGAN</title>
      <link href="/paper-CFGAN/"/>
      <url>/paper-CFGAN/</url>
      
        <content type="html"><![CDATA[<p>本片博客总结paper CFGAN。</p><p>《CFGAN: A Generic Collaborative Filtering Framework based on Generative Adversarial Networks》</p><p>from CIKM 2018</p><p>contribution:  GAN-based CF model</p><p>keyWords: Top-N recommendation, collaborative filtering, generative adversarial networks, implicit feedback</p>]]></content>
      
      
      <categories>
          
          <category> recommender systems </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Recommender systems </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>tensorflow loss分析</title>
      <link href="/train-loss/"/>
      <url>/train-loss/</url>
      
        <content type="html"><![CDATA[<h1><span id="train-loss与test-loss结果分析">train loss与test loss结果分析</span></h1><p>train loss 不断下降，test loss不断下降，说明网络仍在学习;</p><p>train loss 不断下降，test loss趋于不变，说明网络过拟合;</p><p>train loss 趋于不变，test loss不断下降，说明数据集100%有问题;</p><p>train loss 趋于不变，test loss趋于不变，说明学习遇到瓶颈，需要减小学习率或批量数目;</p><p>train loss 不断上升，test loss不断上升，说明网络结构设计不当，训练超参数设置不当，数据集经过清洗等问题。</p><h1><span id="loss和神经网络训练">Loss和神经网络训练</span></h1><h2><span id="训练前的检查工作">训练前的检查工作</span></h2><p>1.loss:在用很小的随机数初始化神经网络后，第一遍计算loss可以做一次检查(当然要记得把正则化系数设为0)。</p><p>2.接着把正则化系数设为正常的小值，加回正则化项，这时候再算损失/loss，应该比刚才要大一些。</p><p>3.试着去拟合一个小的数据集。最后一步，也是很重要的一步，在对大数据集做训练之前，先训练一个小的数据集，然后看看你的神经网络能够做到0损失/loss(当然，是指的正则化系数为0的情况下)，因为如果神经网络实现是正确的，在无正则化项的情况下，完全能够过拟合这一小部分的数据。</p><h2><span id="监控">监控</span></h2><p>开始训练之后，我们可以通过监控一些指标来了解训练的状态。我们还记得有一些参数是我们认为敲定的，比如学习率，比如正则化系数。</p><p>1.损失/loss随每轮完整迭代后的变化</p><p><img src="/train-loss/1.JPG" alt></p><p>合适的学习率可以保证每轮完整训练之后，loss都减小，且能在一段时间后降到一个较小的程度。太小的学习率下loss减小的速度很慢，如果太激进，设置太高的学习率，开始的loss减小速度非常可观，可是到了某个程度之后就不再下降了，在离最低点一段距离的地方反复，无法下降了。</p><p>2.训练集/验证集上的准确度:判断分类器所处的拟合状态。</p><p><img src="/train-loss/2.JPG" alt></p><p>随着时间推进，训练集和验证集上的准确度都会上升，如果训练集上的准确度到达一定程度后，两者之间的差值比较大，那就要注意一下，可能是过拟合现象，如果差值不大，那说明模型状况良好。</p><p>3.权重：权重更新幅度和当前权重幅度的比值权重更新部分是梯度和学习率的乘积，可以独立的检查这个比例，一个合适的比例大概是1e-3。如果得到的比例比这个值小很多，那么说明学习率设定太低了，反之则是设定太高了。</p><p>4.每一层的 激励/梯度值 分布：如果参数初始化不正确，那整个训练过程会越来越慢，甚至直接停掉。</p><h2><span id="关于参数更新部分的注意点">关于参数更新部分的注意点</span></h2><p>当确信解析梯度实现正确后，那就该在后向传播算法中使用它更新权重参数了。就单参数更新这个部分，也是有讲究的：</p><p>1.拿到梯度之后，乘以设定的学习率，用现有的权重减去这个部分，得到新的权重参数(因为梯度表示变化率最大的增大方向，减去这个值之后，损失函数值才会下降)。</p><p>2.在实际训练过程中，随着训练过程推进，逐渐衰减学习率是很有必要的。我们继续回到下山的场景中，刚下山的时候，可能离最低点很远，那我步子迈大一点也没什么关系，可是快到山脚了，我还激进地大步飞奔，一不小心可能就迈过去了。所以还不如随着下山过程推进，逐步减缓一点点步伐。不过这个『火候』确实要好好把握，衰减太慢的话，最低段震荡的情况依旧；衰减太快的话，整个系统下降的『动力』衰减太快，很快就下降不动了。下面提一些常见的学习率衰减方式：</p><ul><li>步伐衰减：这是很常见的一个衰减模式，每过一轮完整的训练周期(所有的图片都过了一遍)之后，学习率下降一些。比如比较常见的一个衰减率可能是每20轮完整训练周期，下降10%。不过最合适的值还真是依问题不同有变化。如果你在训练过程中，发现交叉验证集上呈现很高的错误率，还一直不下降，你可能就可以考虑考虑调整一下(衰减)学习率了。</li><li>指数级别衰减：需要自己敲定的超参数，是迭代轮数。</li><li>1/t衰减：有着数学形式为的衰减模式，其中是需要自己敲定的超参数，是迭代轮数。</li></ul><h2><span id="超参数的设定与优化">超参数的设定与优化</span></h2><p>神经网络的训练过程中，不可避免地要和很多超参数打交道，需要手动设定，大致包括：</p><p>1.初始学习率2.学习率衰减程度3.正则化系数/强度(包括l2正则化强度，dropout比例)</p><p>对于大的深层次神经网络而言，我们需要很多的时间去训练。因此在此之前我们花一些时间去做超参数搜索，以确定最佳设定是非常有必要的。最直接的方式就是在框架实现的过程中，设计一个会持续变换超参数实施优化，并记录每个超参数下每一轮完整训练迭代下的验证集状态和效果。实际工程中，神经网络里确定这些超参数，我们一般很少使用n折交叉验证，一般使用一份固定的交叉验证集就可以了。</p><p>一般对超参数的尝试和搜索都是在log域进行的。例如，一个典型的学习率搜索序列就是learning_rate = 10 ** uniform(-6, 1)。我们先生成均匀分布的序列，再以10为底做指数运算，其实我们在正则化系数中也做了一样的策略。比如常见的搜索序列为[0.5, 0.9, 0.95, 0.99]。另外还得注意一点，如果交叉验证取得的最佳超参数结果在分布边缘，要特别注意，也许取的均匀分布范围本身就是不合理的，也许扩充一下这个搜索范围会有更好的参数。</p><h2><span id="模型融合与优化">模型融合与优化：</span></h2><p>实际工程中，一个能有效提高最后神经网络效果的方式是，训练出多个独立的模型，在预测阶段选结果中的众数。模型融合能在一定程度上缓解过拟合的现象，对最后的结果有一定帮助，我们有一些方式可以得到同一个问题的不同独立模型：</p><ul><li>使用不同的初始化参数。先用交叉验证确定最佳的超参数，然后选取不同的初始值进行训练，结果模型能有一定程度的差别。</li><li>选取交叉验证排序靠前的模型。在用交叉验证确定超参数的时候，选取top的部分超参数，分别进行训练和建模。</li><li>选取训练过程中不同时间点的模型。神经网络训练确实是一件非常耗时的事情，因此有些人在模型训练到一定准确度之后，取不同的时间点的模型去做融合。不过比较明显的是，这样模型之间的差异性其实比较小，好处是一次训练也可以有模型融合的收益。</li></ul><p>检查你的初始权重是否合理，在关掉正则化项的系统里，是否可以取得100%的准确度。</p><p>在训练过程中，对损失函数结果做记录，以及训练集和交叉验证集上的准确度。</p><p>最常见的权重更新方式是SGD+Momentum，推荐试试RMSProp自适应学习率更新算法。</p><p>随着时间推进要用不同的方式去衰减学习率。</p><p>用交叉验证等去搜索和找到最合适的超参数。</p><p>记得也做做模型融合的工作，对结果有帮助。</p><h1><span id="loss保持常数的采坑记录">loss保持常数的采坑记录</span></h1><p>1.loss等于87.33这个问题是在对Inception-V3网络不管是fine-tuning还是train的时候遇到的，无论网络迭代多少次，网络的loss一直保持恒定。</p><p>原因（溢出）：</p><p>由于loss的最大值由FLT_MIN计算得到，FLT_MIN使其对应的自然对数正好是-87.3356，这也就对应上了loss保持87.3356了。这说明softmax在计算的过程中得到了概率值出现了零，由于softmax是用指数函数计算的，指数函数的值都是大于0的，所以应该是计算过程中出现了float溢出的异常，也就是出现了inf，nan等异常值导致softmax输出为0.当softmax之前的feature值过大时，由于softmax先求指数，会超出float的数据范围，成为inf。inf与其他任何数值的和都是inf，softmax在做除法时任何正常范围的数值除以inf都会变成0.然后求loss就出现了87.3356的情况。</p><p>solution:</p><p>由于softmax输入的feature由两部分计算得到：一部分是输入数据，另一部分是各层的权值等组成:</p><p>(1).减小初始化权重，以使得softmax的输入feature处于一个比较小的范围</p><p>(2).降低学习率，这样可以减小权重的波动范围</p><p>(3).如果有BN(batch normalization)层，finetune时最好不要冻结BN的参数，否则数据分布不一致时很容易使输出值变得很大(注意将batch_norm_param中的use_global_stats设置为false )。</p><p>(4).观察数据中是否有异常样本或异常label导致数据读取异常</p><h1><span id="loss不下降的常见原因">loss不下降的常见原因</span></h1><p>1）数据的输入是否正常，data和label是否一致。</p><p>2）网络架构的选择，一般是越深越好，也分数据集。 并且用不用在大数据集上pre-train的参数也很重要的。</p><p>3）loss 对不对。</p>]]></content>
      
      
      
        <tags>
            
            <tag> tensorflow </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>西瓜书day2,day3,day4(线性模型)</title>
      <link href="/%E8%A5%BF%E7%93%9C%E4%B9%A6day2/"/>
      <url>/%E8%A5%BF%E7%93%9C%E4%B9%A6day2/</url>
      
        <content type="html"><![CDATA[<h1><span id="基本形式">基本形式</span></h1><p>example:</p><p>$\mathbb{x}=(x_1;x_2;...;x_d)$</p><p>$x_i$是 $\mathbb{x}$ 在第i个属性上的取值线性模型试图学得$f(\mathbb{x})=\mathbb{w}^T\mathbb{x}+b$ 来预测函数，$\mathbb{w}$ 和 $b$ 为参数</p><p>线性模型优点：可解释性强</p><p>分类：</p><ul><li>回归</li><li>分类</li></ul><h1><span id="回归">回归</span></h1><p>均方误差是回归任务中最常用的性能度量</p><h2><span id="一元线性回归">一元线性回归</span></h2><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day2/1.png" alt><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day2/2.png" alt><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day2/3.png" alt><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day2/4.png" alt><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day2/5.png" alt></p><h2><span id="多元线性回归">多元线性回归</span></h2><p>更一般的情形，样本由多个属性决定，此时$f(\mathbb{x}_i)=\mathbb{w}^T\mathbb{x}_i+b$, 称为多元线性回归</p><p>依旧用最小二乘法<img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day2/6.png" alt><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day2/7.png" alt><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day2/8.png" alt><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day2/9.png" alt></p><h2><span id="对数几率回归">对数几率回归</span></h2><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day2/10.jpg" alt><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day2/11.jpg" alt><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day2/12.jpg" alt></p>]]></content>
      
      
      <categories>
          
          <category> ML </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 西瓜书 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>西瓜书day1（绪论）</title>
      <link href="/%E8%A5%BF%E7%93%9C%E4%B9%A6day1/"/>
      <url>/%E8%A5%BF%E7%93%9C%E4%B9%A6day1/</url>
      
        <content type="html"><![CDATA[<h1><span id="绪论">绪论</span></h1><p>机器学习致力于研究如何通过计算的手段，利用经验来改善系统自身的性能。经验即数据。</p><p>机器学习所研究的主要内容，是关于在计算机上从数据中产生“模型”的算法，learning algorithms.再用模型来预测未来数据。</p><h1><span id="术语">术语</span></h1><p>记录：</p><p>数据集：记录的集合</p><p>训练：从数据中学习模型的过程</p><p>训练集：训练过程中使用的数据样本的集合</p><p>分类任务：预测的结果为离散值（好瓜，坏瓜）</p><p>回归任务：预测值是连续值</p><p>根据训练数据是否有label，学习任务可划分为：“监督学习”，“无监督学习”</p><p>泛化能力：学得模型适用于新样本的能力</p><h1><span id="归纳演绎">归纳演绎</span></h1><p>归纳：从特殊到一般（机器学习）</p><p>演绎：从一般到特殊</p><h1><span id="发展历程">发展历程</span></h1><p>机器学习是人工智能研究发展到一定阶段的必然产物。</p><table><thead><tr><th>年代</th><th>事件</th><th>代表工作</th></tr></thead><tbody><tr><td>二十世纪而五十年代到七十年代</td><td>人工智能的推理期</td><td>感知机、Adaline</td></tr><tr><td>五十年代中后期</td><td>符号主义蓬勃发展，决策理论。增强学习</td><td>结构学习系统，概念学习系统</td></tr><tr><td>八十年代</td><td>决策树学习</td><td>由于复杂度过高而陷入低潮</td></tr><tr><td>九十年代</td><td>基于神将网络的连接学习</td><td>hopfield,BP,产生黑箱模型</td></tr><tr><td>九十年代中期</td><td>统计学习</td><td>SVM, 核方法</td></tr><tr><td>二十一世纪初</td><td>深度学习</td><td>对数据，硬件要求高</td></tr></tbody></table><h1><span id="应用现状">应用现状</span></h1><p>今天，在计算机学科的诸多分支学科中，无论是多媒体，图形学，还是网络通信，软件工程，体系结构，芯片设计都能找到机器学习的身影，尤其是CV与NLP。</p><p>交叉学科：生物信息学</p><p>大数据时代的三大技术：机器学习，云计算，众包</p><p>数据挖掘与机器学习的关系：</p><p>数据挖掘技术在二十世纪九十年代形成，受数据库，机器学习，统计学影响最大。数据挖掘是从海量知识中发掘知识，这就必然涉及对海量数据的管理分析。数据库领域的研究为数据挖掘提供数据管理技术，而机器学习和统计学研究为数据挖掘提供数据分析技术，统计学主要是通过机器学习对数据挖掘发挥影响，机器学习领域与数据库领域是数据挖掘的两大支撑。</p><p><img src="/%E8%A5%BF%E7%93%9C%E4%B9%A6day1/1.jpg" alt></p>]]></content>
      
      
      <categories>
          
          <category> ML </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 西瓜书 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>tensorflow深度学习(2):tf.nn.top_k()</title>
      <link href="/tensorflow%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-2-tf-nn-top-k/"/>
      <url>/tensorflow%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-2-tf-nn-top-k/</url>
      
        <content type="html"><![CDATA[<h1><span id="introduction">introduction</span></h1><p>def top_k(input, k=1, sorted=True, name=None)</p><p>Finds values and indices of the k largest entries for the last dimension.</p><p>If the input is a vector (rank=1), finds the k largest entries in the vector and outputs their values and indices as vectors.Thus values[j] is the j-th largest entry in input, and its index is indices[j].</p><p>For matrices (resp. higher rank input), computes the top k entries in each row (resp. vector along the last dimension).Thus, values.shape = indices.shape = input.shape[:-1] + [k]</p><p>If two elements are equal, the lower-index element appears first.</p><h1><span id="parameters">parameters</span></h1><p><img src="/tensorflow%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-2-tf-nn-top-k/1.JPG" alt></p><h1><span id="code">code</span></h1><p><img src="/tensorflow%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-2-tf-nn-top-k/2.JPG" alt></p>]]></content>
      
      
      
        <tags>
            
            <tag> tensorflow </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>temsorflow常用集合(colection)</title>
      <link href="/tensorflow%E5%B8%B8%E7%94%A8%E9%9B%86%E5%90%88/"/>
      <url>/tensorflow%E5%B8%B8%E7%94%A8%E9%9B%86%E5%90%88/</url>
      
        <content type="html"><![CDATA[<p>tensorflow 用集合collection组织不同类别的对象，tf.GraphKeys中包含了所有默认集合的名称。</p><p>collection在对应的scope内提供了“零存整取”的思想：任意位置，任意层次的对象，统一提取。</p><p>tf.optimizer只优化tf.GraphKeys.TRAINABLE_VARIABLES中的变量</p><h2><span id="常用集合">常用集合</span></h2><ul><li>Variable集合：模型参数</li><li>summary 集合：监测</li><li>自定义集合</li></ul><h1><span id="variable">Variable</span></h1><p>Variable被收集在tf.GraphKeys.VARIABLES的collection中</p><h2><span id="定义">定义</span></h2><p>k=tf.Variable()<img src="/tensorflow%E5%B8%B8%E7%94%A8%E9%9B%86%E5%90%88/1.JPG" alt></p><h1><span id="summary">summary</span></h1><p>Summary被收集在名为tf.GraphKeys.SUMMARIES的collection中</p><h2><span id="define">define</span></h2><p>对网络中tensor取值进行监测</p><p>调用tf.scalar_summary系列函数，会向默认的collection中添加一个operation</p><p><img src="/tensorflow%E5%B8%B8%E7%94%A8%E9%9B%86%E5%90%88/2.JPG" alt></p><h1><span id="自定义">自定义</span></h1><p>tf.add_to_collection(&quot;losses&quot;,l1)losses=tf.get_collection('losses')</p>]]></content>
      
      
      
        <tags>
            
            <tag> tensorflow </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习之线性模型推导</title>
      <link href="/machine-learning-2/"/>
      <url>/machine-learning-2/</url>
      
        <content type="html"><![CDATA[<p>西瓜书，南瓜书</p><h1><span id="一元线性回归">一元线性回归</span></h1><p>最小二乘法推导</p><h2><span id="b的公式推导3638">b的公式推导（3.6，3.8）</span></h2><p>（二元函数求最值）</p><p>1.由最小二乘法导出损失函数E（w,b）</p><p>2.证明损失函数是关于w,b的凸函数</p><p>3.对损失函数关于B求偏导数</p><p>4.另一接偏导数为0求b</p><p>由最小二乘法导出损失函数：</p><p>$E_{w,b}=\sum_{i=1}^m$</p><h2><span id="w的公式推导3537">w的公式推导（3.5，3.7）</span></h2><h1><span id="多元线性回归">多元线性回归</span></h1>]]></content>
      
      
      
        <tags>
            
            <tag> machine learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>machine learning(1)</title>
      <link href="/machine-learning-1/"/>
      <url>/machine-learning-1/</url>
      
        <content type="html"><![CDATA[<h1><span id="机器学习的四大应用领域及其应用">机器学习的四大应用领域及其应用</span></h1><h2><span id="数据挖掘发现数据之间的关系">数据挖掘：发现数据之间的关系</span></h2><p>1.回归问题</p><p>2.分类问题</p><p>根据已知数据，学习函数。</p><h2><span id="计算机视觉像人一样看懂世界">计算机视觉：像人一样看懂世界</span></h2><p>图像分类</p><p>目标检测（无人驾驶）</p><p>语义分割（无人驾驶）</p><p>场景理解（无人驾驶）</p><h2><span id="nlp像人一样看懂文字">NLP：像人一样看懂文字</span></h2><p>文本分类（新闻分类）</p><p>自动生成文本摘要</p><p>翻译</p><p>QA</p><p>人机对话（小冰）</p><p>image to text</p><p>end to end级自动驾驶</p><h2><span id="机器人决策像人一样具有决策能力">机器人决策：像人一样具有决策能力</span></h2><p>TORCS平台（玩赛车游戏）：增强学习（agent,action）</p><p>机器人开门（自动执行）：增强学习</p><h1><span id="机器学习理论分类">机器学习理论分类</span></h1><p>常用的三类：</p><p>1.传统的监督学习（分类，回归）</p><p>2.深度学习（视觉，NLP）</p><p>3.强化学习（机器人）</p><p>三种分类学习按标号顺序循序渐进</p><h1><span id="先重点再难点">先重点，再难点</span></h1><p><img src="/machine-learning-1/1.jpg" alt></p><p><img src="/machine-learning-1/2.jpg" alt></p>]]></content>
      
      
      
        <tags>
            
            <tag> machine learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>调参技巧汇总</title>
      <link href="/%E8%B0%83%E5%8F%82%E6%8A%80%E5%B7%A7%E6%B1%87%E6%80%BB/"/>
      <url>/%E8%B0%83%E5%8F%82%E6%8A%80%E5%B7%A7%E6%B1%87%E6%80%BB/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>推荐系统评估指标(Rank)</title>
      <link href="/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87/"/>
      <url>/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87/</url>
      
        <content type="html"><![CDATA[<h1><span id="mean-average-precision-map">Mean Average Precision (MAP)</span></h1><p>$AP=\frac {\sum_{j=1}^{n_i}P(j)\cdot y_{i,j}}{\sum_{j=1}^{n_i}y_{i,j}}$</p><p>其中，$y_{i,j}$: 排序中第j个元素对于查询i是否是相关的；相关为1，不相关为0。</p><p>$P(j)=\frac {\sum_{k:\pi_{i}(k)\leq\pi_{i}(j)} y_{i,k}}{\pi_{i}(j)}$</p><p>其中，$\pi_{i}(j)$为J的排序位置。</p><p>例如：</p><table><thead><tr><th>rank_no</th><th>是否相关</th></tr></thead><tbody><tr><td>1</td><td>1</td></tr><tr><td>2</td><td>0</td></tr><tr><td>3</td><td>1</td></tr><tr><td>4</td><td>0</td></tr><tr><td>5</td><td>1</td></tr><tr><td>6</td><td>0</td></tr></tbody></table><p>则根据AP计算公式：$AP=(1*1 + (1/2) *0+ (2/3)*1 + (2/4)*0 + (3/5)*0 + (3/6)*0) /3$</p><p>AP的最大值是1，MAP就是对所有user求均值。</p><h1><span id="mean-reciprocal-rank-mrr">Mean Reciprocal Rank (MRR)</span></h1><p>$MRR=\frac{1}{\mid Q \mid} \sum_{i=1}^{\mid Q \mid} \frac{1}{rank_i}$</p><p>其中|Q|是查询个数，ranki是第i个查询，第一个相关的结果所在的排列位置。</p><p>例如：</p><table><thead><tr><th>Query</th><th>Result</th><th>Correct response</th><th>Rank</th><th>Reciprocal rank</th></tr></thead><tbody><tr><td>cat</td><td>catten,cati,cats</td><td>cats</td><td>3</td><td>1/3</td></tr><tr><td>tori</td><td>torii,tori,toruses</td><td>tori</td><td>2</td><td>1/2</td></tr><tr><td>virus</td><td>viruses,virii,viri</td><td>viruses</td><td>1</td><td>1</td></tr></tbody></table><p>对于三个查询，每个查询的ranki分别为3、2、1。所以，MRR=1/3∗(1/3+1/2+1/1)</p><h1><span id="ndcgprerec的计算较为简单已在csdn中介绍这里省略">NDCG，pre,rec的计算较为简单，已在CSDN中介绍，这里省略。</span></h1>]]></content>
      
      
      <categories>
          
          <category> recommender systems </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 评估指标（Rec） </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>cluster</title>
      <link href="/cluster/"/>
      <url>/cluster/</url>
      
        <content type="html"><![CDATA[<h1><span id="概述">概述</span></h1><p>聚类（Clustering）的本质是对数据进行分类，将相异的数据尽可能地分开，而将相似的数据聚成一个类别（簇），使得同一类别的数据具有尽可能高的同质性（homogeneity），类别之间有尽可能高的异质性（heterogeneity），从而方便从数据中发现隐含的有用信息。聚类算法的应用包含如下几方面：</p><ul><li>其他数据挖掘任务的关键中间环节：用于构建数据概要，用于分类、模式识别、假设生成和测试；用于异常检测，检测远离群簇的点。</li><li>数据摘要、数据压缩、数据降维：例如图像处理中的矢量量化技术。创建一个包含所有簇原型的表，即每个原型赋予一个整数值，作为它在表中的索引。每个对象用与它所在簇相关联的原型的索引表示。</li><li>协同过滤：用于推荐系统和用户细分。</li><li>动态趋势检测：对流数据进行聚类，检测动态趋势和模式。</li><li>用于多媒体数据、生物数据、社交网络数据的应用。</li></ul><h1><span id="聚类算法的分类">聚类算法的分类</span></h1><p>1.hierarchical methods：主要讲给定的数据集进行逐层分解，直到满足某种条件为止。具体可分为“自底向上”和“自顶向下”两种方案。在“自底向上”方案中，初始时每个数据点组成一个单独的组，在接下来的迭代中，按一定的距离度量将相互邻近的组合并成一个组，直至所有的记录组成一个分组或者满足某个条件为止。代表算法有：<img src="https://www2.cs.sfu.ca/CourseCentral/459/han/papers/zhang96.pdf" alt="BIRCH">，<img src="https://www2.cs.sfu.ca/CourseCentral/459/han/papers/guha98.pdf" alt="CURE">，CHAMELEON等。自底向上的凝聚层次聚类如下图所示。</p><p><img src="/cluster/p1.jpg" alt></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>gans problem</title>
      <link href="/gans-problem/"/>
      <url>/gans-problem/</url>
      
        <content type="html"><![CDATA[<p>自从2014年Ian Goodfellow提出以来，GAN就存在着训练困难、生成器和判别器的loss无法指示训练进程、生成样本缺乏多样性等问题。从那时起，很多论文都在尝试解决，但是效果不尽人意，比如最有名的一个改进DCGAN依靠的是对判别器和生成器的架构进行实验枚举，最终找到一组比较好的网络架构设置，但是实际上是治标不治本，没有彻底解决问题。而今天的主角Wasserstein GAN（下面简称WGAN）成功地做到了以下爆炸性的几点：</p><ul><li>彻底解决GAN训练不稳定的问题，不再需要小心平衡生成器和判别器的训练程度</li><li>基本解决了collapse mode的问题，确保了生成样本的多样性</li><li>训练过程中终于有一个像交叉熵、准确率这样的数值来指示训练的进程，这个数值越小代表GAN训练得越好，代表生成器产生的图像质量越高</li><li>以上一切好处不需要精心设计的网络架构，最简单的多层全连接网络就可以做到</li></ul><p>推荐阅读：《Towards Principled Methods for Training Generative Adversarial Networks》，《Wasserstein GAN》</p><p>而改进后相比原始GAN的算法实现流程却只改了四点：</p><ul><li>判别器最后一层去掉sigmoid</li><li>生成器和判别器的loss不取log</li><li>每次更新判别器的参数之后把它们的绝对值截断到不超过一个固定常数c</li><li>不要用基于动量的优化算法（包括momentum和Adam），推荐RMSProp，SGD也行</li></ul><h1><span id="1原始gan有什么问题">1.原始GAN有什么问题</span></h1><p>原始GAN中：</p><p>对于D，需要最小化如下损失函数，尽可能把真实样本分为正例，生成样本分为负例:<img src="/generate-model/p17.JPG" alt>  (1)</p><p>对于G，Goodfellow一开始提出来一个损失函数，后来又提出了一个改进的损失函数，分别是</p><p>$E_{x\sim P_g}[log(1-D(x))]$  (2)</p><p>$E_{x\sim P_g}[-log(D(x))]$  (3)</p><p>《Towards Principled Methods for Training Generative Adversarial Networks》分别分析了这两种形式的原始GAN各自的问题所在，下面分别说明。</p><h2><span id="第一种原始gan形式的问题">第一种原始GAN形式的问题</span></h2><p>一句话概括：判别器越好，生成器梯度消失越严重。WGAN前作从两个角度进行了论证，第一个角度是从生成器的等价损失函数切入的。</p><p>首先，从Eq.(1)可以知道，固定G，最优的D是 $D^*(x)=\frac{p_r(x)}{p_r(x)+p_g(x)}$       Eq.(4)这个结果就是公式1的最优值，求导而得，就是看一个样本x来自真实分布和生成分布的可能性的相对比例。如果 $p_r(x)=0$且$p_g(x) \neq 0$, 最优判别器就应该非常自信地给出概率0；如果$p_r(x)=p_g(x)$, 说明该样本是真是假的可能性刚好一半一半，此时最优判别器也应该给出概率0.5。</p><p>然而GAN训练有一个trick，就是别把判别器训练得太好，否则在实验中生成器会完全学不动（loss降不下去），为了探究背后的原因，我们就可以看看在极端情况——判别器最优时，生成器的损失函数变成什么。给公式2加上一个不依赖于生成器的项，使之变成:</p><p>$E_{x\sim P_r}[logD(x)]+E_{x\sim P_g}[log(1-D(x))]$</p><p>注意，最小化这个损失函数等价于最小化公式2，而且它刚好是判别器损失函数的反。代入最优判别器即公式4，再进行简单的变换可以得到:</p><p>$E_{x\sim P_r}[log\frac{p_r(x)}{\frac{1}{2}[p_r(x)+p_g(x)]}]+E_{x\sim P_g}[log\frac{p_g(x)}{\frac{1}{2}[p_r(x)+p_g(x)]}]-2log2$=$2JS(P_r||P_g)-2log2$.  Eq.(5)</p><p>变换成这个样子是为了引入Kullback–Leibler divergence（简称KL散度）和Jensen-Shannon divergence（简称JS散度）这两个重要的相似度衡量指标，后面的主角之一Wasserstein距离，就是要来吊打它们两个的。所以接下来介绍这两个重要的配角——KL散度和JS散度：</p><p>$KL(P_1\mid \mid P_2)=E_{x\sim P_1}log\frac{P_1}{P_2}$.  Eq.(6)</p><p>$JS(P1\mid \mid P2)=\frac{1}{2}KL(P_1\mid \mid \frac{P_1+P_2}{2})+\frac{1}{2}KL(P_2\mid \mid \frac{P_1+P_2}{2})$. Eq.(7)</p><p>根据原始GAN定义的判别器loss，我们可以得到最优判别器的形式；而在最优判别器的下，我们可以把原始GAN定义的生成器loss等价变换为最小化真实分布P_r与生成分布P_g之间的JS散度。我们越训练判别器，它就越接近最优，最小化生成器的loss也就会越近似于最小化$P_r$和$P_g$之间的JS散度。</p><p>问题就出在这个JS散度上。我们会希望如果两个分布之间越接近,它们的JS散度越小，我们通过优化JS散度就能将$P_g$“拉向”$P_r$，最终以假乱真。这个希望在两个分布有所重叠的时候是成立的，但是如果两个分布完全没有重叠的部分，或者它们重叠的部分可忽略（下面解释什么叫可忽略），它们的JS散度是多少呢？</p><p>答案是$log2$,因为对于任意$x$, 只有如下四种可能性：</p><p>$P_1(x)=0$且$P_2(x)=0$</p><p>$P_1(x)\neq0$且$P_2(x)\neq0$</p><p>$P_1(x)=0$且$P_2(x)\neq0$</p><p>$P_1(x)\neq0$且$P_2(x)=0$</p><p>第一种对计算JS散度无贡献，第二种情况由于重叠部分可忽略所以贡献也为0，第三种情况对公式7右边第一个项的贡献是$log\frac{P_2}{\frac{1}{2}(P_2+0)}=log2$,第四种情况与之类似，所以最终$JS(P_1\mid \mid P_2)=log2$</p><p>换句话说，无论$P_r$跟$P_g$是远在天边，还是近在眼前，只要它们俩没有一点重叠或者重叠部分可忽略，JS散度就固定是常数$log 2$，而这对于梯度下降方法意味着——梯度为0！此时对于最优判别器来说，生成器肯定是得不到一丁点梯度信息的；即使对于接近最优的判别器来说，生成器也有很大机会面临梯度消失的问题。</p><p>那么$P_r$与$P_g$不重叠或重叠部分可忽略的可能性有多大？不严谨的答案是：非常大。比较严谨的答案是：当$P_r$与$P_g$的支撑集（support）是高维空间中的低维流形（manifold）时，$P_r$与$P_g$重叠部分测度（measure）为0的概率为1。</p><ul><li>支撑集（support）其实就是函数的非零部分子集，比如ReLU函数的支撑集就是(0, +\infty)，一个概率分布的支撑集就是所有概率密度非零部分的集合。</li><li>流形（manifold）是高维空间中曲线、曲面概念的拓广，我们可以在低维上直观理解这个概念，比如我们说三维空间中的一个曲面是一个二维流形，因为它的本质维度（intrinsic dimension）只有2，一个点在这个二维流形上移动只有两个方向的自由度。同理，三维空间或者二维空间中的一条曲线都是一个一维流形。</li><li>测度（measure）是高维空间中长度、面积、体积概念的拓广，可以理解为“超体积”。</li></ul><p>回过头来看第一句话，“当$P_r$与$P_g$的支撑集是高维空间中的低维流形时”，基本上是成立的。原因是GAN中的生成器一般是从某个低维（比如100维）的随机分布中采样出一个编码向量，再经过一个神经网络生成出一个高维样本（比如64x64的图片就有4096维）。当生成器的参数固定时，生成样本的概率分布虽然是定义在4096维的空间上，但它本身所有可能产生的变化已经被那个100维的随机分布限定了，其本质维度就是100，再考虑到神经网络带来的映射降维，最终可能比100还小，所以生成样本分布的支撑集就在4096维空间中构成一个最多100维的低维流形，“撑不满”整个高维空间。</p><p>“撑不满”就会导致真实分布与生成分布难以“碰到面”，这很容易在二维空间中理解：一方面，二维平面中随机取两条曲线，它们之间刚好存在重叠线段的概率为0；另一方面，虽然它们很大可能会存在交叉点，但是相比于两条曲线而言，交叉点比曲线低一个维度，长度（测度）为0，可忽略。三维空间中也是类似的，随机取两个曲面，它们之间最多就是比较有可能存在交叉线，但是交叉线比曲面低一个维度，面积（测度）是0，可忽略。从低维空间拓展到高维空间，就有了如下逻辑：因为一开始生成器随机初始化，所以$P_g$几乎不可能与$P_r$有什么关联，所以它们的支撑集之间的重叠部分要么不存在，要么就比$P_r$和$P_g$的最小维度还要低至少一个维度，故而测度为0。所谓“重叠部分测度为0”，就是上文所言“不重叠或者重叠部分可忽略”的意思。</p><p>我们就得到了WGAN前作中关于生成器梯度消失的第一个论证：在（近似）最优判别器下，最小化生成器的loss等价于最小化$P_r$与$P_g$之间的JS散度，而由于$P_r$与$P_g$几乎不可能有不可忽略的重叠，所以无论它们相距多远JS散度都是常数$log 2$，最终导致生成器的梯度（近似）为0，梯度消失。</p><h3><span id="从第二个角度论证梯度消失">从第二个角度论证梯度消失</span></h3><ul><li>首先，P_r与P_g之间几乎不可能有不可忽略的重叠，所以无论它们之间的“缝隙”多狭小，都肯定存在一个最优分割曲面把它们隔开，最多就是在那些可忽略的重叠处隔不开而已。</li><li>由于判别器作为一个神经网络可以无限拟合这个分隔曲面，所以存在一个最优判别器，对几乎所有真实样本给出概率1，对几乎所有生成样本给出概率0，而那些隔不开的部分就是难以被最优判别器分类的样本，但是它们的测度为0，可忽略。</li><li>最优判别器在真实分布和生成分布的支撑集上给出的概率都是常数（1和0），导致生成器的loss梯度为0，梯度消失。</li></ul><p>有了这些理论分析，原始GAN不稳定的原因就彻底清楚了：判别器训练得太好，生成器梯度消失，生成器loss降不下去；判别器训练得不好，生成器梯度不准，四处乱跑。只有判别器训练得不好不坏才行，但是这个火候又很难把握，甚至在同一轮训练的前后不同阶段这个火候都可能不一样，所以GAN才那么难训练。</p><p><img src="/gans-problem/1.JPG" alt></p><h2><span id="第二种原始gan形式的问题">第二种原始GAN形式的问题</span></h2><p>一句话概括：最小化第二种生成器loss函数，会等价于最小化一个不合理的距离衡量，导致两个问题，一是梯度不稳定，二是collapse mode即多样性不足。《Towards Principled Methods for Training Generative Adversarial Networks》又是从两个角度进行了论证，下面只说第一个角度.</p><p>上文提到固定G，最优的D是$D^<em>(x)=\frac{p_r(x)}{p_r(x)+p_g(x)}$， 这里，我们可以把KL散度变化成含$D^</em>$的模式：</p><p><img src="/gans-problem/9.JPG" alt></p><p>由以上公式可知：</p><p><img src="/gans-problem/10.JPG" alt></p><p>注意上式最后两项不依赖于生成器G，最终得到最小化公式3等价于最小化</p><p>$KL(P_g\mid \mid P_r)-2JS(P_r\mid \mid P_g)$ Eq.(11)</p><p>这个等价最小化目标存在两个严重的问题。</p><p>第一是它同时要最小化生成分布与真实分布的KL散度，却又要最大化两者的JS散度，一个要拉近，一个却要推远！这在直观上非常荒谬，在数值上则会导致梯度不稳定，这是后面那个JS散度项的毛病。</p><p>第二，即便是前面那个正常的KL散度项也有毛病。因为KL散度不是一个对称的衡量，$KL(P_g\mid \mid P_r)$ 与 $KL(P_r\mid \mid P_g)$ 是有差别的。以前者为例：</p><ul><li>当$P_g(x)\rightarrow0$而$P_r(x)\rightarrow1$时，$P_g(x)log\frac{P_g(x)}{P_r(x)}\rightarrow0$, 对$KL(P_g \mid \mid P_r)$的贡献趋于0.</li><li>当$P_g(x)\rightarrow1$而$P_r(x)\rightarrow0$时，$P_g(x)log\frac{P_g(x)}{P_r(x)}\rightarrow+\infty$, 对$KL(P_g \mid \mid P_r)$的贡献趋于无穷大.</li></ul><p>换言之，$KL(P_g \mid \mid  P_r)$ 对于上面两种错误的惩罚是不一样的，第一种错误对应的是“生成器没能生成真实的样本”，惩罚微小；第二种错误对应的是“生成器生成了不真实的样本” ，惩罚巨大。第一种错误对应的是缺乏多样性，第二种错误对应的是缺乏准确性。这一放一打之下，生成器宁可多生成一些重复但是很“安全”的样本，也不愿意去生成多样性的样本，因为那样一不小心就会产生第二种错误，得不偿失。这种现象就是大家常说的collapse mode。</p><p>第一部分小结：在原始GAN的（近似）最优判别器下，第一种生成器loss面临梯度消失问题，第二种生成器loss面临优化目标荒谬、梯度不稳定、对多样性与准确性惩罚不平衡导致mode collapse这几个问题。</p><p>关于实验证明，可以参考paper原文</p><h1><span id="2wgan之前的一个过渡解决方案">2.WGAN之前的一个过渡解决方案</span></h1><p>原始GAN问题的根源可以归结为两点，一是等价优化的距离衡量（KL散度、JS散度）不合理，二是生成器随机初始化后的生成分布很难与真实分布有不可忽略的重叠。</p><p>WGAN前作其实已经针对第二点提出了一个解决方案，就是对生成样本和真实样本加噪声，直观上说，使得原本的两个低维流形“弥散”到整个高维空间，强行让它们产生不可忽略的重叠。而一旦存在重叠，JS散度就能真正发挥作用，此时如果两个分布越靠近，它们“弥散”出来的部分重叠得越多，JS散度也会越小而不会一直是一个常数，于是（在第一种原始GAN形式下）梯度消失的问题就解决了。在训练过程中，我们可以对所加的噪声进行退火（annealing），慢慢减小其方差，到后面两个低维流形“本体”都已经有重叠时，就算把噪声完全拿掉，JS散度也能照样发挥作用，继续产生有意义的梯度把两个低维流形拉近，直到它们接近完全重合。以上是对原文的直观解释。</p><p>在这个解决方案下我们可以放心地把判别器训练到接近最优，不必担心梯度消失的问题。而当判别器最优时，对公式9取反可得判别器的最小loss为：</p><p><img src="/gans-problem/11.JPG" alt></p><p>其中$P_{r+\epsilon},P_{g+\epsilon}$ 分别是加噪声后的真实分布与生成分布。反过来说，从最优判别器的loss可以反推出当前两个加噪分布的JS散度。两个加噪分布的JS散度可以在某种程度上代表两个原本分布的距离，也就是说可以通过最优判别器的loss反映训练进程！</p><p>但是，因为加噪JS散度的具体数值受到噪声的方差影响，随着噪声的退火，前后的数值就没法比较了，所以它不能成为$P_r$和$P_g$距离的本质性衡量。加噪方案是针对原始GAN问题的第二点根源提出的，解决了训练不稳定的问题，不需要小心平衡判别器训练的火候，可以放心地把判别器训练到接近最优，但是仍然没能够提供一个衡量训练进程的数值指标。但是WGAN本作就从第一点根源出发，用Wasserstein距离代替JS散度，同时完成了稳定训练和进程指标的问题！</p><h1><span id="3wasserstein距离的优越性质">3.Wasserstein距离的优越性质</span></h1><p>Wasserstein距离又叫Earth-Mover（EM）距离，定义如下：</p><p>$W(P_r,P_g)=\mathop{inf}\limits_{r\sim \prod(P_r,P_g)}E_{(x,y)\sim\gamma}[\mid \mid x-y\mid \mid ]$ Eq.(12)</p><p>解释说明：$\prod(P_r,P_g)$ 是$P_r$,$P_g$组合起来的所有可能的联合分布的集合，反过来讲，$\prod(P_r,P_g)$ 中每一个分布的边缘分布都是 $P_r$ 和$P_g$. 对于每一个可能的联合分布 $\gamma$ 而言，可以从中采样 $(x,y)\sim \gamma$  得到一个真实样本 $x$ 和一个生成样本 $y$ , 并算出这对样本的距离 $\mid \mid x-y\mid \mid$, 所以可以计算该联合分布 $\gamma$ 下样本对距离的期望值 $\mathbb{E}_{(x, y) \sim \gamma} [\mid \mid x - y\mid \mid]$ 。在所有可能的联合分布中能够对这个期望值取到的下界 $W(P_r,P_g)$ ，就定义为Wasserstein距离。</p><p>直观上可以把 $\mathbb{E}_{(x, y) \sim \gamma} [\mid \mid x - y\mid \mid]$ 理解为在 $\gamma$ 这个“路径规划”下把 $P_r$ 这堆“沙土”挪到 $P_g$ “位置”所需的“消耗”，而 $W(P_r, P_g)$ 就是“最优路径规划”下的“最小消耗”，所以才叫Earth-Mover（推土机）距离。</p><p>Wasserstein距离相比KL散度、JS散度的优越性在于，即便两个分布没有重叠，Wasserstein距离仍然能够反映它们的远近。WGAN本作通过简单的例子展示了这一点。考虑如下二维空间中的两个分布 $P_1$ 和 $P_2$，$P_1$在线段AB上均匀分布， $P_2$ 在线段CD上均匀分布，通过控制参数 $\theta$ 可以控制着两个分布的距离远近。</p><p><img src="/gans-problem/2.JPG" alt></p><p>此时容易得到</p><p><img src="/gans-problem/3.JPG" alt></p><p>KL散度和JS散度是突变的，要么最大要么最小，Wasserstein距离却是平滑的，如果我们要用梯度下降法优化 $\theta$ 这个参数，前两者根本提供不了梯度，Wasserstein距离却可以。类似地，在高维空间中如果两个分布不重叠或者重叠部分可忽略，则KL和JS既反映不了远近，也提供不了梯度，但是Wasserstein却可以提供有意义的梯度。</p><h1><span id="4从wasserstein距离到wgan">4.从Wasserstein距离到WGAN</span></h1><p>既然Wasserstein距离有如此优越的性质，如果我们能够把它定义为生成器的loss，不就可以产生有意义的梯度来更新生成器，使得生成分布被拉向真实分布吗？</p><p>没那么简单，因为Wasserstein距离定义（公式12）中的 $\inf_{\gamma \sim \Pi (P_r, P_g)}$ 没法直接求解，不过没关系，作者用了一个已有的定理把它变换为如下形式:</p><p>$W(P_r, P_g) = \frac{1}{K} \sup_{\mid \mid f\mid\mid_L \leq K} \mathbb{E}<em>{x \sim P_r} [f(x)] - \mathbb{E}</em>{x \sim P_g} [f(x)]$（公式13）</p><p>证明过程见paper附录。</p><p>首先需要介绍一个概念——Lipschitz连续。它其实就是在一个连续函数 $f$ 上面额外施加了一个限制，要求存在一个常数 $K\geq 0$ 使得定义域内的任意两个元素 $x_1$ 和 $x_2$ 都满足</p><p>$\mid f(x_1) - f(x_2)\mid \leq K \mid x_1 - x_2\mid$</p><p>此时称函数 $f$ 的Lipschitz常数为K。</p><p>简单理解，比如说 $f$ 的定义域是实数集合，那上面的要求就等价于 $f$ 的导函数绝对值不超过K。再比如说 $\log (x)$ 就不是Lipschitz连续，因为它的导函数没有上界。Lipschitz连续条件限制了一个连续函数的最大局部变动幅度。</p><p>公式13的意思就是在要求函数f的Lipschitz常数 $\mid \mid f\mid \mid_L$ 不超过K的条件下，对所有可能满足条件的 $f$ 取到 $\mathbb{E}<em>{x \sim P_r} [f(x)] - \mathbb{E}</em>{x \sim P_g} [f(x)]$ 的上界，然后再除以 $K$。特别地，我们可以用一组参数w来定义一系列可能的函数 $f_w$，此时求解公式13可以近似变成求解如下形式</p><p>$K \cdot W(P_r, P_g) \approx \max_{w: \mid f_w\mid_L \leq K} \mathbb{E}<em>{x \sim P_r} [f_w(x)] - \mathbb{E}</em>{x \sim P_g} [f_w(x)]$（公式14）</p><p>由于神经网络的拟合能力足够强大，我们有理由相信，这样定义出来的一系列 $f_w$ 虽然无法囊括所有可能，但是也足以高度近似公式13要求的那个 $sup_{\mid \mid f\mid \mid_L \leq K}$ 了。</p><p>最后，还不能忘了满足公式14中 $\mid \mid f_w\mid \mid_L \leq K$ 这个限制。我们其实不关心具体的K是多少，只要它不是正无穷就行，因为它只是会使得梯度变大K倍，并不会影响梯度的方向。所以作者采取了一个非常简单的做法，就是限制神经网络 $f_\theta$ 的所有参数 $w_i$ 的不超过某个范围 $[-c, c]$，比如 $w_i \in [- 0.01, 0.01]$，此时关于输入样本x的导数 $\frac{\partial f_w}{\partial x}$ 也不会超过某个范围，所以一定存在某个不知道的常数K使得 $f_w$ 的局部变动幅度不会超过它，Lipschitz连续条件得以满足。具体在算法实现中，只需要每次更新完w后把它clip回这个范围就可以了。</p><p>到此为止，我们可以构造一个含参数w、最后一层不是非线性激活层的判别器网络 $f_w$ ，在限制w不超过某个范围的条件下，使得</p><p>$L = \mathbb{E}<em>{x \sim P_r} [f_w(x)] - \mathbb{E}</em>{x \sim P_g} [f_w(x)]$ （公式15）</p><p>尽可能取到最大，此时L就会近似真实分布与生成分布之间的Wasserstein距离（忽略常数倍数K）。注意原始GAN的判别器做的是真假二分类任务，所以最后一层是sigmoid，但是现在WGAN中的判别器 $f_w$ 做的是近似拟合Wasserstein距离，属于回归任务，所以要把最后一层的sigmoid拿掉。</p><p>接下来生成器要近似地最小化Wasserstein距离，可以最小化L，由于Wasserstein距离的优良性质，我们不需要担心生成器梯度消失的问题。再考虑到L的第一项与生成器无关，就得到了WGAN的两个loss。</p><p>$- \mathbb{E}_{x \sim P_g} [f_w(x)]$（公式16，WGAN生成器loss函数）</p><p>$\mathbb{E}<em>{x \sim P_g} [f_w(x)]- \mathbb{E}</em>{x \sim P_r} [f_w(x)]$（公式17，WGAN判别器loss函数）</p><p>公式15是公式17的反，可以指示训练进程，其数值越小，表示真实分布与生成分布的Wasserstein距离越小，GAN训练得越好。</p><p><img src="/gans-problem/4.JPG" alt></p><p>上文说过，WGAN与原始GAN第一种形式相比，只改了四点：</p><ul><li>判别器最后一层去掉sigmoid</li><li>生成器和判别器的loss不取log</li><li>每次更新判别器的参数之后把它们的绝对值截断到不超过一个固定常数c</li><li>不要用基于动量的优化算法（包括momentum和Adam），推荐RMSProp，SGD也行</li></ul><p>前三点都是从理论分析中得到的，已经介绍完毕；第四点却是作者从实验中发现的，属于trick，相对比较“玄”。作者发现如果使用Adam，判别器的loss有时候会崩掉，当它崩掉时，Adam给出的更新方向与梯度方向夹角的cos值就变成负数，更新方向与梯度方向南辕北辙，这意味着判别器的loss梯度是不稳定的，所以不适合用Adam这类基于动量的优化算法。作者改用RMSProp之后，问题就解决了，因为RMSProp适合梯度不稳定的情况。</p><p>实验验证：</p><p>1.判别器所近似的Wasserstein距离与生成器的生成图片质量高度相关，如下所示（此即题图）：</p><p><img src="/gans-problem/5.JPG" alt></p><p>2.WGAN如果用类似DCGAN架构，生成图片的效果与DCGAN差不多：</p><p><img src="/gans-problem/6.JPG" alt></p><p>但是厉害的地方在于WGAN不用DCGAN各种特殊的架构设计也能做到不错的效果，比如如果大家一起拿掉Batch Normalization的话，DCGAN就崩了：</p><p><img src="/gans-problem/7.JPG" alt></p><p>如果WGAN和原始GAN都使用多层全连接网络（MLP），不用CNN，WGAN质量会变差些，但是原始GAN不仅质量变得更差，而且还出现了collapse mode，即多样性不足：</p><p><img src="/gans-problem/8.JPG" alt></p><p>3.在所有WGAN的实验中未观察到collapse mode。</p><p>相比于判别器迭代次数的改变，对判别器架构超参的改变会直接影响到对应的Lipschitz常数K，进而改变近似Wasserstein距离的倍数，前后两轮训练的指标就肯定不能比较了，这是需要在实际应用中注意的。对此我想到了一个工程化的解决方式，不是很优雅：取同样一对生成分布和真实分布，让前后两个不同架构的判别器各自拟合到收敛，看收敛到的指标差多少倍，可以近似认为是后面的K_2相对前面K_1的变化倍数，于是就可以用这个变化倍数校正前后两轮训练的指标。</p><h1><span id="总结">总结</span></h1><p>《Towards Principled Methods for Training Generative Adversarial Networks》分析了Ian Goodfellow提出的原始GAN两种形式各自的问题，第一种形式等价在最优判别器下等价于最小化生成分布与真实分布之间的JS散度，由于随机生成分布很难与真实分布有不可忽略的重叠以及JS散度的突变特性，使得生成器面临梯度消失的问题；第二种形式在最优判别器下等价于既要最小化生成分布与真实分布直接的KL散度，又要最大化其JS散度，相互矛盾，导致梯度不稳定，而且KL散度的不对称性使得生成器宁可丧失多样性也不愿丧失准确性，导致collapse mode现象。</p><p>《Towards Principled Methods for Training Generative Adversarial Networks》针对分布重叠问题提出了一个过渡解决方案，通过对生成样本和真实样本加噪声使得两个分布产生重叠，理论上可以解决训练不稳定的问题，可以放心训练判别器到接近最优，但是未能提供一个指示训练进程的可靠指标，也未做实验验证。</p><p>WGAN引入了Wasserstein距离，由于它相对KL散度与JS散度具有优越的平滑特性，理论上可以解决梯度消失问题。接着通过数学变换将Wasserstein距离写成可求解的形式，利用一个参数数值范围受限的判别器神经网络来最大化这个形式，就可以近似Wasserstein距离。在此近似最优判别器下优化生成器使得Wasserstein距离缩小，就能有效拉近生成分布与真实分布。WGAN既解决了训练不稳定的问题，也提供了一个可靠的训练进程指标，而且该指标确实与生成样本的质量高度相关。作者对WGAN进行了实验验证。</p>]]></content>
      
      
      <categories>
          
          <category> Deep learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GAN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>gan application</title>
      <link href="/gan-application/"/>
      <url>/gan-application/</url>
      
        <content type="html"><![CDATA[<p>自2014年Ian Goodfellow提出了GAN（Generative Adversarial Network）以来，对GAN的研究可谓如火如荼。各种GAN的变体不断涌现，下图是GAN相关论文的发表情况：</p><p><img src="/gan-application/1.jpg" alt></p><h1><span id="gans-现在可以做什么">GANs 现在可以做什么？</span></h1><p><img src="/gan-application/3.jpg" alt></p><h1><span id="gan应用史">GAN应用史</span></h1><p>首先简单介绍一下GAN出现以来GAN变体们的进化史：</p><h4><span id="gan的cv史">GAN的CV史</span></h4><ul><li>GAN最初用来生成一维信号（语言，语音）以及简单的二维信号（minist）</li><li>后续研究者提出DCGAN， 可以相对更有效的生成二维的图像信号（但分辨率仍然很小，多数只有 64<em>64 或 128</em>128 ）,这是 GAN 首次在图像生成取得很大的进步。</li><li>2016年，商汤-香港中文大学联合实验室与罗格斯大学等机构提出了 StackGAN 算法，发明了更好的神经网路结构，将生成图像的分辨率从 $128<em>128$ 大幅提升到 $256</em>256$。</li><li>随后， NVIDIA 一篇以名人的脸孔为训练素材，生成出相当逼真的假名人照的论文，将分辨率一举拉高到 1024*1024，立刻令外界惊叹，GAN 一战成名。</li><li>今天，GAN不仅在二维图像的生成上有成熟的发展与应用，在三维信号以及高维信号的应用上也取得了不错的进步，例如视频生成，三维重建等。</li></ul><p>详细的展示将以几篇优秀的论文呈现</p><h4><span id="gan新的网络结构">GAN新的网络结构</span></h4><p>GAN变体如火如荼地今天，不仅出现了很多应用，也出现了一些网络结构上的改进.例如 CGAN, cycleGAN, DualGAN, DiscoGAN, TripleGAN...</p><p>本博客将展示CGAN, cycleGAN，stackgan,stylegan等</p><h4><span id="gan的对抗思想被其他深度学习应用引入目标检测-对抗攻击-信息检索-贝叶斯理论-capsule-强化学习-离散输出nlp-自编码器-半监督学习增强了原始应用的性能">GAN的对抗思想被其他深度学习应用引入(目标检测、对抗攻击、信息检索、贝叶斯理论、Capsule、强化学习、离散输出“NLP”、自编码器、半监督学习，增强了原始应用的性能。</span></h4><p>一开始外界普遍认为 GAN 只是一个生成模型，不过其实对抗性的思想对于改进现有 AI 算法同样很有帮助。举例来说，传统的深度学习算法可以看作 GAN 的生成器，引入鉴别器后，可以改良原有模型的任务表现，让现有 AI 算法做的更好、生成更接近真实的结果。商汤－香港中大联合实验室教授吕建勤从事研究 GAN 进行图像超分辨率，不仅是把低分辨率的图像提高，将其变为高分辨率图像，还可以近一步自动美化图像的风格和细节。</p><p>另一位商汤－香港中大联合实验室教授林达华则是以 GAN 增强图像标题生成的真实性。图像标题生成主要是希望通过计算机看懂图像，并且用自然语言来描述图像内容，加入鉴别器可以判断这句话是人类撰写还是电脑生成的，借由这种方式让原来 AI 模型生成的标题更有“人味”、更自然。也有许多从业者将 GAN 引入机器翻译、人脸识别、信息检索等方向，在去年取得很好的突破。</p><p><img src="/gan-application/2.jpg" alt></p><p>本博客主要介绍IRGAN，graphgan,SeqGAN</p>]]></content>
      
      
      <categories>
          
          <category> Deep learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GAN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GAN theory</title>
      <link href="/GAN-theory/"/>
      <url>/GAN-theory/</url>
      
        <content type="html"><![CDATA[<p>from 《Generative Adversarial Nets》 NIPS 2014 by Goodfellow.</p><h1><span id="1gan的基本思想">1.GAN的基本思想</span></h1><p>GAN通过博弈的思想来训练生成模型与对狼模型，基本思想不再重复阐述，可用如下图替代。</p><p><img src="/GAN-theory/1.JPG" alt></p><h1><span id="2gan的基本框架">2.GAN的基本框架</span></h1><p>在下面的示例图像中，蓝色区域显示了图像空间中包含真实图像的部分，具有很高的概率(超过某个阈值)，黑点表示我们的数据点(每个点是数据集中的一个图像)。现在，生成模型描述分布 $\hat{p}_\theta(x)$ (绿色)，它是通过从一个单位高斯分布(红色)中取点并通过一个(确定性)神经网络映射它们隐式定义的——我们的生成模型(黄色)。我们的神经网络是含参数 $\theta$ 的函数， 调整这些参数将调整生成的采样分布。我们的目标是生成一个分布（参数θ）匹配真实数据分布(例如,通过KL散度)。因此,你可以想象绿色分布随机,然后开始训练，迭代的改变参数使生成分布更接近真实分布。</p><p><img src="/GAN-theory/2.JPG" alt></p><h1><span id="3常用散度">3.常用散度</span></h1><p>散度是用来衡量两个分布之间差异的指标，因此，在讲解GAN原理之前，我要首先讲一下在GAN中用到的几个散度。s</p><h3><span id="31kl">3.1.KL</span></h3><p>KL散度又称relative entropy, 是信息论中的定义，是是两个概率分布P和Q差别的非对称性的度量。</p><h5><span id="维基百科中这样定义">维基百科中这样定义：</span></h5><ul><li><p>对于离散随机变量，概率分布P 和 Q的KL散度可按下式定义为：</p><p>$KL(P \mid \mid Q)= \sum_i P(i)log\frac{P(i)}{Q(i)}$.</p><p>即按概率P求得的P和Q的对数商的平均值。KL散度仅当概率P和Q各自总和均为1，且对于任何i皆满足 $Q(i)&gt;0$及 $P(i)&gt;0$ 时，才有定义。式中出现 $0log 0$ 的情况，其值按0处理。</p></li><li><p>对于连续随机变量，其概率分布P和Q可按积分方式定义为:</p><p>$KL(P \mid \mid Q)= E_{i\sim P}log\frac{P}{Q}$</p><p>即为P关于Q的相对熵。</p></li></ul><h5><span id="特性">特性</span></h5><ul><li>相对熵的值为非负数</li><li>当且仅当P=Q时，相对熵为0</li><li>尽管从直觉上KL散度是个度量或距离函数, 但是它实际上并不是一个真正的度量或距离。因为KL散度不具有对称性：从分布P到Q的距离通常并不等于从Q到P的距离。$KL(P\mid \mid Q)\neq KL(Q\mid \mid P)$, 这也是在距离度量中的一大忌。</li></ul><h3><span id="32js">3.2.JS</span></h3><p>由于KL散度不具有对称性，用其衡量距离是行不通的，所以，在KL散度的基础上又出现了JS散度，JS散度既保留了KL散度的优点，又解决的对称问题：</p><p>$JS(P1\mid \mid P2)=\frac{1}{2}KL(P_1\mid \mid \frac{P_1+P_2}{2})+\frac{1}{2}KL(P_2\mid \mid \frac{P_1+P_2}{2})$</p><p>原始GAN是基于JS散度的度量，但经过实践与理论的分析，人们渐渐摒弃了这种度量方式，改用Wasserstein距离，关于原因参见我的另一篇博客《GAN'S problem》,这里只简要介绍Wasserstein距离的定义。</p><h3><span id="33wasserstein距离">3.3.Wasserstein距离</span></h3><p>Wasserstein距离又叫Earth-Mover距离(EM距离)，用于衡量两个分布之间的距离，定义：</p><p>$W(P_r,P_g)=\mathop{inf}\limits_{r\sim \prod(P_r,P_g)}E_{(x,y)\sim\gamma}[\mid \mid x-y\mid \mid ]$</p><p>解释说明：$\prod(P_r,P_g)$ 是$P_r$,$P_g$组合起来的所有可能的联合分布的集合，反过来讲，$\prod(P_r,P_g)$ 中每一个分布的边缘分布都是 $P_r$ 和$P_g$. 对于每一个可能的联合分布 $\gamma$ 而言，可以从中采样 $(x,y)\sim \gamma$  得到一个真实样本 $x$ 和一个生成样本 $y$ , 并算出这对样本的距离 $\mid \mid x-y\mid \mid$, 所以可以计算该联合分布 $\gamma$ 下样本对距离的期望值 $\mathbb{E}_{(x, y) \sim \gamma} [\mid \mid x - y\mid \mid]$ 。在所有可能的联合分布中能够对这个期望值取到的下界 $W(P_r,P_g)$ ，就定义为Wasserstein距离。</p><p>直观上可以把 $\mathbb{E}_{(x, y) \sim \gamma} [\mid \mid x - y\mid \mid]$ 理解为在 $\gamma$ 这个“路径规划”下把 $P_r$ 这堆“沙土”挪到 $P_g$ “位置”所需的“消耗”，而 $W(P_r, P_g)$ 就是“最优路径规划”下的“最小消耗”，所以才叫Earth-Mover（推土机）距离。</p><p>Wasserstein距离相比KL散度、JS散度的优越性在于，即便两个分布没有重叠，Wasserstein距离仍然能够反映它们的远近。WGAN本作通过简单的例子展示了这一点。考虑如下二维空间中的两个分布 $P_1$ 和 $P_2$，$P_1$在线段AB上均匀分布， $P_2$ 在线段CD上均匀分布，通过控制参数 $\theta$ 可以控制着两个分布的距离远近。</p><h1><span id="4gan原理">4.GAN原理</span></h1><p>GAN的思想启发自博弈论中的零和游戏，包含一个生成网络G和一个判别网络D。</p><h4><span id="41-目标函数">4.1 目标函数：</span></h4><p><img src="/GAN-theory/3.JPG" alt="GAN_objective function"></p><h4><span id="42-workflow">4.2 workflow</span></h4><p><img src="/GAN-theory/4.JPG" alt></p><h4><span id="43-算法">4.3 算法：</span></h4><p><img src="/GAN-theory/5.JPG" alt></p><h4><span id="44-优化-p_gp_data">4.4 优化 $p_g=p_{data}$</span></h4><p>1.首先固定G，优化D。 对D的目标函数求导，并验证最优解即最大值为：</p><p>$D_G^*(x)=\frac{p_{data}}{p_{data}(x)+p_{g}(x)}$</p><p>proof 如下：</p><p><img src="/GAN-theory/6.JPG" alt></p><p>因此目标函数可重写为：</p><p><img src="/GAN-theory/7.JPG" alt></p><p>2.接下来固定D， 训练G，在G的全局最小值处，目标函数为$-log4$.</p><p>证明过程如下：</p><p><img src="/GAN-theory/8.JPG" alt></p><p>在当前最优的D下，G的目标函数为 $-log4+2*JS(p_{data}\mid \mid p_{g})$,由于两分布是非负的，所以G的全局最优解为-log4, 此时 $p_{data}=p_{g}$.</p><p>最后可以证明当且仅当$p_{data}=p_{g}$,</p><h4><span id="45-收敛性">4.5 收敛性</span></h4><p>原文中给出证明，如果G和D有足够的能力，那么给定G，D可以达到最优解， 并且$p_g$ 可以更新来优化目标函数，使得 $p_{g}$ 收敛于$p_{data}$.</p><p>证明过程：</p><p><img src="/GAN-theory/9.JPG" alt></p><h1><span id="gan特性">GAN特性</span></h1><h4><span id="优点">优点：</span></h4><ul><li>计算梯度时只用到了反向传播，而不需要马尔科夫链。</li><li>训练时不需要对隐变量做推断。</li><li>理论上，只要是可微分函数都能用于构建D和G，因而能够与深度学习结合来学   习深度产生式网络（deep generative model）。</li><li>统计角度上来看，G的参数更新不是直接来自于数据样本，而是使用来自D的反传梯度。</li></ul><h4><span id="缺点">缺点</span></h4><ul><li>生成器的分布没有显示的表达</li><li>比较难训练，D与G之间需要很好的同步，例如D更新k次而G更新1次。将在后文中介绍GAN的缺点与训练技巧</li></ul>]]></content>
      
      
      <categories>
          
          <category> Deep learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GAN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>generate model</title>
      <link href="/generate-model/"/>
      <url>/generate-model/</url>
      
        <content type="html"><![CDATA[<h1><span id="生成模型">生成模型</span></h1><p>生成模型(generative model)描述的是这一类的模型：接收了从分布 $p_{data}$ 取样的若干样本构成我们的训练集，然后让模型学习到一个模拟这一分布的概率分布$p_{model}$.</p><p><img src="/generate-model/p5.JPG" alt></p><p>在有些情况下，我们可以直接的估计概率分布，如下图所示的密度概率分布模型：</p><p><img src="/generate-model/p1.jpg" alt="Image of gen models"></p><p>有些情况，我们需要从中生成一些样本，如下图所示训练数据为ImageNet中的样本，训练的生成模型可以生成以假乱真的图片：</p><p><img src="/generate-model/p2.JPG" alt="Image of gen models"></p><h1><span id="为什么研究生成模型">为什么研究生成模型</span></h1><p>那么研究生成模型的意义何在呢？尤其是对于非直接密度估计而只能从模型中生成样本的一类情况，特别是对于图像，这类模型只能提供更多的图像，而我们并不缺少海量的图像。</p><p>主要原因如下：</p><ul><li>这是对我们能够表示和操控高维概率分布的能力的有效检验。</li><li>我们可以将生成模型结合到强化学习(reinforcement learning)中，例如对于model-based RL可用生成模型来模拟可能发生的未来情况，以便RL算法进行规划(planning)，例如 Deep Visual Foresight for Planning Robot Motion。</li><li>生成模型可以用有损失（部分样本无标记）的数据进行训练，进行半监督学习(semi-supervised learning)，降低了我们获得数据样本的难度。</li><li>生成模型可以处理多峰值(multi-modal)的输出。对于很多任务，一个输入可能对应多个可能的输出，一些传统的机器学习模型只能学到一种输出而无法学习多种可能的输出。</li><li>还有一些任务需要产生看起来真实的样本。如由低分辨率图片产生高分辨率图片，图像转换等等。</li></ul><p><img src="/generate-model/p3.JPG" alt="Image of gen models"></p><p>输入低分辨率图片，生成模型产生接近原分辨率的图片。</p><p><img src="/generate-model/p4.JPG" alt="Image of gen models"></p><p>从街道轮廓图生成真实图，从卫星图片生成地图，从草图生成真实图片</p><h1><span id="生成模型分类">生成模型分类</span></h1><p>那么生成模型是如何工作的呢？为了简化讨论，我们这里考虑符合最大似然(maximum likelihood)原则(可参考最大似然法与最大后验概率估计——深度学习花书第五章（三）)的生成模型。其基本思想是模型是带有参数 $\theta$ 的概率分布的估计，则模型给予m个训练样本的似然率为 $\prod_{i=1}^m p_{model}(c^{(i)};\theta)$, 最大似然原则就是选择使该概率最大的参数。即</p><p>$\theta^* = \mathop{argmax}\limits_{\theta}\prod_{i=1}^m p_{model}(c^{(i)};\theta)$</p><p>$=\mathop{argmax}\limits_{\theta} log \prod_{i=1}^m p_{model}(c^{(i)};\theta)$</p><p>$=\mathop{argmax}\limits_{\theta}\sum_{i=1}^m log p_{model}(c^{(i)};\theta)$</p><p>其过程如下图所示，模型会逐渐将训练数据所处的概率增大。</p><p><img src="/generate-model/p7.JPG" alt="Image of gen models"></p><p>另一方面，我们也可以将最大似然近似看做是使模型与数据分布KL divergence（可参考概率论——深度学习花书第三章）最小的参数,即：</p><p>$\theta^* = \mathop{argmin}\limits_{\theta}D_{KL}(p_{data}(x) \mid\mid p_{model}(x;\theta))$</p><p><img src="/generate-model/p6.JPG" alt></p><p>先来看看左边一支Explicit density显性密度模型，即显性的定义密度分布 $p_{model}(x;\theta)$ ，对于这类模型，似然率最大化的过程比较直接：我们将密度分布代入到似然率的表达式中，然后沿着梯度上升的方向更新模型即可，但其难点在于如何定义模型使得其既能表达数据的复杂度同时又方便计算。大致有两种方式：</p><ul><li><p>Tractable explicit model（易解显性模型），即定义一个方便计算的密度分布，主要一类模型是Fully visible belief nets，简称FVBN，也被称作Auto-Regressive Network，这一类模型利用了概率的链式法则，转化为条件概率的联乘积形式,NADE,PixelRNN,PixelCNN都属于这一类模型，许多更复杂的模型也是基于这一类模型，例如DeepMind的语音合成模型WaveNet。这类模型一大缺点是模型之后的元素值值得生成依赖于之前的元素值，即我们需要先生成$x_1$再生成$x_2$，其效率较低。其优点是由于直接定义了可解的密度分布，我们可直接应用基于训练数据对数似然率的优化模型，但同时这也限制了可供选择的密度分布类型。</p></li><li><p>Approximate explicit model（近似显性模型）可以避免需要设定可解的密度分布的限制，其密度分布可以是那一计算的，但可用一些近似方法来求最大似然率。这又可以分为两类，即确定性近似（deterministic approximation），通常是指变分近似（可参考变分推断——深度学习第十九章），即转化为Evidence lower bound的极值问题，之后会详细总结变分自编码器VAE。这一方法的缺点是现在VAE生成的图片都比较模糊，对于这一现象暂时还没有很好的解释。另一类是随机近似(stochastic approximation)，如MCMC方法（可参考蒙特卡罗方法——深度学习第十七章），如果样本可以较快的产生且各样本之间的方差较小，可以利用MCMC，但我们之前在第十七章也看到这一方法混合时间较长且没有很好的方法判断是否已经converge，所以效率较低。</p></li></ul><p>再来看右边一支Implicit density model隐性密度模型，即不明确定义模型密度分布，而是非直接的与  作用，即从中取样，也可以分为两类：</p><ul><li>也是利用达到平稳分布后的马尔科夫链来取样，如generative stochastic network(生成随机网络)，简称GSN。马尔科夫链的缺点如难以拓展到高维空间，巨大的计算量等缺点也适用于这种模型。</li><li>Generative Adversarial Network(生成对抗网络)，简称GAN，这一模型取样时只需要进行一步，而不需要利用马尔科夫链运行若干次直至达到平稳分布，所以采样效率很高。其基本思想是利用生成神经网络和鉴别神经网络两个网络相互对抗，达到纳什均衡。其优点是可以并行的产生样本，不需要马尔科夫链，效率高；生成函数没有限制，可以表达很多种分布；实际中GAN生成的样本视觉上较其他方法好。当然，由于它不再是优化问题，而是需要找到纳什均衡，所以训练过程不够稳定。</li></ul><p>现在比较常用的是FVBN，VAE与GAN</p><h2><span id="玻尔兹曼机">玻尔兹曼机</span></h2><p>玻尔兹曼机是一种基于能量函数的概率模型，其联合分布概率可表示为 $p(\overline{v},\overline{h}) = \frac {exp(-E(\overline{v},\overline{h}))}{Z}$, 其中$\overline{v}$ 代表了输入的观察到的变量，$\overline{h}$代表了隐藏变量，Z是分配函数，Restricted Boltzmann machine对这一能量函数进一步简化，假定了网络中仅有隐藏变量与观察变量的连接，而观察变量间没有连接，隐藏变量间也没有连接，且隐藏变量可用$n_h$个二进制随机变量表示，如下图的无向图所示:</p><p><img src="/generate-model/p8.JPG" alt></p><h2><span id="生成随机网络">生成随机网络</span></h2><p>再来看看另一种利用马尔科夫链采样的生成模型，生成随机网络GSN，与玻尔兹曼机相比，它不是显性的定义观察量与隐藏量的联合分布，而是在马尔科夫链中利用了两个条件概率分布：</p><p>1.$p(x^k\mid h^k)$ 指导如何根据现在的隐藏变量产生下一个观察量。</p><p>2.$p(h^k\mid h^{k-1},x^{k-1})$ 根据前一个状态的隐藏变量和观察量更新隐藏变量。</p><p>联合概率分布只是隐性定义的，是马尔科夫链的稳态分布。</p><h2><span id="自回归网络">自回归网络</span></h2><p>自回归网络Auto-Regressive Networks，又叫做Fully-visible Bayes networks(FVBN)，是一种有向概率图，其中条件概率用神经网络来表示，利用概率的链式法则，它将关于观察量的联合概率分布，分为一系列条件概率$p(x_i\mid x_{i-1},...,x_1)$ 的乘积形式</p><p>$p(x)=\prod_{i=1}^{n_i} p(x_i\mid x_{i-1},...,x_1)$</p><p>简单的线性自回归网络结构没有隐藏变量，也不共享特征或参数，如下图所示</p><p><img src="/generate-model/p9.JPG" alt="上图是FVBN的有向图表示，下图是相应的计算图"></p><p>如果我们想增大模型的容量，使其可以近似任意联合概率分布，则可以加入隐藏变量，另外还可以通过特征或参数共享使得泛化效果更好，其计算图如下所示:</p><p><img src="/generate-model/p10.JPG" alt></p><p>其优点有在可以表述随机变量的高阶依赖关系的同时减少了模型所需要的参数，例如假设变量可取离散的k种不同的值，则每个$p(x_i\mid x_{i-1},...,x_1)$ 可用有$(i-1)*k$ 个输入及k个输出的神经网络表示，而不需要指数级别的参数。另一个优点是我们不需要对于每一个$x_i$ 都采用一个不同的神经网络，而是将它们合并为一个神经网络，即用来预测$x_i$ 的隐藏特征可以被重复利用来对$x_{i+k}(k&gt;0)$ 进行预测，这些隐藏单位的参数因此可以通过联合优化使得序列中所有变量的预测都得到改善。</p><p>在生成图像时，FVBN类模型通常能够得到更高质量的图片，由于其直接模拟概率分布，更容易评估训练效果，其训练过程也较GAN稳定，但是由于其训练过程的序列性，训练过程较为缓慢。</p><p>FVBN有两类模型PixelRNN和PixelCNN.在图像合成方面应用广泛，尤其是由残缺图像补全完整图像的应用。其基本思想是从某个角落里开始，依据之前的像素信息利用RNN或CNN来预测下一个位置的像素值。对于PixelRNN其过程如下图所示，其中与之前变量的依赖关系用RNN如LSTM结构来模拟：</p><p><img src="/generate-model/p11.JPG" alt></p><p>另外在语音合成领域，FVBN也有较好的效果，例如DeepMind的WaveNet模型就是基于FVBN的原理。</p><h2><span id="变分自编码器">变分自编码器</span></h2><p>自编码器的结构如下，利用神经网络将输入信息编码到其特征空间，再利用神经网络将这些特征重构为与输入类似的信息。通常特征z相较输入x的维度要小，只包含重要特征。</p><p><img src="/generate-model/p12.JPG" alt></p><p>而为了从模型中生成新的样本，我们只需要从分布$p_{model}(z)$ 中采样z,再经过解码网络得到样本x, 其概率分布表示为<img src="/generate-model/p13.JPG" alt>，但是这个积分是难以计算的，其后验概率$p_{model}(z\mid x)=p_{model}(x\mid z)p_{model}(z)/p_{model}(x)$ 同样是难以计算的，所以我们就要利用变分近似来求其lower bound，而我们就是利用加码网络$q(z\mid x)$ 来近似$p_{model}(z\mid x)$.</p><p>可以做如下推导：</p><p><img src="/generate-model/p14.JPG" alt></p><p>其中第一项我们可以通过从加码网络中采样来近似，而第二项由于$q(z\mid x)$ 和$p_{model}(z)$ 我们均可以选取可适的函数使其有闭合的解析形式，也是容易计算的。这两项合起来就是我们之前在变分推断中定义的evidence lower bound，简称ELBO函数，我们可以用梯度上升方法来逐渐优化它。</p><p>总结一下，VAE就是在训练时利用加码网络和解码网络利用变分法来极大化evidence lower bound，这样使得  的下限提高，在要利用模型生成样本时则可从解码网络取样得到生成样本。VAE的理论原理比较自然，实现也比较容易，而且中间学习到的特征空间也可以用来迁移到其他的任务，但是虽然它显性的定义了概率分布，但并不是精确的求解概率分布，而是用lower bound来近似其概率分布，所以在做模型评估时不如上一篇总结的PixelRNN/PixelCNN好，而且其生成的样本较之之后要总结的GAN的样本通常要更模糊些，一些例子如下图所示：</p><p><img src="/generate-model/p15.JPG" alt></p><p>当然关于VAE为何生成样本模糊，如何改善VAE的研究仍然很有意义，而且还有将VAE与GAN相结合的研究也可以同时利用二者的优势.</p><h2><span id="生成对抗网络">生成对抗网络</span></h2><p>我们之前总结的两个主要的模型FVBN与VAE都是显性的定义了概率密度分布，假如我们并不需要求密度分布，而只是希望模型能产生合理的样本，那么我就可以放弃对密度分布的定义，而GAN就是这样一种模型，它采取了博弈论的解决方法：通过两个神经网络的相互博弈，其中一个叫做生成网络Generator Network，一个叫做判别网络Discriminator Network，生成网络尽力产生可以以假乱真的样本来迷惑判别网络，判别网络尽力区分真实样本与生成网络生成的假样本，通过不断的交替学习，两个网络的准确度都越来越高，最后生成网络可以模拟与训练集分布相同的样本分布，如下图所示。</p><p><img src="/generate-model/p16.JPG" alt></p><p>详细来说，用D来表示判别函数，$\theta^{(D)}$ 来表示该网络的参数，用$J^{(D)}(\theta^{(D)},\theta^{(G)})$ 来表示其损失函数，用G来表示生成网络，用 $\theta^{(G)}$ 来表示该网络的参数，用$J^{(G)}(\theta^{(D)},\theta^{(G)})$ 来表示其损失函数。生成网络的作用是在只能控制 $\theta^{(G)}$ 的情况下尽量减少 $J^{(G)}(\theta^{(D)},\theta^{(G)})$ ，而判别网络的作用是在只能控制$\theta^{(D)}$ 的情况下尽量减小$J^{(D)}(\theta^{(D)},\theta^{(G)})$ 。把这两个网络看做两个玩家，每个玩家都只能控制自己的参数，而不能改变另一个玩家的参数，所以相较于将该问题看做一个优化问题，更自然的是当做博弈论中的博弈问题，而该问题的解就是纳什均衡(Nash equilibrium)状态，即 $(\theta^{(D)},\theta^{(G)})$ 使得 $J^{(D)}$ 相对于 $\theta^{(D)}$ 极小同时  $J^{G}$ 相对于 $\theta^{(G)}$ 极小。</p><p>对于判别网络，其损失函数就是经典的二元分类器的交叉熵损失</p><p><img src="/generate-model/p17.JPG" alt>其中来自于真实分布的样本标记是1，而来自于生成网络的样本标记为0。</p><p>对于生成网络的损失函数，最简单的假设就是假设这是一个零和博弈 zero-sum game。由于它与判别网络损失恰恰相反，所以我们可以用minmax的形式表示我们希望得到的解</p><p>$\theta^*=\mathop{argmin}\limits_{\theta_{(G)}} \mathop{max}\limits_{\theta_{(D)}}V(\theta^{(D)},\theta^{(G)})$</p><p>其中 $V(\theta^{(D)},\theta^{(G)})$ 为上文提到的交叉熵损失。</p><p>上表达可以做如下解释：判别器的目的是令  $V(\theta^{(D)},\theta^{(G)})$ 尽量大就是使真实样本 $D_{\theta_D}(x)$ 接近1，而伪造样本 $D_{\theta_D}(G(<em>{\theta_G}(z)))$ 接近0。而生成网络的目的是令 $V(\theta^{(D)},\theta^{(G)})$ 尽量小，即使伪造样本 $D</em>{\theta_{D}}(G(<em>{\theta</em>{G}}(z)))$ 也接近1.</p><p>以上就是GAN的基本原理，即从博弈的角度来使生成网络与判别网络共同进步，最后使生成网络可以以假乱真。而GAN的变种模型也很多，可以参考hindupuravinash/the-gan-zoo中列举的各种GAN模型。</p><p>近两年关于GAN的研究和应用非常多，比如图像风格迁移，根据文字生成图像等等。 另一方面，GAN也由于训练过程的不稳定性常受诟病，为了增强GAN的稳定性，也有Wasserstein GAN, LSGAN等改进模型方面的研究。这些将在下一篇博客中介绍。总结一下，做为深度学习花书的最后一部分，GAN是近些年生成模型研究比较活跃的方向，它的原理不再是对显性概率分布做直接计算或近似处理，而是利用了生成网络与判别网络的相互博弈，是一种新颖而有效的思路。希望这方面的模型能够更加稳定，得到更多的应用。</p>]]></content>
      
      
      <categories>
          
          <category> Deep learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GAN </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
